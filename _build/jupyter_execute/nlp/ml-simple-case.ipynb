{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning: A Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's assume that we have collected a list of personal names and we have their corresponding gender labels, i.e., whether the name is a male or female one.\n",
    "\n",
    "The goal of this example is to create a classifier that would automatically classify a given name into either male or female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Quick Example: Name Gender Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We use the data provided in NLTK. Please download the corpus data if necessary.\n",
    "- We load the corpus, `nltk.corpus.names` and randomize it before we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- As now our unit for classification is a name. In **feature engineering**, our goal is to transform the texts (i.e., names) into vectorized reprsentations.\n",
    "- To start with, let's represent each text (name) by using its last character as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_vectorizer(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "\n",
    "\n",
    "text_vectorizer('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We then apply the feature engineering method to every text in the data and split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "featuresets = [(text_vectorizer(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(text_vectorizer('Neo'))\n",
    "classifier.classify(text_vectorizer('Trinity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Post-hoc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- One of the most important steps after model training is to examine which features contribute the most to the classifier prediction of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     39.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.3 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.0 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     10.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Please note that in `NLTK`, we can use the `apply_features` to create training and test datasets.\n",
    "- When you have a very large feature set, this can be more effective in terms of memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(text_vectorizer, labeled_names[500:])\n",
    "test_set = apply_features(text_vectorizer, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can we improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the following, we will talk about methods that we may consider to further improve the model training.\n",
    "\n",
    "- Feature Engineering\n",
    "- Error Analysis\n",
    "- Cross Validation\n",
    "- Try Different Machine-Learning Algorithms\n",
    "- (Ensemble Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More Sophisticated Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can extract more features from the names.\n",
    "- Use the following features for vectorized representations of names:\n",
    "    - The first/last letter\n",
    "    - Frequencies of all 26 alphabets in the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def text_vectorizer2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer2('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(text_vectorizer2, labeled_names[500:])\n",
    "test_set = apply_features(text_vectorizer2, labeled_names[:500])\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     39.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.3 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.0 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     10.5 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.2 : 1.0\n",
      "             last_letter = 'm'              male : female =     10.0 : 1.0\n",
      "                count(v) = 2              female : male   =      8.8 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.5 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.9 : 1.0\n",
      "                count(a) = 3              female : male   =      5.2 : 1.0\n",
      "                count(i) = 3                male : female =      5.1 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.1 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.6 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.6 : 1.0\n",
      "             last_letter = 'z'              male : female =      4.3 : 1.0\n",
      "                count(w) = 1                male : female =      4.3 : 1.0\n",
      "                  has(w) = True             male : female =      4.3 : 1.0\n",
      "             last_letter = 't'              male : female =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train-Development-Test Data Splits for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Normally we have **train**-**test** splits of data\n",
    "- Sometimes we use **development (dev)** set for error analysis and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Now let's train the model on the **training set** and first check the classifier's performance on the **dev** set.\n",
    "- We then identify the errors the classifier made in the **dev** set.\n",
    "- We perform error analysis for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]\n",
    "\n",
    "train_set = [(text_vectorizer2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(text_vectorizer2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(text_vectorizer2(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(text_vectorizer2(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('error-analysis.csv', 'w') as f:\n",
    "\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['tag', 'guess', 'name'])\n",
    "    write.writerows(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/confusion-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Confusion Matrix:\n",
    "    - **True positives** are relevant items that we correctly identified as relevant.\n",
    "    - **True negatives** are irrelevant items that we correctly identified as irrelevant.\n",
    "    - **False positives** (or Type I errors) are irrelevant items that we incorrectly identified as relevant.\n",
    "    - **False negatives** (or Type II errors) are relevant items that we incorrectly identified as irrelevant.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given these four numbers, we can define the following model evaluation metrics:\n",
    "- **Accuracy**: How many items were correctly classified?\n",
    "- **Precision**: How many of the items identified by the classifier as relevant are indeed relevant, is TP/(TP+FP).\n",
    "- **Recall**: How many of the true relevant items were successfully identified by the classifier, is TP/(TP+FN).\n",
    "- **F-Measure (or F-Score)**: the harmonic mean of the precision and recall,i.e.:\n",
    "    \n",
    "\n",
    "$$ \n",
    "F= \\frac{(2 × Precision × Recall)}{(Precision + Recall)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Compute the Confusion Matrix\n",
    "t_f = [feature for (feature, label) in test_set]  # features of test set\n",
    "t_l = [label for (feature, label) in test_set]  # labels of test set\n",
    "t_l_pr = [classifier.classify(f) for f in t_f]  # predicted labels of test set\n",
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <52.4%> 10.0% |\n",
      "  male |  15.6% <22.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def createCM(classifier, test_set):\n",
    "    t_f = [feature for (feature, label) in test_set]\n",
    "    t_l = [label for (feature, label) in test_set]\n",
    "    t_l_pr = [classifier.classify(f) for f in t_f]\n",
    "    cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "    print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <52.4%> 10.0% |\n",
      "  male |  15.6% <22.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can also check our average model performance using the cross-validation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "![](../images/ml-kfold.png)\n",
    "(Source: https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.76\n",
      "accuracy: 0.76\n",
      "accuracy: 0.78\n",
      "accuracy: 0.77\n",
      "accuracy: 0.78\n",
      "accuracy: 0.78\n",
      "accuracy: 0.79\n",
      "accuracy: 0.79\n",
      "accuracy: 0.8\n",
      "accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "acc_kf = [] ## accuracy holder\n",
    "\n",
    "## Cross-validation\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = nltk.NaiveBayesClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]])\n",
    "    cur_fold_acc = nltk.classify.util.accuracy(\n",
    "        classifier, train_set[test_index[0]:test_index[len(test_index) - 1]])\n",
    "    acc_kf.append(cur_fold_acc)\n",
    "    print('accuracy:', np.round(cur_fold_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783712315137699"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Try Different Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Try Maxent Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Maxent is memory hungry, slower, and it requires `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.9 s, sys: 11.2 ms, total: 5.91 s\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import MaxentClassifier\n",
    "classifier_maxent = MaxentClassifier.train(train_set,\n",
    "                                           algorithm='gis',\n",
    "                                           trace=0,\n",
    "                                           max_iter=100,\n",
    "                                           min_lldelta=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{note}\n",
    "The default algorithm for training is `iis` (Improved Iterative Scaling). Another alternative is `gis` (General Iterative Scaling), which is faster.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.624"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -0.193 last_letter=='a' and label is 'male'\n",
      "  -0.129 last_letter=='k' and label is 'female'\n",
      "  -0.126 last_letter=='f' and label is 'female'\n",
      "  -0.119 count(v)==2 and label is 'male'\n",
      "  -0.078 last_letter=='p' and label is 'female'\n",
      "  -0.076 last_letter=='m' and label is 'female'\n",
      "  -0.075 count(a)==3 and label is 'male'\n",
      "  -0.075 last_letter=='v' and label is 'female'\n",
      "  -0.070 last_letter=='d' and label is 'female'\n",
      "  -0.065 last_letter=='i' and label is 'male'\n",
      "  -0.059 last_letter=='w' and label is 'female'\n",
      "  -0.059 count(l)==3 and label is 'male'\n",
      "  -0.058 last_letter=='o' and label is 'female'\n",
      "  -0.055 count(e)==3 and label is 'male'\n",
      "  -0.052 last_letter=='r' and label is 'female'\n",
      "  -0.051 count(a)==2 and label is 'male'\n",
      "  -0.050 last_letter=='z' and label is 'female'\n",
      "  -0.050 count(p)==3 and label is 'male'\n",
      "  -0.044 count(n)==3 and label is 'male'\n",
      "   0.044 last_letter=='c' and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "classifier_maxent.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <62.4%>     . |\n",
      "  male |  37.6%     <.>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6180124223602484\n",
      "accuracy: 0.6304347826086957\n",
      "accuracy: 0.6475155279503105\n",
      "accuracy: 0.59472049689441\n",
      "accuracy: 0.6360808709175739\n",
      "accuracy: 0.6531881804043546\n",
      "accuracy: 0.6485225505443235\n",
      "accuracy: 0.5847589424572317\n",
      "accuracy: 0.640746500777605\n",
      "accuracy: 0.645412130637636\n",
      "CPU times: user 59.7 s, sys: 132 ms, total: 59.8 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = MaxentClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        algorithm='gis',\n",
    "        trace=0,\n",
    "        max_iter=10,\n",
    "        min_lldelta=0.5)\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Try Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Parameters:\n",
    "    - `binary`: whether the features are binary\n",
    "    - `entropy_cutoff`: a value used during tree refinement process (entropy=1 -> high-level uncertainty; entropy = 0 -> perfect model prediction)\n",
    "    - `depth_cutoff`: to control the depth of the tree\n",
    "    - `support_cutoff`: the mimimum number of instances that are required to make a decision about a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 28.8 ms, total: 16.4 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier.train(train_set,\n",
    "                                             binary=True,\n",
    "                                             entropy_cutoff=0.7,\n",
    "                                             depth_cutoff=5,\n",
    "                                             support_cutoff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <59.2%>  3.2% |\n",
      "  male |  24.8% <12.8%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7065217391304348\n",
      "accuracy: 0.7158385093167702\n",
      "accuracy: 0.7515527950310559\n",
      "accuracy: 0.6909937888198758\n",
      "accuracy: 0.7325038880248833\n",
      "accuracy: 0.7418351477449455\n",
      "accuracy: 0.702954898911353\n",
      "accuracy: 0.6765163297045101\n",
      "accuracy: 0.7356143079315708\n",
      "accuracy: 0.713841368584759\n",
      "CPU times: user 2min 39s, sys: 301 ms, total: 2min 40s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = DecisionTreeClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        binary=True,\n",
    "        entropy_cutoff=0.7,\n",
    "        depth_cutoff=5,\n",
    "        support_cutoff=5)\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Try `sklearn` Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` is a very useful module for machine learning. We will talk more about this module in our later lectures.\n",
    "- This package provides a lot more ML algorithms for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Naive Bayes in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB())>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "sk_classifier = SklearnClassifier(MultinomialNB())\n",
    "sk_classifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.742"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Logistic Regression in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.774"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_classifier = SklearnClassifier(LogisticRegression(max_iter=500))\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Support Vector Machine in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` provides several implementations for Support Vector Machines.\n",
    "- Please see its documentation for more detail: [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sk_classifier = SklearnClassifier(SVC())\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "sk_classifier = SklearnClassifier(LinearSVC(max_iter=2000))\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "sk_classifier = SklearnClassifier(NuSVC())\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- NLTK Book, [Chapter 6 Learning to Classify Texts](https://www.nltk.org/book/ch06.html)\n",
    "- Géron (2019), Chapter 3 Classification"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}