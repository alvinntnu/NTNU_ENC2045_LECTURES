

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Neural Language Model: A Start &#8212; ENC2045 Computational Linguistics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nlp/dl-neural-language-model-primer';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Word Embeddings" href="text-vec-embedding.html" />
    <link rel="prev" title="Sequence Models Intuition" href="dl-sequence-models-intuition.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/ntnu-word-2.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/ntnu-word-2.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">INTRODUCTION</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="nlp-primer.html">Natural Language Processing: A Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-pipeline.html">NLP Pipeline</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Preprocessing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="text-preprocessing.html">Text Preprocessing</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="text-normalization-eng.html">Text Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-tokenization.html">Text Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-enrichment.html">Text Enrichment</a></li>
<li class="toctree-l2"><a class="reference internal" href="chinese-word-seg.html">Chinese Word Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="google-colab.html">Google Colab</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Vectorization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="text-vec-traditional.html">Text Vectorization Using Traditional Methods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml-overview.html">Machine Learning: Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-simple-case.html">Machine Learning: A Simple Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-algorithm.html">Classification Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine-Learning NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml-common-nlp-tasks.html">Common NLP Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-sklearn-classification.html">Sentiment Analysis Using Bag-of-Words</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-emsemble-learning.html">Emsemble Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="topic-modeling-naive.html">Topic Modeling: A Naive Example</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-neural-network-from-scratch.html">Neural Network From Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-simple-case.html">Deep Learning: A Simple Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-sentiment-case.html">Deep Learning: Sentiment Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Language Model and Embeddings</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-sequence-models-intuition.html">Sequence Models Intuition</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Neural Language Model: A Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="text-vec-embedding.html">Word Embeddings</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequence Models, Attention, Transformers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-attention-transformer-intuition.html">Attention and Transformers: Intuitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-seq-to-seq-attention-addition.html">Sequence Model with Attention for Addition Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-transformers-keras.html">Sentiment Classification with Transformer (Self-Study)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="langchain-llm-intro.html">Large Language Model (Under Construction…)</a></li>
<li class="toctree-l1"><a class="reference internal" href="langchain-introduction.html">Langchain: An Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="langchain-youtube.html">LangChain Application: YouTube Summary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercise/1-python-basics.html">1. Assignment I: Python Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/2-preprocessing.html">2. Assignment II: Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/3-chinese-nlp.html">3. Assignment III: Chinese Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/4-text-vectorization.html">4. Assignment IV: Text Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/5-machine-learning.html">5. Assignment V: Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/6-topic-modeling.html">6. Assignment VI: Topic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/7-dl-chinese-name-gender.html">7. Assignment VII: Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/8-sentiment-analysis-dl.html">8. Assignment VIII: Sentiment Analysis Using Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/9-neural-language-model.html">9. Assignment IV: Neural Language Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exams</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercise/final-exam-112.html">Final Exam</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/nlp/dl-neural-language-model-primer.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nlp/dl-neural-language-model-primer.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Language Model: A Start</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflow-of-neural-language-model">Workflow of Neural Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigram-model">Bigram Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization">Tokenization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-to-sequences-and-training-testing-sets">Text-to-Sequences and Training-Testing Sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-representation-of-the-next-word">One-hot Representation of the Next-Word</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-rnn-language-model">Define RNN Language Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-using-the-model">Text Generation Using the Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-strategies-for-text-generation">Sampling Strategies for Text Generation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beam-search-skipped">Beam Search (skipped)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#searching-in-nlp">Searching in NLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#beam-search-decoding">Beam Search Decoding</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-language-model-a-start">
<h1>Neural Language Model: A Start<a class="headerlink" href="#neural-language-model-a-start" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p>In this tutorial, we will look at a naive example of <strong>neural language model</strong>.</p></li>
<li><p>Given a corpus, we can build a neural language model, which will learn to predict the next word given a specified limited context.</p></li>
</ul>
<ul class="simple">
<li><p>Depending on the size of the <strong>limited context</strong>, we can implement different types of neural language model:</p>
<ul>
<li><p><strong>Bigram</strong>-based neural language model: The model uses one preceding word for the next-word prediction.</p></li>
<li><p><strong>Trigram</strong>-based neural language model: The model uses two preceding words for the next-word prediction.</p></li>
<li><p><strong>Line</strong>-based neural language model: The model uses all the existing fore-going words in the “sequence” for the next-word prediction.</p></li>
<li><p><strong>Discourse</strong>-based neural language model: The model uses inter-sentential information for next-word prediction (e.g., BERT).</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>This tutorial will demonstarte how to build a bigram-based language model.</p></li>
<li><p>In the Assignments, you need to extend the same rationale to other types of language models.</p></li>
</ul>
<section id="workflow-of-neural-language-model">
<h2>Workflow of Neural Language Model<a class="headerlink" href="#workflow-of-neural-language-model" title="Permalink to this headline">#</a></h2>
<p><img alt="" src="../_images/neural-language-model-flowchart.png" /></p>
<div class="dropdown admonition seealso">
<p class="admonition-title">See also</p>
<p>We frequently encounter the need to train models on large datasets, which can be memory-intensive and difficult to load entirely into the local machine’s memory at once. Therefore, it’s essential to master techniques for optimizing the data loading process during model training.</p>
<p>Tensorflow provides an effective Dataset API for this. Using TensorFlow Dataset API involves several steps to create and manipulate datasets efficiently. Here’s a step-by-step guide:</p>
<ol class="arabic">
<li><p><strong>Import TensorFlow:</strong>
Make sure you have TensorFlow installed and import it into your Python script or notebook.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</li>
<li><p><strong>Create Dataset from Data:</strong>
There are different ways to create a dataset, such as from a list, NumPy array, tensors, or files.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># From a list</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>

<span class="c1"># From a NumPy array</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="c1"># From tensors</span>
<span class="n">tensor1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensors</span><span class="p">((</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">))</span>

<span class="c1"># From files</span>
<span class="n">file_paths</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;file1.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;file2.txt&#39;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TextLineDataset</span><span class="p">(</span><span class="n">file_paths</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Transformations:</strong>
Apply transformations to the dataset using methods like <code class="docutils literal notranslate"><span class="pre">map()</span></code>, <code class="docutils literal notranslate"><span class="pre">filter()</span></code>, <code class="docutils literal notranslate"><span class="pre">batch()</span></code>, <code class="docutils literal notranslate"><span class="pre">shuffle()</span></code>, etc.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Map a function to each element</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Filter elements</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Batch elements</span>
<span class="n">batched_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Shuffle elements</span>
<span class="n">shuffled_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Repeat dataset</span>
<span class="n">repeated_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">count</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Iterate Over the Dataset:</strong>
Use a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop or iterator to iterate over the dataset and process the elements.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

<span class="c1"># If you need to batch the dataset first</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched_dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Use in Model Training:</strong>
Pass the dataset directly to the model’s <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Performance Optimization:</strong>
For better performance, consider using prefetching, caching, and parallelism.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Handling Complex Data:</strong>
For more complex data processing, you can use <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> to apply Python functions to each element of the dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Your custom Python code here</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">my_function</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ol>
<p>These are the basic steps to use TensorFlow Dataset API effectively. Adjustments can be made based on the specific requirements of your project and the characteristics of your data.</p>
</div>
</section>
<section id="bigram-model">
<h2>Bigram Model<a class="headerlink" href="#bigram-model" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>A bigram-based language model assumes that the next word (to be predicted) depends only on one preceding word.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Dependencies</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span><span class="p">,</span> <span class="n">plot_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Embedding</span>
</pre></div>
</div>
</div>
</div>
<section id="tokenization">
<h3>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>A quick reminder of important parameters for <code class="docutils literal notranslate"><span class="pre">Tokenzier()</span></code>:</p>
<ul>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">num_words</span></code></strong>: the maximum number of words to keep, based on word frequency. Only the most common <code class="docutils literal notranslate"><span class="pre">num_words-1</span></code> words will be kept.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">filters</span></code></strong>: a string where each element is a character that will be filtered from the texts. The default includes all punctuations, plus tabs and line breaks (except for the <code class="docutils literal notranslate"><span class="pre">'</span></code> character).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">lower</span></code></strong>: boolean. Whether to convert the texts to lowercase.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">split</span></code></strong>: string. Separator for word splitting.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">char_level</span></code></strong>: if True, every character will be treated as a token.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">oov_token</span></code></strong>: if given, it will be added to <code class="docutils literal notranslate"><span class="pre">word_index</span></code> and used to replace out-of-vocabulary words during <code class="docutils literal notranslate"><span class="pre">text_to_sequence</span></code> calls</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># source text</span>
<span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot; Jack and Jill went up the hill</span><span class="se">\n</span>
<span class="s2">		To fetch a pail of water</span><span class="se">\n</span>
<span class="s2">		Jack fell down and broke his crown</span><span class="se">\n</span>
<span class="s2">		And Jill came tumbling after</span><span class="se">\n</span><span class="s2"> &quot;&quot;&quot;</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">]</span>

<span class="c1"># integer encode text</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># now the data consists of a sequence of word index integers</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># determine the vocabulary size</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vocabulary Size: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vocabulary Size: 22
{&#39;and&#39;: 1, &#39;jack&#39;: 2, &#39;jill&#39;: 3, &#39;went&#39;: 4, &#39;up&#39;: 5, &#39;the&#39;: 6, &#39;hill&#39;: 7, &#39;to&#39;: 8, &#39;fetch&#39;: 9, &#39;a&#39;: 10, &#39;pail&#39;: 11, &#39;of&#39;: 12, &#39;water&#39;: 13, &#39;fell&#39;: 14, &#39;down&#39;: 15, &#39;broke&#39;: 16, &#39;his&#39;: 17, &#39;crown&#39;: 18, &#39;came&#39;: 19, &#39;tumbling&#39;: 20, &#39;after&#39;: 21}
</pre></div>
</div>
</div>
</div>
</section>
<section id="text-to-sequences-and-training-testing-sets">
<h3>Text-to-Sequences and Training-Testing Sets<a class="headerlink" href="#text-to-sequences-and-training-testing-sets" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Principles for bigrams extraction</p>
<ul>
<li><p>When we create bigrams as the input sequences for network training, we need to make sure that we do not include <strong>unmeaningful</strong> bigrams, such as bigrams spanning the text boundaries, or sentence boundaries.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create bigrams sequences</span>

<span class="c1">## bigrams holder</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>


<span class="c1">## Extract bigrams from each text</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">)):</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="n">e</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Sequences: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Sequences: 21
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequences</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[2, 1],
       [1, 3],
       [3, 4],
       [4, 5],
       [5, 6]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>A sequence contains both our input and also output of the network.</p></li>
<li><p>That is, for bigram-based LM, the first word is the input <em>X</em> and the second word is the expected output <em>y</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># split into X and y elements</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sequences</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[2 1]
 [1 3]
 [3 4]
 [4 5]
 [5 6]]
[2 1 3 4 5]
[1 3 4 5 6]
</pre></div>
</div>
</div>
</div>
</section>
<section id="one-hot-representation-of-the-next-word">
<h3>One-hot Representation of the Next-Word<a class="headerlink" href="#one-hot-representation-of-the-next-word" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Because the neural language model is going to be a multi-class classifier (for word prediction), we need to convert our <code class="docutils literal notranslate"><span class="pre">y</span></code> into one-hot encoding.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># one hot encode outputs</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(21, 22)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-rnn-language-model">
<h3>Define RNN Language Model<a class="headerlink" href="#define-rnn-language-model" title="Permalink to this headline">#</a></h3>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>  <span class="c1"># LSTM Complexity</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 1, 16)             352       
                                                                 
 lstm (LSTM)                 (None, 64)                20736     
                                                                 
 dense (Dense)               (None, 22)                1430      
                                                                 
=================================================================
Total params: 22518 (87.96 KB)
Trainable params: 22518 (87.96 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
None
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compile network</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># fit network</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/500
1/1 - 1s - loss: 3.0912 - accuracy: 0.0000e+00 - 559ms/epoch - 559ms/step
Epoch 2/500
1/1 - 0s - loss: 3.0901 - accuracy: 0.0000e+00 - 2ms/epoch - 2ms/step
Epoch 3/500
1/1 - 0s - loss: 3.0890 - accuracy: 0.0000e+00 - 2ms/epoch - 2ms/step
Epoch 4/500
1/1 - 0s - loss: 3.0879 - accuracy: 0.0952 - 2ms/epoch - 2ms/step
Epoch 5/500
1/1 - 0s - loss: 3.0868 - accuracy: 0.0952 - 2ms/epoch - 2ms/step
Epoch 6/500
1/1 - 0s - loss: 3.0857 - accuracy: 0.1429 - 2ms/epoch - 2ms/step
Epoch 7/500
1/1 - 0s - loss: 3.0846 - accuracy: 0.2857 - 2ms/epoch - 2ms/step
Epoch 8/500
1/1 - 0s - loss: 3.0835 - accuracy: 0.3333 - 2ms/epoch - 2ms/step
Epoch 9/500
1/1 - 0s - loss: 3.0823 - accuracy: 0.4286 - 2ms/epoch - 2ms/step
Epoch 10/500
1/1 - 0s - loss: 3.0812 - accuracy: 0.4286 - 2ms/epoch - 2ms/step
Epoch 11/500
1/1 - 0s - loss: 3.0800 - accuracy: 0.3810 - 2ms/epoch - 2ms/step
Epoch 12/500
1/1 - 0s - loss: 3.0788 - accuracy: 0.3810 - 2ms/epoch - 2ms/step
Epoch 13/500
1/1 - 0s - loss: 3.0776 - accuracy: 0.4286 - 2ms/epoch - 2ms/step
Epoch 14/500
1/1 - 0s - loss: 3.0764 - accuracy: 0.4286 - 2ms/epoch - 2ms/step
Epoch 15/500
1/1 - 0s - loss: 3.0751 - accuracy: 0.4286 - 2ms/epoch - 2ms/step
Epoch 16/500
1/1 - 0s - loss: 3.0738 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 17/500
1/1 - 0s - loss: 3.0725 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 18/500
1/1 - 0s - loss: 3.0711 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 19/500
1/1 - 0s - loss: 3.0697 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 20/500
1/1 - 0s - loss: 3.0683 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 21/500
1/1 - 0s - loss: 3.0668 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 22/500
1/1 - 0s - loss: 3.0653 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 23/500
1/1 - 0s - loss: 3.0637 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 24/500
1/1 - 0s - loss: 3.0621 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 25/500
1/1 - 0s - loss: 3.0605 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 26/500
1/1 - 0s - loss: 3.0588 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 27/500
1/1 - 0s - loss: 3.0570 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 28/500
1/1 - 0s - loss: 3.0552 - accuracy: 0.5714 - 5ms/epoch - 5ms/step
Epoch 29/500
1/1 - 0s - loss: 3.0533 - accuracy: 0.5714 - 3ms/epoch - 3ms/step
Epoch 30/500
1/1 - 0s - loss: 3.0514 - accuracy: 0.5714 - 4ms/epoch - 4ms/step
Epoch 31/500
1/1 - 0s - loss: 3.0494 - accuracy: 0.4762 - 3ms/epoch - 3ms/step
Epoch 32/500
1/1 - 0s - loss: 3.0473 - accuracy: 0.4762 - 4ms/epoch - 4ms/step
Epoch 33/500
1/1 - 0s - loss: 3.0452 - accuracy: 0.4762 - 4ms/epoch - 4ms/step
Epoch 34/500
1/1 - 0s - loss: 3.0430 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 35/500
1/1 - 0s - loss: 3.0407 - accuracy: 0.4762 - 4ms/epoch - 4ms/step
Epoch 36/500
1/1 - 0s - loss: 3.0383 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 37/500
1/1 - 0s - loss: 3.0359 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 38/500
1/1 - 0s - loss: 3.0334 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 39/500
1/1 - 0s - loss: 3.0308 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 40/500
1/1 - 0s - loss: 3.0281 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 41/500
1/1 - 0s - loss: 3.0253 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 42/500
1/1 - 0s - loss: 3.0224 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 43/500
1/1 - 0s - loss: 3.0194 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 44/500
1/1 - 0s - loss: 3.0163 - accuracy: 0.4762 - 1ms/epoch - 1ms/step
Epoch 45/500
1/1 - 0s - loss: 3.0131 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 46/500
1/1 - 0s - loss: 3.0099 - accuracy: 0.4762 - 1ms/epoch - 1ms/step
Epoch 47/500
1/1 - 0s - loss: 3.0065 - accuracy: 0.4762 - 1ms/epoch - 1ms/step
Epoch 48/500
1/1 - 0s - loss: 3.0029 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 49/500
1/1 - 0s - loss: 2.9993 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 50/500
1/1 - 0s - loss: 2.9955 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 51/500
1/1 - 0s - loss: 2.9917 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 52/500
1/1 - 0s - loss: 2.9876 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 53/500
1/1 - 0s - loss: 2.9835 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 54/500
1/1 - 0s - loss: 2.9792 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 55/500
1/1 - 0s - loss: 2.9748 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 56/500
1/1 - 0s - loss: 2.9702 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 57/500
1/1 - 0s - loss: 2.9655 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 58/500
1/1 - 0s - loss: 2.9606 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 59/500
1/1 - 0s - loss: 2.9556 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 60/500
1/1 - 0s - loss: 2.9504 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 61/500
1/1 - 0s - loss: 2.9450 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 62/500
1/1 - 0s - loss: 2.9395 - accuracy: 0.4762 - 2ms/epoch - 2ms/step
Epoch 63/500
1/1 - 0s - loss: 2.9338 - accuracy: 0.4762 - 1ms/epoch - 1ms/step
Epoch 64/500
1/1 - 0s - loss: 2.9279 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 65/500
1/1 - 0s - loss: 2.9218 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 66/500
1/1 - 0s - loss: 2.9155 - accuracy: 0.5238 - 1ms/epoch - 1ms/step
Epoch 67/500
1/1 - 0s - loss: 2.9091 - accuracy: 0.5238 - 1ms/epoch - 1ms/step
Epoch 68/500
1/1 - 0s - loss: 2.9024 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 69/500
1/1 - 0s - loss: 2.8956 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 70/500
1/1 - 0s - loss: 2.8885 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 71/500
1/1 - 0s - loss: 2.8812 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 72/500
1/1 - 0s - loss: 2.8737 - accuracy: 0.5238 - 1ms/epoch - 1ms/step
Epoch 73/500
1/1 - 0s - loss: 2.8660 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 74/500
1/1 - 0s - loss: 2.8580 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 75/500
1/1 - 0s - loss: 2.8498 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 76/500
1/1 - 0s - loss: 2.8414 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 77/500
1/1 - 0s - loss: 2.8328 - accuracy: 0.5238 - 2ms/epoch - 2ms/step
Epoch 78/500
1/1 - 0s - loss: 2.8239 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 79/500
1/1 - 0s - loss: 2.8147 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 80/500
1/1 - 0s - loss: 2.8053 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 81/500
1/1 - 0s - loss: 2.7956 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 82/500
1/1 - 0s - loss: 2.7857 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 83/500
1/1 - 0s - loss: 2.7755 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 84/500
1/1 - 0s - loss: 2.7650 - accuracy: 0.5714 - 2ms/epoch - 2ms/step
Epoch 85/500
1/1 - 0s - loss: 2.7543 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 86/500
1/1 - 0s - loss: 2.7433 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 87/500
1/1 - 0s - loss: 2.7320 - accuracy: 0.6190 - 3ms/epoch - 3ms/step
Epoch 88/500
1/1 - 0s - loss: 2.7204 - accuracy: 0.6190 - 3ms/epoch - 3ms/step
Epoch 89/500
1/1 - 0s - loss: 2.7086 - accuracy: 0.6190 - 4ms/epoch - 4ms/step
Epoch 90/500
1/1 - 0s - loss: 2.6965 - accuracy: 0.6190 - 3ms/epoch - 3ms/step
Epoch 91/500
1/1 - 0s - loss: 2.6840 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 92/500
1/1 - 0s - loss: 2.6713 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 93/500
1/1 - 0s - loss: 2.6584 - accuracy: 0.6190 - 3ms/epoch - 3ms/step
Epoch 94/500
1/1 - 0s - loss: 2.6451 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 95/500
1/1 - 0s - loss: 2.6315 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 96/500
1/1 - 0s - loss: 2.6177 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 97/500
1/1 - 0s - loss: 2.6036 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 98/500
1/1 - 0s - loss: 2.5892 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 99/500
1/1 - 0s - loss: 2.5745 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 100/500
1/1 - 0s - loss: 2.5595 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 101/500
1/1 - 0s - loss: 2.5443 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 102/500
1/1 - 0s - loss: 2.5288 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 103/500
1/1 - 0s - loss: 2.5130 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 104/500
1/1 - 0s - loss: 2.4970 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 105/500
1/1 - 0s - loss: 2.4807 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 106/500
1/1 - 0s - loss: 2.4642 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 107/500
1/1 - 0s - loss: 2.4475 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 108/500
1/1 - 0s - loss: 2.4305 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 109/500
1/1 - 0s - loss: 2.4133 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 110/500
1/1 - 0s - loss: 2.3958 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 111/500
1/1 - 0s - loss: 2.3782 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 112/500
1/1 - 0s - loss: 2.3604 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 113/500
1/1 - 0s - loss: 2.3424 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 114/500
1/1 - 0s - loss: 2.3242 - accuracy: 0.6190 - 1ms/epoch - 1ms/step
Epoch 115/500
1/1 - 0s - loss: 2.3058 - accuracy: 0.6190 - 2ms/epoch - 2ms/step
Epoch 116/500
1/1 - 0s - loss: 2.2873 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 117/500
1/1 - 0s - loss: 2.2686 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 118/500
1/1 - 0s - loss: 2.2498 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 119/500
1/1 - 0s - loss: 2.2309 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 120/500
1/1 - 0s - loss: 2.2119 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 121/500
1/1 - 0s - loss: 2.1928 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 122/500
1/1 - 0s - loss: 2.1735 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 123/500
1/1 - 0s - loss: 2.1542 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 124/500
1/1 - 0s - loss: 2.1349 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 125/500
1/1 - 0s - loss: 2.1154 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 126/500
1/1 - 0s - loss: 2.0959 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 127/500
1/1 - 0s - loss: 2.0764 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 128/500
1/1 - 0s - loss: 2.0569 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 129/500
1/1 - 0s - loss: 2.0373 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 130/500
1/1 - 0s - loss: 2.0177 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 131/500
1/1 - 0s - loss: 1.9981 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 132/500
1/1 - 0s - loss: 1.9786 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 133/500
1/1 - 0s - loss: 1.9590 - accuracy: 0.6667 - 2ms/epoch - 2ms/step
Epoch 134/500
1/1 - 0s - loss: 1.9394 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 135/500
1/1 - 0s - loss: 1.9199 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 136/500
1/1 - 0s - loss: 1.9003 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 137/500
1/1 - 0s - loss: 1.8809 - accuracy: 0.6667 - 1ms/epoch - 1ms/step
Epoch 138/500
1/1 - 0s - loss: 1.8614 - accuracy: 0.7619 - 2ms/epoch - 2ms/step
Epoch 139/500
1/1 - 0s - loss: 1.8420 - accuracy: 0.7619 - 1ms/epoch - 1ms/step
Epoch 140/500
1/1 - 0s - loss: 1.8226 - accuracy: 0.7619 - 2ms/epoch - 2ms/step
Epoch 141/500
1/1 - 0s - loss: 1.8032 - accuracy: 0.7619 - 1ms/epoch - 1ms/step
Epoch 142/500
1/1 - 0s - loss: 1.7839 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 143/500
1/1 - 0s - loss: 1.7647 - accuracy: 0.8095 - 4ms/epoch - 4ms/step
Epoch 144/500
1/1 - 0s - loss: 1.7455 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 145/500
1/1 - 0s - loss: 1.7263 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 146/500
1/1 - 0s - loss: 1.7072 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 147/500
1/1 - 0s - loss: 1.6882 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 148/500
1/1 - 0s - loss: 1.6691 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 149/500
1/1 - 0s - loss: 1.6502 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 150/500
1/1 - 0s - loss: 1.6313 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 151/500
1/1 - 0s - loss: 1.6124 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 152/500
1/1 - 0s - loss: 1.5936 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 153/500
1/1 - 0s - loss: 1.5749 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 154/500
1/1 - 0s - loss: 1.5562 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 155/500
1/1 - 0s - loss: 1.5376 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 156/500
1/1 - 0s - loss: 1.5190 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 157/500
1/1 - 0s - loss: 1.5005 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 158/500
1/1 - 0s - loss: 1.4821 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 159/500
1/1 - 0s - loss: 1.4637 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 160/500
1/1 - 0s - loss: 1.4454 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 161/500
1/1 - 0s - loss: 1.4271 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 162/500
1/1 - 0s - loss: 1.4090 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 163/500
1/1 - 0s - loss: 1.3909 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 164/500
1/1 - 0s - loss: 1.3729 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 165/500
1/1 - 0s - loss: 1.3549 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 166/500
1/1 - 0s - loss: 1.3371 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 167/500
1/1 - 0s - loss: 1.3193 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 168/500
1/1 - 0s - loss: 1.3017 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 169/500
1/1 - 0s - loss: 1.2841 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 170/500
1/1 - 0s - loss: 1.2667 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 171/500
1/1 - 0s - loss: 1.2493 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 172/500
1/1 - 0s - loss: 1.2321 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 173/500
1/1 - 0s - loss: 1.2150 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 174/500
1/1 - 0s - loss: 1.1980 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 175/500
1/1 - 0s - loss: 1.1811 - accuracy: 0.8095 - 3ms/epoch - 3ms/step
Epoch 176/500
1/1 - 0s - loss: 1.1643 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 177/500
1/1 - 0s - loss: 1.1477 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 178/500
1/1 - 0s - loss: 1.1313 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 179/500
1/1 - 0s - loss: 1.1150 - accuracy: 0.8095 - 2ms/epoch - 2ms/step
Epoch 180/500
1/1 - 0s - loss: 1.0988 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 181/500
1/1 - 0s - loss: 1.0828 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 182/500
1/1 - 0s - loss: 1.0669 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 183/500
1/1 - 0s - loss: 1.0512 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 184/500
1/1 - 0s - loss: 1.0357 - accuracy: 0.8095 - 1ms/epoch - 1ms/step
Epoch 185/500
1/1 - 0s - loss: 1.0204 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 186/500
1/1 - 0s - loss: 1.0052 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 187/500
1/1 - 0s - loss: 0.9902 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 188/500
1/1 - 0s - loss: 0.9754 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 189/500
1/1 - 0s - loss: 0.9608 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 190/500
1/1 - 0s - loss: 0.9464 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 191/500
1/1 - 0s - loss: 0.9321 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 192/500
1/1 - 0s - loss: 0.9181 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 193/500
1/1 - 0s - loss: 0.9043 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 194/500
1/1 - 0s - loss: 0.8906 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 195/500
1/1 - 0s - loss: 0.8772 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 196/500
1/1 - 0s - loss: 0.8640 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 197/500
1/1 - 0s - loss: 0.8510 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 198/500
1/1 - 0s - loss: 0.8382 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 199/500
1/1 - 0s - loss: 0.8256 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 200/500
1/1 - 0s - loss: 0.8132 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 201/500
1/1 - 0s - loss: 0.8011 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 202/500
1/1 - 0s - loss: 0.7892 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 203/500
1/1 - 0s - loss: 0.7774 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 204/500
1/1 - 0s - loss: 0.7659 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 205/500
1/1 - 0s - loss: 0.7546 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 206/500
1/1 - 0s - loss: 0.7435 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 207/500
1/1 - 0s - loss: 0.7327 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 208/500
1/1 - 0s - loss: 0.7220 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 209/500
1/1 - 0s - loss: 0.7116 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 210/500
1/1 - 0s - loss: 0.7013 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 211/500
1/1 - 0s - loss: 0.6913 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 212/500
1/1 - 0s - loss: 0.6815 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 213/500
1/1 - 0s - loss: 0.6719 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 214/500
1/1 - 0s - loss: 0.6625 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 215/500
1/1 - 0s - loss: 0.6533 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 216/500
1/1 - 0s - loss: 0.6443 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 217/500
1/1 - 0s - loss: 0.6355 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 218/500
1/1 - 0s - loss: 0.6269 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 219/500
1/1 - 0s - loss: 0.6184 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 220/500
1/1 - 0s - loss: 0.6102 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 221/500
1/1 - 0s - loss: 0.6022 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 222/500
1/1 - 0s - loss: 0.5943 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 223/500
1/1 - 0s - loss: 0.5866 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 224/500
1/1 - 0s - loss: 0.5791 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 225/500
1/1 - 0s - loss: 0.5718 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 226/500
1/1 - 0s - loss: 0.5647 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 227/500
1/1 - 0s - loss: 0.5577 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 228/500
1/1 - 0s - loss: 0.5509 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 229/500
1/1 - 0s - loss: 0.5442 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 230/500
1/1 - 0s - loss: 0.5378 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 231/500
1/1 - 0s - loss: 0.5314 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 232/500
1/1 - 0s - loss: 0.5253 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 233/500
1/1 - 0s - loss: 0.5192 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 234/500
1/1 - 0s - loss: 0.5134 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 235/500
1/1 - 0s - loss: 0.5076 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 236/500
1/1 - 0s - loss: 0.5020 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 237/500
1/1 - 0s - loss: 0.4966 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 238/500
1/1 - 0s - loss: 0.4913 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 239/500
1/1 - 0s - loss: 0.4861 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 240/500
1/1 - 0s - loss: 0.4810 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 241/500
1/1 - 0s - loss: 0.4761 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 242/500
1/1 - 0s - loss: 0.4713 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 243/500
1/1 - 0s - loss: 0.4666 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 244/500
1/1 - 0s - loss: 0.4620 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 245/500
1/1 - 0s - loss: 0.4576 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 246/500
1/1 - 0s - loss: 0.4532 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 247/500
1/1 - 0s - loss: 0.4490 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 248/500
1/1 - 0s - loss: 0.4449 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 249/500
1/1 - 0s - loss: 0.4409 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 250/500
1/1 - 0s - loss: 0.4369 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 251/500
1/1 - 0s - loss: 0.4331 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 252/500
1/1 - 0s - loss: 0.4294 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 253/500
1/1 - 0s - loss: 0.4257 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 254/500
1/1 - 0s - loss: 0.4222 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 255/500
1/1 - 0s - loss: 0.4187 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 256/500
1/1 - 0s - loss: 0.4154 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 257/500
1/1 - 0s - loss: 0.4121 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 258/500
1/1 - 0s - loss: 0.4089 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 259/500
1/1 - 0s - loss: 0.4058 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 260/500
1/1 - 0s - loss: 0.4027 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 261/500
1/1 - 0s - loss: 0.3997 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 262/500
1/1 - 0s - loss: 0.3968 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 263/500
1/1 - 0s - loss: 0.3940 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 264/500
1/1 - 0s - loss: 0.3912 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 265/500
1/1 - 0s - loss: 0.3885 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 266/500
1/1 - 0s - loss: 0.3859 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 267/500
1/1 - 0s - loss: 0.3833 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 268/500
1/1 - 0s - loss: 0.3808 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 269/500
1/1 - 0s - loss: 0.3784 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 270/500
1/1 - 0s - loss: 0.3760 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 271/500
1/1 - 0s - loss: 0.3736 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 272/500
1/1 - 0s - loss: 0.3713 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 273/500
1/1 - 0s - loss: 0.3691 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 274/500
1/1 - 0s - loss: 0.3669 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 275/500
1/1 - 0s - loss: 0.3648 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 276/500
1/1 - 0s - loss: 0.3627 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 277/500
1/1 - 0s - loss: 0.3607 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 278/500
1/1 - 0s - loss: 0.3587 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 279/500
1/1 - 0s - loss: 0.3568 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 280/500
1/1 - 0s - loss: 0.3549 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 281/500
1/1 - 0s - loss: 0.3530 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 282/500
1/1 - 0s - loss: 0.3512 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 283/500
1/1 - 0s - loss: 0.3494 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 284/500
1/1 - 0s - loss: 0.3476 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 285/500
1/1 - 0s - loss: 0.3459 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 286/500
1/1 - 0s - loss: 0.3443 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 287/500
1/1 - 0s - loss: 0.3426 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 288/500
1/1 - 0s - loss: 0.3410 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 289/500
1/1 - 0s - loss: 0.3395 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 290/500
1/1 - 0s - loss: 0.3379 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 291/500
1/1 - 0s - loss: 0.3364 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 292/500
1/1 - 0s - loss: 0.3349 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 293/500
1/1 - 0s - loss: 0.3335 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 294/500
1/1 - 0s - loss: 0.3321 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 295/500
1/1 - 0s - loss: 0.3307 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 296/500
1/1 - 0s - loss: 0.3293 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 297/500
1/1 - 0s - loss: 0.3280 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 298/500
1/1 - 0s - loss: 0.3267 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 299/500
1/1 - 0s - loss: 0.3254 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 300/500
1/1 - 0s - loss: 0.3241 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 301/500
1/1 - 0s - loss: 0.3229 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 302/500
1/1 - 0s - loss: 0.3217 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 303/500
1/1 - 0s - loss: 0.3205 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 304/500
1/1 - 0s - loss: 0.3193 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 305/500
1/1 - 0s - loss: 0.3181 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 306/500
1/1 - 0s - loss: 0.3170 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 307/500
1/1 - 0s - loss: 0.3159 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 308/500
1/1 - 0s - loss: 0.3148 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 309/500
1/1 - 0s - loss: 0.3137 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 310/500
1/1 - 0s - loss: 0.3127 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 311/500
1/1 - 0s - loss: 0.3116 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 312/500
1/1 - 0s - loss: 0.3106 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 313/500
1/1 - 0s - loss: 0.3096 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 314/500
1/1 - 0s - loss: 0.3086 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 315/500
1/1 - 0s - loss: 0.3076 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 316/500
1/1 - 0s - loss: 0.3066 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 317/500
1/1 - 0s - loss: 0.3057 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 318/500
1/1 - 0s - loss: 0.3048 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 319/500
1/1 - 0s - loss: 0.3038 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 320/500
1/1 - 0s - loss: 0.3029 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 321/500
1/1 - 0s - loss: 0.3021 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 322/500
1/1 - 0s - loss: 0.3012 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 323/500
1/1 - 0s - loss: 0.3003 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 324/500
1/1 - 0s - loss: 0.2995 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 325/500
1/1 - 0s - loss: 0.2986 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 326/500
1/1 - 0s - loss: 0.2978 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 327/500
1/1 - 0s - loss: 0.2970 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 328/500
1/1 - 0s - loss: 0.2962 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 329/500
1/1 - 0s - loss: 0.2954 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 330/500
1/1 - 0s - loss: 0.2946 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 331/500
1/1 - 0s - loss: 0.2938 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 332/500
1/1 - 0s - loss: 0.2931 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 333/500
1/1 - 0s - loss: 0.2923 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 334/500
1/1 - 0s - loss: 0.2916 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 335/500
1/1 - 0s - loss: 0.2908 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 336/500
1/1 - 0s - loss: 0.2901 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 337/500
1/1 - 0s - loss: 0.2894 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 338/500
1/1 - 0s - loss: 0.2887 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 339/500
1/1 - 0s - loss: 0.2880 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 340/500
1/1 - 0s - loss: 0.2873 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 341/500
1/1 - 0s - loss: 0.2866 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 342/500
1/1 - 0s - loss: 0.2860 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 343/500
1/1 - 0s - loss: 0.2853 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 344/500
1/1 - 0s - loss: 0.2847 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 345/500
1/1 - 0s - loss: 0.2840 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 346/500
1/1 - 0s - loss: 0.2834 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 347/500
1/1 - 0s - loss: 0.2828 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 348/500
1/1 - 0s - loss: 0.2822 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 349/500
1/1 - 0s - loss: 0.2815 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 350/500
1/1 - 0s - loss: 0.2809 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 351/500
1/1 - 0s - loss: 0.2803 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 352/500
1/1 - 0s - loss: 0.2798 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 353/500
1/1 - 0s - loss: 0.2792 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 354/500
1/1 - 0s - loss: 0.2786 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 355/500
1/1 - 0s - loss: 0.2780 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 356/500
1/1 - 0s - loss: 0.2775 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 357/500
1/1 - 0s - loss: 0.2769 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 358/500
1/1 - 0s - loss: 0.2764 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 359/500
1/1 - 0s - loss: 0.2758 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 360/500
1/1 - 0s - loss: 0.2753 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 361/500
1/1 - 0s - loss: 0.2748 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 362/500
1/1 - 0s - loss: 0.2743 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 363/500
1/1 - 0s - loss: 0.2737 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 364/500
1/1 - 0s - loss: 0.2732 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 365/500
1/1 - 0s - loss: 0.2727 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 366/500
1/1 - 0s - loss: 0.2722 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 367/500
1/1 - 0s - loss: 0.2718 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 368/500
1/1 - 0s - loss: 0.2713 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 369/500
1/1 - 0s - loss: 0.2708 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 370/500
1/1 - 0s - loss: 0.2703 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 371/500
1/1 - 0s - loss: 0.2699 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 372/500
1/1 - 0s - loss: 0.2694 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 373/500
1/1 - 0s - loss: 0.2689 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 374/500
1/1 - 0s - loss: 0.2685 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 375/500
1/1 - 0s - loss: 0.2681 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 376/500
1/1 - 0s - loss: 0.2676 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 377/500
1/1 - 0s - loss: 0.2672 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 378/500
1/1 - 0s - loss: 0.2668 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 379/500
1/1 - 0s - loss: 0.2664 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 380/500
1/1 - 0s - loss: 0.2659 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 381/500
1/1 - 0s - loss: 0.2655 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 382/500
1/1 - 0s - loss: 0.2651 - accuracy: 0.8571 - 5ms/epoch - 5ms/step
Epoch 383/500
1/1 - 0s - loss: 0.2647 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 384/500
1/1 - 0s - loss: 0.2643 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 385/500
1/1 - 0s - loss: 0.2639 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 386/500
1/1 - 0s - loss: 0.2636 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 387/500
1/1 - 0s - loss: 0.2632 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 388/500
1/1 - 0s - loss: 0.2628 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 389/500
1/1 - 0s - loss: 0.2624 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 390/500
1/1 - 0s - loss: 0.2621 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 391/500
1/1 - 0s - loss: 0.2617 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 392/500
1/1 - 0s - loss: 0.2614 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 393/500
1/1 - 0s - loss: 0.2610 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 394/500
1/1 - 0s - loss: 0.2607 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 395/500
1/1 - 0s - loss: 0.2603 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 396/500
1/1 - 0s - loss: 0.2600 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 397/500
1/1 - 0s - loss: 0.2597 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 398/500
1/1 - 0s - loss: 0.2593 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 399/500
1/1 - 0s - loss: 0.2590 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 400/500
1/1 - 0s - loss: 0.2587 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 401/500
1/1 - 0s - loss: 0.2584 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 402/500
1/1 - 0s - loss: 0.2581 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 403/500
1/1 - 0s - loss: 0.2578 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 404/500
1/1 - 0s - loss: 0.2575 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 405/500
1/1 - 0s - loss: 0.2572 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 406/500
1/1 - 0s - loss: 0.2569 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 407/500
1/1 - 0s - loss: 0.2566 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 408/500
1/1 - 0s - loss: 0.2563 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 409/500
1/1 - 0s - loss: 0.2560 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 410/500
1/1 - 0s - loss: 0.2557 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 411/500
1/1 - 0s - loss: 0.2555 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 412/500
1/1 - 0s - loss: 0.2552 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 413/500
1/1 - 0s - loss: 0.2549 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 414/500
1/1 - 0s - loss: 0.2547 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 415/500
1/1 - 0s - loss: 0.2544 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 416/500
1/1 - 0s - loss: 0.2541 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 417/500
1/1 - 0s - loss: 0.2539 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 418/500
1/1 - 0s - loss: 0.2536 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 419/500
1/1 - 0s - loss: 0.2534 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 420/500
1/1 - 0s - loss: 0.2532 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 421/500
1/1 - 0s - loss: 0.2529 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 422/500
1/1 - 0s - loss: 0.2527 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 423/500
1/1 - 0s - loss: 0.2524 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 424/500
1/1 - 0s - loss: 0.2522 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 425/500
1/1 - 0s - loss: 0.2520 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 426/500
1/1 - 0s - loss: 0.2517 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 427/500
1/1 - 0s - loss: 0.2515 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 428/500
1/1 - 0s - loss: 0.2513 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 429/500
1/1 - 0s - loss: 0.2511 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 430/500
1/1 - 0s - loss: 0.2509 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 431/500
1/1 - 0s - loss: 0.2507 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 432/500
1/1 - 0s - loss: 0.2504 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 433/500
1/1 - 0s - loss: 0.2502 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 434/500
1/1 - 0s - loss: 0.2500 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 435/500
1/1 - 0s - loss: 0.2498 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 436/500
1/1 - 0s - loss: 0.2496 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 437/500
1/1 - 0s - loss: 0.2494 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 438/500
1/1 - 0s - loss: 0.2492 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 439/500
1/1 - 0s - loss: 0.2491 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 440/500
1/1 - 0s - loss: 0.2489 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 441/500
1/1 - 0s - loss: 0.2487 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 442/500
1/1 - 0s - loss: 0.2485 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 443/500
1/1 - 0s - loss: 0.2483 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 444/500
1/1 - 0s - loss: 0.2481 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 445/500
1/1 - 0s - loss: 0.2479 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 446/500
1/1 - 0s - loss: 0.2478 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 447/500
1/1 - 0s - loss: 0.2476 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 448/500
1/1 - 0s - loss: 0.2474 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 449/500
1/1 - 0s - loss: 0.2472 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 450/500
1/1 - 0s - loss: 0.2471 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 451/500
1/1 - 0s - loss: 0.2469 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 452/500
1/1 - 0s - loss: 0.2467 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 453/500
1/1 - 0s - loss: 0.2466 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 454/500
1/1 - 0s - loss: 0.2464 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 455/500
1/1 - 0s - loss: 0.2463 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 456/500
1/1 - 0s - loss: 0.2461 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 457/500
1/1 - 0s - loss: 0.2459 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 458/500
1/1 - 0s - loss: 0.2458 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 459/500
1/1 - 0s - loss: 0.2456 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 460/500
1/1 - 0s - loss: 0.2455 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 461/500
1/1 - 0s - loss: 0.2453 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 462/500
1/1 - 0s - loss: 0.2452 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 463/500
1/1 - 0s - loss: 0.2450 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 464/500
1/1 - 0s - loss: 0.2449 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 465/500
1/1 - 0s - loss: 0.2448 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 466/500
1/1 - 0s - loss: 0.2446 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 467/500
1/1 - 0s - loss: 0.2445 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 468/500
1/1 - 0s - loss: 0.2443 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 469/500
1/1 - 0s - loss: 0.2442 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 470/500
1/1 - 0s - loss: 0.2441 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 471/500
1/1 - 0s - loss: 0.2439 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 472/500
1/1 - 0s - loss: 0.2438 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 473/500
1/1 - 0s - loss: 0.2437 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 474/500
1/1 - 0s - loss: 0.2435 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 475/500
1/1 - 0s - loss: 0.2434 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 476/500
1/1 - 0s - loss: 0.2433 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 477/500
1/1 - 0s - loss: 0.2431 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 478/500
1/1 - 0s - loss: 0.2430 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 479/500
1/1 - 0s - loss: 0.2429 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 480/500
1/1 - 0s - loss: 0.2428 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 481/500
1/1 - 0s - loss: 0.2427 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 482/500
1/1 - 0s - loss: 0.2425 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 483/500
1/1 - 0s - loss: 0.2424 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 484/500
1/1 - 0s - loss: 0.2423 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 485/500
1/1 - 0s - loss: 0.2422 - accuracy: 0.8571 - 4ms/epoch - 4ms/step
Epoch 486/500
1/1 - 0s - loss: 0.2421 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 487/500
1/1 - 0s - loss: 0.2420 - accuracy: 0.8571 - 3ms/epoch - 3ms/step
Epoch 488/500
1/1 - 0s - loss: 0.2418 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 489/500
1/1 - 0s - loss: 0.2417 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 490/500
1/1 - 0s - loss: 0.2416 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 491/500
1/1 - 0s - loss: 0.2415 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 492/500
1/1 - 0s - loss: 0.2414 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 493/500
1/1 - 0s - loss: 0.2413 - accuracy: 0.8571 - 2ms/epoch - 2ms/step
Epoch 494/500
1/1 - 0s - loss: 0.2412 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 495/500
1/1 - 0s - loss: 0.2411 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 496/500
1/1 - 0s - loss: 0.2410 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 497/500
1/1 - 0s - loss: 0.2409 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 498/500
1/1 - 0s - loss: 0.2408 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 499/500
1/1 - 0s - loss: 0.2407 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
Epoch 500/500
1/1 - 0s - loss: 0.2406 - accuracy: 0.8571 - 1ms/epoch - 1ms/step
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.src.callbacks.History at 0x16f059a90&gt;
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>  <span class="n">show_shapes</span><span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/40c64e9aadf82a97b5bfa908c6bf909dd27a35b75a699d04484f52ac766c8f42.png" src="../_images/40c64e9aadf82a97b5bfa908c6bf909dd27a35b75a699d04484f52ac766c8f42.png" />
</div>
</div>
</section>
<section id="text-generation-using-the-model">
<h3>Text Generation Using the Model<a class="headerlink" href="#text-generation-using-the-model" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>After we trained the bigram-based LM, we can use the model for text generation (e.g., a one-to-many sequence-to-sequence application).</p></li>
<li><p>We can implement a simple text generator: the model always outputs the next-word that has the highest predicted probability value from the neural LM.</p></li>
<li><p>At every time step, the model will use the newly predicted word as the input for another next-word prediction.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a sequence from the model</span>
<span class="k">def</span> <span class="nf">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seed_text</span><span class="p">,</span> <span class="n">n_words</span><span class="p">):</span>
    <span class="n">in_text</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">seed_text</span><span class="p">,</span> <span class="n">seed_text</span>
    <span class="c1"># generate a fixed number of words</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_words</span><span class="p">):</span>
        <span class="c1"># encode the text as integer</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">in_text</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        
        <span class="c1"># predict a word in the vocabulary</span>
        <span class="n">yhat</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">encoded</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># map predicted word index to word</span>
        <span class="n">out_word</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">yhat</span><span class="p">:</span>
                <span class="n">out_word</span> <span class="o">=</span> <span class="n">word</span>
                <span class="k">break</span>
        <span class="c1"># append to input</span>
        <span class="n">in_text</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">out_word</span><span class="p">,</span> <span class="n">result</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">out_word</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>In the above <code class="docutils literal notranslate"><span class="pre">generate_seq()</span></code>, we use a <strong>greedy search</strong>, which selects the most likely word at each time step in the output sequence.</p></li>
<li><p>While this approach features its efficiency, the quality of the final output sequences may not necessarily be optimal.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;Jill&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - 0s 144ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
Jill went up the hill and jill went up the hill
</pre></div>
</div>
</div>
</div>
</section>
<section id="sampling-strategies-for-text-generation">
<h3>Sampling Strategies for Text Generation<a class="headerlink" href="#sampling-strategies-for-text-generation" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Given a trained language model and a <strong>seed</strong> text chunk, we can generate new text by greedy-search like we’ve seen above.</p></li>
<li><p>But we may sometimes have to add a certain degree of <strong>variation</strong> to the robotic texts for linguistic <strong>creativity</strong>.</p></li>
</ul>
<ul class="simple">
<li><p>Possible alternatives:</p>
<ul>
<li><p>We can re-normalize the predicted probability distributions of all next-words to reduce probability differences between the highest and the lowest. (Please see Ch.8.1 Text Generation with LSTM in Chollet’s Deep Learning with Python. You will need this strategy for the assignment.)</p></li>
<li><p>We can use non-greedy search by keeping the top <em>k</em> probable candidates in the list for next-word prediction. (cf. <strong>Beam Search</strong> below) and determine the tokens by choosing the sequence of the maximum probability.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="beam-search-skipped">
<h2>Beam Search (skipped)<a class="headerlink" href="#beam-search-skipped" title="Permalink to this headline">#</a></h2>
<section id="searching-in-nlp">
<h3>Searching in NLP<a class="headerlink" href="#searching-in-nlp" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In the previous demonstration, when we generate the predicted next word, we adopt a naive approach, i.e., always choosing the word of the highest probability.</p></li>
<li><p>It is common in NLP for models to output a probability distribution over words in the vocabulary.</p></li>
<li><p>This step involves searching through all the possible output sequences based on their likelihood.</p></li>
<li><p>Choosing the next word of highest probability does not guarantee us the most optimal sequence.</p></li>
<li><p>The search problem is exponential in the length of the output sequence given the large size of vocabulary.</p></li>
</ul>
</section>
<section id="beam-search-decoding">
<h3>Beam Search Decoding<a class="headerlink" href="#beam-search-decoding" title="Permalink to this headline">#</a></h3>
<p>The beam search expands all possible next steps and keeps the <strong><span class="math notranslate nohighlight">\(k\)</span></strong> most likely, where <strong><span class="math notranslate nohighlight">\(k\)</span></strong> is a researcher-specified parameter and controls the number of beams or parallel searches through the sequence of probabilities.</p>
<p>The search process can stop for each candidate independently either by:</p>
<ul class="simple">
<li><p>reaching a maximum length</p></li>
<li><p>reaching an end-of-sequence token</p></li>
<li><p>reaching a threshold likelihood</p></li>
</ul>
<div class="highlight-{note] notranslate"><div class="highlight"><pre><span></span>Please see Jason Brownlee&#39;s blog post [How to Implement a Beam Search Decoder for Natural Language Processing](https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/) for the python implementation.

The following codes are based on Jason&#39;s code.
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The following codes may not work properly. In Beam Search, when the model predicts <code class="docutils literal notranslate"><span class="pre">None</span></code> as the next character, we should set it as a stopping condition. The following codes have not be optimized with respect to this.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a sequence from the model</span>
<span class="k">def</span> <span class="nf">generate_seq_beam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seed_text</span><span class="p">,</span> <span class="n">n_words</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">in_text</span> <span class="o">=</span> <span class="n">seed_text</span> 
    <span class="n">sequences</span> <span class="o">=</span> <span class="p">[[[</span><span class="n">in_text</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">]]</span>
    <span class="c1"># prepare id_2_word map</span>
    <span class="n">id_2_word</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
    
    <span class="c1"># start next-word generating</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_words</span><span class="p">):</span>
        <span class="n">all_candidates</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>        
        <span class="c1">#print(&quot;Next word &quot;, _+1)</span>
        <span class="c1"># temp list to hold all possible candidates</span>
        <span class="c1"># `sequence + next words`</span>


        <span class="c1"># for each existing sequence</span>
        <span class="c1"># take the last word of the sequence</span>
        <span class="c1"># find probs of all words in the next position</span>
        <span class="c1"># save the top k</span>
        <span class="c1"># all_candidates should have 3 * 22 = 66 candidates</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">)):</span>
            <span class="c1"># for the current sequence</span>
            <span class="n">seq</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>            
            <span class="c1"># next word probablity distribution</span>
            <span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">seq</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
            <span class="n">model_pred_prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="c1"># compute all probabilities for `curent_sequence + all_possible_next_word`</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_pred_prob</span><span class="p">)):</span>
                <span class="n">candidate</span> <span class="o">=</span> <span class="p">[</span><span class="n">seq</span> <span class="o">+</span> <span class="p">[</span><span class="n">id_2_word</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">score</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">model_pred_prob</span><span class="p">[</span><span class="n">j</span><span class="p">])]</span>
                <span class="n">all_candidates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>

            <span class="n">all_candidates</span><span class="o">=</span> <span class="p">[[</span><span class="n">seq</span><span class="p">,</span> <span class="n">score</span><span class="p">]</span> <span class="k">for</span> <span class="n">seq</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">all_candidates</span> <span class="k">if</span> <span class="n">seq</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

            <span class="c1"># order all candidates (seqence + nextword) by score</span>
            <span class="c1">#print(&quot;all_condidates length:&quot;, len(all_candidates))</span>
            <span class="n">ordered</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_candidates</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># default ascending</span>
            <span class="c1"># select k best</span>
            <span class="n">sequences</span> <span class="o">=</span> <span class="n">ordered</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span> <span class="c1">## choose top k</span>

    <span class="k">return</span> <span class="n">sequences</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_seq_beam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;Jill&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 10ms/step
1/1 [==============================] - 0s 9ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 8ms/step
1/1 [==============================] - 0s 7ms/step
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;jack&#39;], 4.68290707655251],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;], 4.72132352180779],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;], 4.762729896232486],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;, &#39;jack&#39;],
  5.449550641700625],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;, &#39;down&#39;],
  5.487967086955905],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;],
  5.529373461380601],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;jack&#39;],
  6.136371387168765],
 [[&#39;Jill&#39;, &#39;up&#39;, &#39;hill&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;, &#39;jack&#39;, &#39;jack&#39;, &#39;down&#39;],
  6.174787832424045],
 [[&#39;Jill&#39;,
   &#39;up&#39;,
   &#39;hill&#39;,
   &#39;jack&#39;,
   &#39;jack&#39;,
   &#39;down&#39;,
   &#39;jack&#39;,
   &#39;down&#39;,
   &#39;jack&#39;,
   &#39;jack&#39;],
  6.216194206848741],
 [[&#39;Jill&#39;,
   &#39;up&#39;,
   &#39;hill&#39;,
   &#39;jack&#39;,
   &#39;jack&#39;,
   &#39;down&#39;,
   &#39;jack&#39;,
   &#39;jack&#39;,
   &#39;down&#39;,
   &#39;jack&#39;],
  6.216194206848741]]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Check <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">Ch 7 Neural Networks and Neural Language Models</a> in Speech and Language Processing (3rd ed. draft).</p></li>
<li><p>Chollet (2017): Ch 8.1</p></li>
<li><p>Check Jason Brownlee’s blog post <a class="reference external" href="https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/">How to Develop Word-Based Neural Language Models in Python with Keras</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="dl-sequence-models-intuition.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Sequence Models Intuition</p>
      </div>
    </a>
    <a class="right-next"
       href="text-vec-embedding.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Word Embeddings</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflow-of-neural-language-model">Workflow of Neural Language Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigram-model">Bigram Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization">Tokenization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-to-sequences-and-training-testing-sets">Text-to-Sequences and Training-Testing Sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-representation-of-the-next-word">One-hot Representation of the Next-Word</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-rnn-language-model">Define RNN Language Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-using-the-model">Text Generation Using the Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-strategies-for-text-generation">Sampling Strategies for Text Generation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beam-search-skipped">Beam Search (skipped)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#searching-in-nlp">Searching in NLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#beam-search-decoding">Beam Search Decoding</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alvin Cheng-Hsien Chen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023 Alvin Chen.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>