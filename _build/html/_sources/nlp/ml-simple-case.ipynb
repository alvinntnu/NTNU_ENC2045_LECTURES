{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning: A Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{contents}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Quick Example: Name Gender Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's assume that we have collected a list of personal names and we have their corresponding gender labels, i.e., whether the name is a male or female one.\n",
    "\n",
    "The goal of this example is to create a classifier that would automatically classify a given name into either male or female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We use the data provided in NLTK. Please download the corpus data if necessary.\n",
    "- We load the corpus, `nltk.corpus.names` and randomize it before we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/alvinchen/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Colab Only\n",
    "nltk.download(\"names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Now our **base unit** for classification is a name. \n",
    "- In **feature engineering**, our goal is to transform the texts (i.e., names) into vectorized representations.\n",
    "- To start with, let's represent each text (name) by using its last character as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_vectorizer(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "\n",
    "\n",
    "text_vectorizer('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We then apply the feature engineering method to every text in the data and split the data into **training** and **testing** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "featuresets = [(text_vectorizer(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now all the training/testing tokens are included in a **list**.\n",
    "- Each training token (i.e., base unit) is encoded as a **tuple** of `(feature dictionary, string)`, where we have its features represented as a **dictionary**, and its label as a **string**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'y'}, 'female'),\n",
       " ({'last_letter': 'd'}, 'male'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please note that in `NLTK`, we can use the `apply_features` to create training and testing datasets.\n",
    "- When you have a very large feature set, this can be more effective in terms of memory management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is our earlier method of creating training and testing sets:\n",
    "\n",
    "```\n",
    "featuresets = [(text_vectorizer(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = apply_features(text_vectorizer, labeled_names[500:])\n",
    "# test_set = apply_features(text_vectorizer, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A good start is to try the simple Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we train the model, we need to evaluate its performance on the testing dataset.\n",
    "- Model evaluation usually involves comparing the predictions provided by the model with the correct answers/labels.\n",
    "- The evaluation results are often summarized in a **confusion matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/confusion-matrix.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion Matrix:\n",
    "    - **True positives** are relevant items that we correctly identified as relevant.\n",
    "    - **True negatives** are irrelevant items that we correctly identified as irrelevant.\n",
    "    - **False positives** (or Type I errors) are irrelevant items that we incorrectly identified as relevant.\n",
    "    - **False negatives** (or Type II errors) are relevant items that we incorrectly identified as irrelevant.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given these four numbers, we can define the following model evaluation metrics:\n",
    "    - **Accuracy**: How many items were correctly classified, i.e., $\\frac{TP + TN}{N}$\n",
    "    - **Precision**: How many of the items identified by the classifier as relevant are indeed relevant, i.e., $\\frac{TP}{TP+FP}$.\n",
    "    - **Recall**: How many of the true relevant items were successfully identified by the classifier, i.e., $\\frac{TP}{TP+FN}$.\n",
    "    - **F-Measure (or F-Score)**: the harmonic mean of the precision and recall,i.e.:\n",
    "        \n",
    "\n",
    "    $$ \n",
    "    F= \\frac{(2 × Precision × Recall)}{(Precision + Recall)} \n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "When dealing with imbalanced class distributions, we need to take into account the baseline performance in our model evaluation. For example. if the distribution of `Class 0` and `Class 1` is 9:1, then a naive classifier might as well classify all cases as `Class 0`, yielding a high-**precision** performance (i.e., Precision = 90%).\n",
    "\n",
    "Given this baseline, to better evaluate the classifier on imbalanced dataset, probably the classifier's **recall rates** are more important.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "**Precision, Recall, and F-measure**\n",
    "\n",
    "In machine learning, precision and recall are two important metrics used to evaluate the performance of a classifier. Precision measures the proportion of correctly predicted positive instances among all instances predicted as positive, while recall measures the proportion of correctly predicted positive instances among all actual positive instances. Sometimes, it's challenging to optimize both precision and recall simultaneously during model training because increasing one may lead to a decrease in the other. For example, making the classifier more conservative can improve precision but lower recall, and vice versa. This trade-off between precision and recall highlights the importance of using a metric that considers both aspects simultaneously, such as the F measure. The F measure combines precision and recall into a single score, providing a balanced assessment of a classifier's performance without favoring one metric over the other. Therefore, in scenarios where precision and recall cannot be optimized simultaneously, the F measure becomes crucial for evaluating the classifier's effectiveness.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the Confusion Matrix\n",
    "t_f = [feature for (feature, label) in test_set]  # features of test set\n",
    "t_l = [label for (feature, label) in test_set]  # labels of test set\n",
    "t_l_pr = [classifier.classify(f) for f in t_f]  # predicted labels of test set\n",
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |   f     |\n",
      "       |   e     |\n",
      "       |   m   m |\n",
      "       |   a   a |\n",
      "       |   l   l |\n",
      "       |   e   e |\n",
      "-------+---------+\n",
      "female |<264> 61 |\n",
      "  male |  57<118>|\n",
      "-------+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <52.8%> 12.2% |\n",
      "  male |  11.4% <23.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=False, truncate=9))\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrap as a function\n",
    "def createCM(classifier, test_set):\n",
    "    t_f = [feature for (feature, label) in test_set]\n",
    "    t_l = [label for (feature, label) in test_set]\n",
    "    t_l_pr = [classifier.classify(f) for f in t_f]\n",
    "    cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "    print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <52.8%> 12.2% |\n",
      "  male |  11.4% <23.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also get confusion matrix statistics from `sklearn`:\n",
    "    - `confusion_matrix`\n",
    "    - `ConfusionMatrixDisplay`\n",
    "    - `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264  61]\n",
      " [ 57 118]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## label names\n",
    "target_names = ['female', 'male']\n",
    "## confusion matrix\n",
    "cm = confusion_matrix(y_true = t_l, y_pred = t_l_pr, labels = target_names)\n",
    "print(cm)\n",
    "## plotting\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix= cm,\n",
    "                              display_labels= target_names)    \n",
    "\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.82      0.81      0.82       325\n",
      "        male       0.66      0.67      0.67       175\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.74      0.74      0.74       500\n",
      "weighted avg       0.77      0.76      0.76       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## confusion matrix report\n",
    "print(classification_report(y_true = t_l, y_pred = t_l_pr, target_names= ['female','male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n",
      "0.77\n",
      "0.7882\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "print((272+124)/500)\n",
    "\n",
    "## macro F measures\n",
    "print((0.84 + 0.70)/2)\n",
    "\n",
    "## weighted F measures\n",
    "print(0.84*(315/(315+185)) + 0.70 * (185/(315+185)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    ":class: dropdown\n",
    "\n",
    "- The **macro-averaged** F1 score (or macro F1 score) is computed using the arithmetic mean (aka unweighted mean) of all the per-class F1 scores. This method treats all classes equally regardless of their class distributions.\n",
    "\n",
    "- The **weighted-averaged** F1 score is calculated by taking the mean of all per-class F1 scores while considering each class’s distribution in the dataset. The \"weight\" essentially refers to the proportion of each class’s token numbers relative to the sum of the entire dataset.\n",
    "\n",
    "- Which metrics should be more crucial to your evaluation?\n",
    "\n",
    "    - If you're dealing with an imbalanced dataset where all classes are equally important, go for the **macro-averaged** F1 score.\n",
    "    - If your dataset is imbalanced, but you want to give more importance to classes with more examples, go for the **weighted-averaged** F1 score.\n",
    "    - If you have a balanced dataset and want a straightforward metric for overall performance, you can use accuracy, which is sometimes referred to as **micro** F1 score.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we obtain a classifier, we can use it for (new) case predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(text_vectorizer('Alvino')))\n",
    "print(classifier.classify(text_vectorizer('Trinity')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Post-hoc Analysis (Interpreting the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- One of the most important steps after model training is to examine which features contribute the most to the classifier prediction of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.5 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.5 : 1.0\n",
      "             last_letter = 'o'              male : female =      9.4 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.3 : 1.0\n",
      "             last_letter = 'm'              male : female =      7.7 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can we improve the model/classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the following, we will talk about methods that we may consider to further improve the model training.\n",
    "\n",
    "- Feature Engineering\n",
    "- Error Analysis\n",
    "- Cross Validation\n",
    "- Try Different Machine-Learning Algorithms\n",
    "- (Ensemble Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More Sophisticated Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can extract more useful features from the names.\n",
    "- Use the following features for vectorized representations of names:\n",
    "    - The first/last letter\n",
    "    - Frequencies of all 26 alphabets in the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## refine out text vectorizer\n",
    "def text_vectorizer2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'a',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 1,\n",
       " 'has(a)': True,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 0,\n",
       " 'has(h)': False,\n",
       " 'count(i)': 1,\n",
       " 'has(i)': True,\n",
       " 'count(j)': 0,\n",
       " 'has(j)': False,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 1,\n",
       " 'has(l)': True,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 0,\n",
       " 'has(o)': False,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 1,\n",
       " 'has(v)': True,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer2('Alvin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer2('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## more sophisticated feature engineering\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mapply_features\u001b[49m(text_vectorizer2, labeled_names[\u001b[38;5;241m500\u001b[39m:])\n\u001b[1;32m      3\u001b[0m test_set \u001b[38;5;241m=\u001b[39m apply_features(text_vectorizer2, labeled_names[:\u001b[38;5;241m500\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apply_features' is not defined"
     ]
    }
   ],
   "source": [
    "## more sophisticated feature engineering\n",
    "train_set = apply_features(text_vectorizer2, labeled_names[500:])\n",
    "test_set = apply_features(text_vectorizer2, labeled_names[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the model\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.2 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.3 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.3 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.5 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.5 : 1.0\n",
      "                count(v) = 2              female : male   =      9.6 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.5 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.8 : 1.0\n",
      "             last_letter = 'o'              male : female =      7.8 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.4 : 1.0\n",
      "             last_letter = 'w'              male : female =      4.8 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.8 : 1.0\n",
      "                count(a) = 3              female : male   =      4.7 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.6 : 1.0\n",
      "                count(w) = 1                male : female =      4.4 : 1.0\n",
      "                  has(w) = True             male : female =      4.4 : 1.0\n",
      "             last_letter = 'z'              male : female =      4.3 : 1.0\n",
      "                count(f) = 2                male : female =      4.1 : 1.0\n",
      "             last_letter = 's'              male : female =      4.0 : 1.0\n",
      "             last_letter = 't'              male : female =      4.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "## Post-hoc analysis\n",
    "classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train-Development-Test Data Splits for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Normally we have **training**-**testing** splits of data\n",
    "- Sometimes we can use **development (dev)** set for error analysis and feature engineering.\n",
    "- This dev set should be independent of training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Now let's train the model on the **training set** and first check the classifier's performance on the **dev** set.\n",
    "- We then identify the errors the classifier made in the **dev** set.\n",
    "- We perform **error analysis** for potential model improvement.\n",
    "- We only test our **final model** on the testing set. (Note: Testing set can only be used **once**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "## train-dev-test split\n",
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]\n",
    "\n",
    "## Feature engineering\n",
    "train_set = [(text_vectorizer2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(text_vectorizer2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(text_vectorizer2(n), gender) for (n, gender) in test_names]\n",
    "\n",
    "## Train the model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "## Evaluate the model on dev set\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## identify error cases\n",
    "\n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(text_vectorizer2(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## save error cases for post-hoc analysis\n",
    "import csv\n",
    "\n",
    "with open('error-analysis.csv', 'w') as f:\n",
    "\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['tag', 'guess', 'name'])\n",
    "    write.writerows(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ideally, we can inspect the errors in a spreadsheet and come up with better rules (features) that could help improve the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>guess</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Clayborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Davidde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Sean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Helen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Frances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Isadore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Dorolice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Alan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Brigit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Merrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Trish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Karl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Sinclair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Vince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Kellen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Jermayne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Justin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Tessy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Kenny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Juanita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag   guess      name\n",
       "0      male  female  Clayborn\n",
       "1      male  female   Davidde\n",
       "2      male  female      Sean\n",
       "3    female    male     Helen\n",
       "4    female    male   Frances\n",
       "5      male  female   Isadore\n",
       "6    female    male  Dorolice\n",
       "7      male  female      Alan\n",
       "8    female    male    Brigit\n",
       "9      male  female    Merrel\n",
       "240  female    male     Trish\n",
       "241    male  female      Karl\n",
       "242    male  female  Sinclair\n",
       "243    male  female     Vince\n",
       "244    male  female    Kellen\n",
       "245    male  female  Jermayne\n",
       "246  female    male    Justin\n",
       "247  female    male     Tessy\n",
       "248    male  female     Kenny\n",
       "249    male  female   Juanita"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "## check first and last N rows\n",
    "pd.read_csv('error-analysis.csv').iloc[[*range(10), *range(-10, 0)],]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can also check our average model performance using the cross-validation method on the training dataset before the real testing of the model.\n",
    "- This method is often useful if you need to fine-tune the hyperparameters during the model training stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "![](../images/ml-kfold.png)\n",
    "(Source: https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77\n",
      "accuracy: 0.76\n",
      "accuracy: 0.82\n",
      "accuracy: 0.8\n",
      "accuracy: 0.79\n",
      "accuracy: 0.79\n",
      "accuracy: 0.78\n",
      "accuracy: 0.76\n",
      "accuracy: 0.77\n",
      "accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "acc_kf = []  ## accuracy holder\n",
    "\n",
    "## Cross-validation\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = nltk.NaiveBayesClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]])\n",
    "    cur_fold_acc = nltk.classify.util.accuracy(\n",
    "        classifier, train_set[test_index[0]:test_index[len(test_index) - 1]])\n",
    "    acc_kf.append(cur_fold_acc)\n",
    "    print('accuracy:', np.round(cur_fold_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791382108323754"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Try Different Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- There are many ML algorithms for classification tasks.\n",
    "- Here we will demonstrate a few more classifiers implemented in NLTK, including:\n",
    "    - Maximum Entropy Classifier (Logistic Regression)\n",
    "    - Decision Tree Classifier\n",
    "- Also, in NLTK, we can use the classification methods provided in `sklearn` as well, including:\n",
    "    - Naive Bayes\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- When we try another ML algorithm, we do the following:\n",
    "    - train the model\n",
    "    - check model performance (accuracy and confusion matrix)\n",
    "    - check the most informative features\n",
    "    - obtain average performance using *k*-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Try Maxent Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Maxent is memory hungry, slower, and it requires `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 23.9 ms, total: 40.7 s\n",
      "Wall time: 41.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "## Train Maxent model\n",
    "classifier_maxent = MaxentClassifier.train(train_set,\n",
    "                                           algorithm='iis',\n",
    "                                           trace=0,\n",
    "                                           max_iter=10000,\n",
    "                                           min_lldelta=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{note}\n",
    "The default algorithm for training is `iis` (Improved Iterative Scaling). Another alternative is `gis` (General Iterative Scaling), which is faster.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6987577639751553\n",
      "accuracy: 0.687888198757764\n",
      "accuracy: 0.6739130434782609\n",
      "accuracy: 0.7360248447204969\n",
      "accuracy: 0.713841368584759\n",
      "accuracy: 0.702954898911353\n",
      "accuracy: 0.7200622083981337\n",
      "accuracy: 0.6905132192846034\n",
      "accuracy: 0.6905132192846034\n",
      "accuracy: 0.6858475894245724\n",
      "CPU times: user 1min 37s, sys: 137 ms, total: 1min 37s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Cross validation on training\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = MaxentClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        algorithm='gis',\n",
    "        trace=0,\n",
    "        max_iter=100,\n",
    "        min_lldelta=0.01) ## set smaller value for `min_lldelta`\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <58.0%>  5.0% |\n",
      "  male |  12.2% <24.8%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## evaluate the model\n",
    "createCM(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -3.224 last_letter=='a' and label is 'male'\n",
      "  -2.547 last_letter=='k' and label is 'female'\n",
      "  -2.475 last_letter=='f' and label is 'female'\n",
      "  -2.020 count(v)==2 and label is 'male'\n",
      "  -1.494 last_letter=='v' and label is 'female'\n",
      "   1.483 count(j)==2 and label is 'female'\n",
      "  -1.435 last_letter=='m' and label is 'female'\n",
      "  -1.408 last_letter=='p' and label is 'female'\n",
      "  -1.345 last_letter=='d' and label is 'female'\n",
      "  -1.181 last_letter=='i' and label is 'male'\n",
      "  -1.076 last_letter=='o' and label is 'female'\n",
      "   1.031 last_letter=='c' and label is 'male'\n",
      "  -1.020 first_letter=='x' and label is 'female'\n",
      "  -0.985 count(p)==3 and label is 'male'\n",
      "   0.931 count(h)==3 and label is 'male'\n",
      "  -0.900 last_letter=='r' and label is 'female'\n",
      "  -0.847 count(i)==3 and label is 'female'\n",
      "  -0.794 count(e)==3 and label is 'male'\n",
      "   0.774 count(g)==3 and label is 'male'\n",
      "   0.690 count(u)==3 and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "## posthoc analysis\n",
    "classifier_maxent.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Try Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Parameters:\n",
    "    - `binary`: whether the features are binary\n",
    "    - `entropy_cutoff`: a value used during tree refinement process\n",
    "        - entropy = 1 -> high-level uncertainty\n",
    "        - entropy = 0 -> perfect model prediction\n",
    "    - `depth_cutoff`: to control the depth of the tree\n",
    "    - `support_cutoff`: the minimum number of instances that are required to make a decision about a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.02 s, sys: 1.89 ms, total: 4.02 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train decision tree model\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier.train(train_set,\n",
    "                                             binary=True,\n",
    "                                             entropy_cutoff=0.7,\n",
    "                                             depth_cutoff=5,\n",
    "                                             support_cutoff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7111801242236024\n",
      "accuracy: 0.6956521739130435\n",
      "accuracy: 0.7049689440993789\n",
      "accuracy: 0.7329192546583851\n",
      "accuracy: 0.7231726283048211\n",
      "accuracy: 0.7200622083981337\n",
      "accuracy: 0.7247278382581649\n",
      "accuracy: 0.7262830482115086\n",
      "accuracy: 0.7356143079315708\n",
      "accuracy: 0.7107309486780715\n",
      "CPU times: user 1min 19s, sys: 121 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## cross-validation on training \n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = DecisionTreeClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        binary=True,\n",
    "        entropy_cutoff=0.7,\n",
    "        depth_cutoff=5,\n",
    "        support_cutoff=5)\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <61.2%>  1.8% |\n",
      "  male |  22.8% <14.2%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## evaluate the model on test data\n",
    "createCM(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_letter=d? ........................................ male\n",
      "else: ................................................. male\n",
      "  last_letter=r? ...................................... male\n",
      "    first_letter=j? ................................... male\n",
      "      count(n)=0? ..................................... male\n",
      "      else: ........................................... female\n",
      "    else: ............................................. male\n",
      "      first_letter=e? ................................. female\n",
      "        count(t)=0? ................................... male\n",
      "        else: ......................................... female\n",
      "      else: ........................................... male\n",
      "  else: ............................................... male\n",
      "    last_letter=o? .................................... male\n",
      "    else: ............................................. male\n",
      "      last_letter=s? .................................. female\n",
      "        first_letter=p? ............................... female\n",
      "        else: ......................................... male\n",
      "      else: ........................................... male\n",
      "        count(w)=0? ................................... female\n",
      "        else: ......................................... male\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## posthoc \n",
    "print(classifier_dt.pretty_format(depth=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Try `sklearn` Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` is a very useful module for machine learning. We will talk more about this module in our later lectures.\n",
    "- This package provides a lot more ML algorithms for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB())>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "## Using sklearn naive bayes in nltk\n",
    "sk_classifier = SklearnClassifier(MultinomialNB())\n",
    "sk_classifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluate model\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Regression in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <56.4%>  6.6% |\n",
      "  male |  11.0% <26.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## using sklearn logistic regression in nltk\n",
    "sk_classifier = SklearnClassifier(LogisticRegression(max_iter=500))\n",
    "sk_classifier.train(train_set)\n",
    "\n",
    "## evaluate the model\n",
    "nltk.classify.accuracy(sk_classifier, test_set)\n",
    "# createCM(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Support Vector Machine in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` provides several implementations for Support Vector Machines.\n",
    "- Please see its documentation for more detail: [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <57.4%>  5.6% |\n",
      "  male |   8.6% <28.4%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "## using sklearn SVM in nltk\n",
    "sk_classifier = SklearnClassifier(SVC())\n",
    "sk_classifier.train(train_set)\n",
    "\n",
    "## evaluate the model\n",
    "nltk.classify.accuracy(sk_classifier, test_set)\n",
    "# createCM(sk_classifier, test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## using sklearn linear SVM in nltk\n",
    "sk_classifier = SklearnClassifier(LinearSVC(max_iter=2000, dual=True))\n",
    "sk_classifier.train(train_set)\n",
    "\n",
    "## evaluate model\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "## using sklearn linear nuSVM in nltk\n",
    "sk_classifier = SklearnClassifier(NuSVC())\n",
    "sk_classifier.train(train_set)\n",
    "## evaluate model\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Remaining Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. **Feature Engineering**: Feature engineering is highlighted as a crucial aspect of the machine learning process. This involves selecting, extracting, and transforming features from the raw data to create meaningful representations that can improve the performance of the model.\n",
    "\n",
    "2. **Linguistically Motivated Features**: There is a suggestion to include more linguistically motivated features during the feature engineering process. This implies that domain-specific knowledge and linguistic insights can be valuable in designing features that capture relevant information from the data.\n",
    "\n",
    "3. **Text Vectorization Quality**: The quality of text vectorization is emphasized as it greatly influences the performance of the classifier. Text vectorization converts textual data into numerical representations that machine learning algorithms can work with. Ensuring accurate and informative vectorization is crucial for effective modeling.\n",
    "\n",
    "4. **Hyperparameter Tuning**: Every machine learning algorithm requires setting hyperparameters, which can significantly impact the model's performance. Tuning these hyperparameters to optimal values is essential for achieving the best possible performance from the model.\n",
    "\n",
    "5. **Systematic Hyperparameter Optimization**: There is a need for a more systematic approach to finding the optimal combinations of hyperparameters for a given machine learning algorithm. This suggests the importance of methods such as grid search or randomized search to systematically explore the hyperparameter space and identify the best settings.\n",
    "\n",
    "6. **Importance of Sklearn**: We will come back to these issues when discussing machine learning with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- NLTK Book, [Chapter 6 Learning to Classify Texts](https://www.nltk.org/book/ch06.html)\n",
    "- Géron (2019), Chapter 3 Classification"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python-notes-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "1519.67px",
    "top": "85px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
