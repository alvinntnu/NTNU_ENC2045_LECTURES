{"cells":[{"cell_type":"markdown","metadata":{"id":"s_9F2uu-Vfjx"},"source":["# Text Vectorization Using Traditional Methods"]},{"cell_type":"markdown","metadata":{"id":"UAS4xbBNVfjz"},"source":["\n","Traditionally, in linguistic studies, experts would analyze text by **manually labeling** it with linguistic characteristics they deemed relevant. These labels are then converted into numeric values, making it easier to process the text computationally.\n","\n","However, this approach requires a lot of manual effort. In statistical language processing, the focus is on automating this process by developing techniques to automatically convert text into numeric representations. One popular method for this is the **bag-of-words** approach, which we'll explore in this tutorial.\n","\n",":::{contents}\n",":::\n"]},{"cell_type":"markdown","metadata":{"id":"F6C6zjkGVfjz"},"source":["\n","## Feature Engineering\n","\n","Feature engineering is the process of selecting, transforming, or creating features from raw text data to improve the performance of machine learning models. In the context of natural language processing (NLP), feature engineering involves converting textual data into a **numerical** format that machine learning algorithms can understand and process effectively.\n","\n","The bag-of-words (BoW) model is a common (yet naive) technique used in feature engineering for NLP. It represents text data as a collection of unique words (or tokens) present in the corpus, ignoring grammar and word order. Each document in the corpus is then represented as a vector, where each dimension corresponds to a unique word in the vocabulary, and the value in each dimension represents the frequency or presence of that word in the document.\n","\n","So, the connection between feature engineering and bag of words lies in the fact that the bag-of-words model is a method used in feature engineering to convert textual data into a structured numerical format that can be used as input for machine learning algorithms. It allows us to extract meaningful features from text data, making it suitable for tasks such as classification, clustering, and sentiment analysis.\n"]},{"cell_type":"markdown","metadata":{"id":"mzclfrN4Vfj0"},"source":["## Import necessary dependencies and settings"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709151009182,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"WWOixt6jVfj0"},"outputs":[],"source":["# import warnings\n","# warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","## Default Style Settings\n","matplotlib.rcParams['figure.dpi'] = 150\n","pd.options.display.max_colwidth = 200\n","#%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"85olu0IwVfj1"},"source":["## Sample Corpus of Text Documents"]},{"cell_type":"markdown","metadata":{"id":"QapAq4ZBVfj1"},"source":["- To have a quick intuition of how bag-of-words work, we start with a naive corpus, which consists of only eight short documents. Each document is in fact a simple sentence.\n","- Each document in the corpus has a label. Let's assume that the label refers to the **topic** of each document."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709151009182,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"SjpbSJ-oVfj1","outputId":"a4fcaa05-5482-467f-ab66-ab1e914b99ac","scrolled":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The sky is blue and beautiful.</td>\n","      <td>weather</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this blue and beautiful sky!</td>\n","      <td>weather</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The quick brown fox jumps over the lazy dog.</td>\n","      <td>animals</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n","      <td>food</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I love green eggs, ham, sausages and bacon!</td>\n","      <td>food</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The brown fox is quick and the blue dog is lazy!</td>\n","      <td>animals</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The sky is very blue and the sky is very beautiful today</td>\n","      <td>weather</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The dog is lazy but the brown fox is quick!</td>\n","      <td>animals</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                             Document Category\n","0                                      The sky is blue and beautiful.  weather\n","1                                   Love this blue and beautiful sky!  weather\n","2                        The quick brown fox jumps over the lazy dog.  animals\n","3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n","4                         I love green eggs, ham, sausages and bacon!     food\n","5                    The brown fox is quick and the blue dog is lazy!  animals\n","6            The sky is very blue and the sky is very beautiful today  weather\n","7                         The dog is lazy but the brown fox is quick!  animals"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["## documents\n","corpus = [\n","    'The sky is blue and beautiful.', 'Love this blue and beautiful sky!',\n","    'The quick brown fox jumps over the lazy dog.',\n","    \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n","    'I love green eggs, ham, sausages and bacon!',\n","    'The brown fox is quick and the blue dog is lazy!',\n","    'The sky is very blue and the sky is very beautiful today',\n","    'The dog is lazy but the brown fox is quick!'\n","]\n","\n","## labels\n","labels = [\n","    'weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather',\n","    'animals'\n","]\n","\n","## DF\n","corpus = np.array(corpus) # np.array better than list\n","corpus_df = pd.DataFrame({'Document': corpus, 'Category': labels})\n","corpus_df"]},{"cell_type":"markdown","metadata":{"id":"EHP5mgedVfj2"},"source":[":::{tip}\n","\n","In text processing, people often cast `list` into `np.array` for efficiency. A numpy array is a lot faster than the native `list` in Python.\n","\n","If you are interested, please check this [YouTube Numpy Crash Course](https://www.youtube.com/watch?v=9JUAPgtkKpI&t=1868s).\n","\n",":::"]},{"cell_type":"markdown","metadata":{"id":"X9h71h2ZVfj2"},"source":["## Simple Text Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"YZvJh9_eVfj2"},"source":["- A few steps for text preprocessing\n","    - Remove special characters\n","    - Normalize letter case\n","    - Remove redundant spaces\n","    - Tokenize each document into word-tokens\n","    - Remove stop words\n","- All these preprocessing steps are wrapped in one function, `normalize_document()`."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1709151043118,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"OdyqIV8gVuk1","outputId":"9c1c2905-48f4-4586-f921-c7f97774de90"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/alvinchen/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["## Colab Only\n","nltk.download(\"stopwords\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709151050520,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"o5de_YFXVfj3"},"outputs":[],"source":["wpt = nltk.WordPunctTokenizer()\n","stop_words = nltk.corpus.stopwords.words('english')\n","\n","\n","def normalize_document(doc):\n","    \"\"\"\n","    Normalize the document.\n","\n","    Parameters:\n","    - doc (list): A list of documents\n","\n","    Returns:\n","    list: a list of preprocessed documents\n","\n","    \"\"\"\n","\n","    # lower case and remove special characters\\whitespaces\n","    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I | re.A)\n","    doc = doc.lower()\n","    doc = doc.strip()\n","    # tokenize document\n","    tokens = wpt.tokenize(doc)\n","    # filter stopwords out of document\n","    filtered_tokens = [token for token in tokens if token not in stop_words]\n","    # re-create document from filtered tokens\n","    doc = ' '.join(filtered_tokens)\n","    return doc\n","\n","\n","normalize_corpus = np.vectorize(normalize_document)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709151050950,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"cj4O5tX0Vfj3","outputId":"fa2f3bb5-22b7-46ee-c300-104ab929c9bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["['The sky is blue and beautiful.' 'Love this blue and beautiful sky!'\n"," 'The quick brown fox jumps over the lazy dog.'\n"," \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\"\n"," 'I love green eggs, ham, sausages and bacon!'\n"," 'The brown fox is quick and the blue dog is lazy!'\n"," 'The sky is very blue and the sky is very beautiful today'\n"," 'The dog is lazy but the brown fox is quick!']\n","==================================================\n","['sky blue beautiful' 'love blue beautiful sky'\n"," 'quick brown fox jumps lazy dog'\n"," 'kings breakfast sausages ham bacon eggs toast beans'\n"," 'love green eggs ham sausages bacon' 'brown fox quick blue dog lazy'\n"," 'sky blue sky beautiful today' 'dog lazy brown fox quick']\n"]}],"source":["norm_corpus = normalize_corpus(corpus)\n","print(corpus)\n","print(\"=\"*50)\n","print(norm_corpus)"]},{"cell_type":"markdown","metadata":{"id":"xaoISwENVfj3"},"source":["## Bag of Words Model"]},{"cell_type":"markdown","metadata":{"id":"MXAFXeGZVfj3"},"source":["- Bag-of-words model is the simplest way (i.e., easy to be automated) to vectorize texts into numeric representations.\n","- In short, it is a method to represent a text using its word frequency list."]},{"cell_type":"markdown","metadata":{"id":"b3qzCPDmVfj3"},"source":["![](../images/text-representation-bow.gif)"]},{"cell_type":"markdown","metadata":{"id":"5q-jOrWpVfj3"},"source":["### `CountVectorizer()` from `sklearn`"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709151050950,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"Jw_gQx5tVfj3","outputId":"7fe5367b-f9cd-4281-85b6-efca81d65c79"},"outputs":[{"data":{"text/plain":["<8x20 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 42 stored elements in Compressed Sparse Row format>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","# get bag of words features in sparse format\n","cv = CountVectorizer(min_df=0., max_df=1.)\n","cv_matrix = cv.fit_transform(norm_corpus)\n","cv_matrix"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709151050950,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"T1s_9LVfVfj3","outputId":"c0fb10b4-ff3a-41fc-993a-e823d7acabc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["  (0, 17)\t1\n","  (0, 3)\t1\n","  (0, 2)\t1\n","  (1, 17)\t1\n","  (1, 3)\t1\n","  (1, 2)\t1\n","  (1, 14)\t1\n","  (2, 15)\t1\n","  (2, 5)\t1\n","  (2, 8)\t1\n","  (2, 11)\t1\n","  (2, 13)\t1\n","  (2, 6)\t1\n","  (3, 12)\t1\n","  (3, 4)\t1\n","  (3, 16)\t1\n","  (3, 10)\t1\n","  (3, 0)\t1\n","  (3, 7)\t1\n","  (3, 18)\t1\n","  (3, 1)\t1\n","  (4, 14)\t1\n","  (4, 16)\t1\n","  (4, 10)\t1\n","  (4, 0)\t1\n","  (4, 7)\t1\n","  (4, 9)\t1\n","  (5, 3)\t1\n","  (5, 15)\t1\n","  (5, 5)\t1\n","  (5, 8)\t1\n","  (5, 13)\t1\n","  (5, 6)\t1\n","  (6, 17)\t2\n","  (6, 3)\t1\n","  (6, 2)\t1\n","  (6, 19)\t1\n","  (7, 15)\t1\n","  (7, 5)\t1\n","  (7, 8)\t1\n","  (7, 13)\t1\n","  (7, 6)\t1\n"]}],"source":["# view non-zero feature positions in the sparse matrix\n","print(cv_matrix)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1709151051318,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"U3xu-yvwVfj3","outputId":"64859140-26e1-42ef-fb5e-4c05ad7662f9"},"outputs":[{"data":{"text/plain":["array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n","       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n","       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n","       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],\n","       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# view dense representation\n","# warning might give a memory error if data is too big\n","cv_matrix = cv_matrix.toarray()\n","cv_matrix"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1709151051318,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"PzhPjFooVfj3","outputId":"a0172822-7b0b-4b9f-d3b6-413a1669bd25"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bacon</th>\n","      <th>beans</th>\n","      <th>beautiful</th>\n","      <th>blue</th>\n","      <th>breakfast</th>\n","      <th>brown</th>\n","      <th>dog</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>green</th>\n","      <th>ham</th>\n","      <th>jumps</th>\n","      <th>kings</th>\n","      <th>lazy</th>\n","      <th>love</th>\n","      <th>quick</th>\n","      <th>sausages</th>\n","      <th>sky</th>\n","      <th>toast</th>\n","      <th>today</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   bacon  beans  beautiful  blue  breakfast  brown  dog  eggs  fox  green  \\\n","0      0      0          1     1          0      0    0     0    0      0   \n","1      0      0          1     1          0      0    0     0    0      0   \n","2      0      0          0     0          0      1    1     0    1      0   \n","3      1      1          0     0          1      0    0     1    0      0   \n","4      1      0          0     0          0      0    0     1    0      1   \n","5      0      0          0     1          0      1    1     0    1      0   \n","6      0      0          1     1          0      0    0     0    0      0   \n","7      0      0          0     0          0      1    1     0    1      0   \n","\n","   ham  jumps  kings  lazy  love  quick  sausages  sky  toast  today  \n","0    0      0      0     0     0      0         0    1      0      0  \n","1    0      0      0     0     1      0         0    1      0      0  \n","2    0      1      0     1     0      1         0    0      0      0  \n","3    1      0      1     0     0      0         1    0      1      0  \n","4    1      0      0     0     1      0         1    0      0      0  \n","5    0      0      0     1     0      1         0    0      0      0  \n","6    0      0      0     0     0      0         0    2      0      1  \n","7    0      0      0     1     0      1         0    0      0      0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# get all unique words in the corpus\n","vocab = cv.get_feature_names_out()\n","# show document feature vectors\n","pd.DataFrame(cv_matrix, columns=vocab)"]},{"cell_type":"markdown","metadata":{"id":"A9ro9WaoVfj4"},"source":["- Issues with Bag-of-Words Text Representation\n","    - **Word order** is ignored.\n","    - **Raw** absolute frequency counts of words do not necessarily represent the meaning of the text properly.\n","    - **Marginal** frequencies play important roles. (Row and Columns)\n"]},{"cell_type":"markdown","metadata":{"id":"5rXe3_UzVfj4"},"source":["## Improving Bag-of-Words Text Representation"]},{"cell_type":"markdown","metadata":{"id":"OEfT5wmPVfj4"},"source":["To enhance the Bag of Words (BOW) representation of texts, we can consider the following approaches:\n","\n","1. **Utilize n-grams**: Instead of just using individual words (unigrams), we can include sequences of words (n-grams) in the BOW model. This helps capture partial word order information in the text, which can provide richer semantics.\n","\n","2. **Filter words**: We can filter out words based on certain criteria such as their distributional characteristics (e.g., term frequencies, document frqeuencies) or morphosyntactic patterns (e.g., morphological endings). This can help remove noisy or irrelevant words from the BOW representation, making it more focused on the essential semantic content.\n","\n","3. **Weighting**: Instead of just counting the frequency of each word in the text, we can apply weights to the raw frequency counts. Various weighting schemes such as Term Frequency-Inverse Document Frequency (TF-IDF) can be employed to assign higher weights to words that are more informative and less common across the entire corpus. This helps prioritize important words and downplay the significance of common words that may not carry much semantic meaning."]},{"cell_type":"markdown","metadata":{"id":"zk1S5c22Vfj4"},"source":["In `CountVectorizer()`, we can utilize its parameters:\n","\n","- `max_df`: When building the vocabulary, the vectorizer will ignore terms that have a **document frequency** strictly higher than the given threshold (corpus-specific stop words). `float` = the parameter represents a proportion of documents; `integer` = absolute counts.\n","- `min_df`: When building the vocabulary, the vectorizer will ignore terms that have a **document frequency** strictly lower than the given threshold. `float` = the parameter represents a proportion of documents; `integer` = absolute counts.\n","- `max_features` : Build a vocabulary that only consider the top `max_features` ordered by term frequency across the corpus.\n","- `ngram_range` : The lower and upper boundary of the range of n-values for different word n-grams. `tuple` (min_n, max_n), default=(1, 1).\n","- `token_pattern`: Regular expression denoting what constitutes a \"token\" in vocabulary. The default regexp select tokens of 2 or more alphanumeric characters (Note: **punctuation** is completely ignored and always treated as a token separator). If there is a capturing group in token_pattern then the captured group content, not the entire match, becomes the token. At most one capturing group is permitted.\n"]},{"cell_type":"markdown","metadata":{"id":"sNmaVl4iVfj4"},"source":[":::{warning}\n","\n","The `token_pattern` parameter in `CountVectorizer` is crucial for specifying the pattern used to extract tokens (words) from the text data. By default, `token_pattern` is set to a regular expression that captures words consisting of 2 or more alphanumeric characters. This default setting works well for English text where words are typically separated by whitespace and punctuation.\n","\n","However, when working with languages like Chinese, where words are not separated by whitespace, it becomes necessary to adjust the `token_pattern` parameter to ensure that the tokenizer recognizes the individual words correctly. In the case of Chinese text data that has been word-segmented (i.e., split into individual words), specifying the appropriate `token_pattern` is essential for preserving the integrity of the original word tokens.\n","\n","Without specifying the `token_pattern`, the default behavior of `CountVectorizer` may not correctly identify the segmented words in Chinese text, leading to incorrect tokenization and potentially impacting the accuracy of the analysis or modeling tasks performed using the vectorized data.\n",":::"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['多少人為生命在努力勇敢的走下去' '對這個世界如果你有太多的抱怨' '我們是不是該知足' '為什麼人要這麼的脆弱墮落' '珍惜一切就算沒有擁有'\n"," '請你打開電視看看' '跌倒了就不敢繼續往前走']\n"]}],"source":["import jieba\n","\n","## raw corpus (list)\n","corpus_zh = [\n","    '對這個世界如果你有太多的抱怨',\n","    '跌倒了就不敢繼續往前走',\n","    '為什麼人要這麼的脆弱墮落',\n","    '請你打開電視看看',\n","    '多少人為生命在努力勇敢的走下去',\n","    '我們是不是該知足',\n","    '珍惜一切就算沒有擁有'\n","]\n","\n","## np.array\n","corpus_zh = np.array(corpus_zh)\n","\n","## vectorize\n","cv_zh = CountVectorizer(min_df=0., max_df=1.)\n","cv_zh_matrix = cv_zh.fit_transform(corpus_zh)\n","\n","# get all unique words in the corpus\n","vocab = cv_zh.get_feature_names_out()\n","print(vocab)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/alvinchen/anaconda3/envs/python-notes/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","Building prefix dict from the default dictionary ...\n","Loading model from cache /var/folders/70/qfdgs0k52qj24jtjcz7d0dkm0000gn/T/jieba.cache\n","Loading model cost 0.261 seconds.\n","Prefix dict has been built successfully.\n"]},{"name":"stdout","output_type":"stream","text":["['一切' '下去' '不敢' '世界' '了' '人為' '人要' '什麼' '你' '努力' '勇敢' '在' '墮落' '多' '多少'\n"," '太' '如果' '對' '就' '就算' '往前走' '我們' '打' '抱怨' '擁有' '是不是' '有' '沒有' '為' '珍惜'\n"," '生命' '的' '看看' '知足' '繼續' '脆弱' '該' '請' '走' '跌倒' '這個' '這麼' '開電視']\n"]}],"source":["## Define language/task-specific word tokenizer\n","def jieba_tokenizer(text):\n","    # Use Jieba to tokenize the text\n","    tokens = jieba.lcut(text)\n","    return list(tokens)\n","\n","\n","## vectorizer with self-defined tokenizer\n","cv_zh = CountVectorizer(min_df=0., max_df=1.,\n","                     tokenizer = jieba_tokenizer)\n","cv_zh_matrix = cv_zh.fit_transform(corpus_zh)\n","# get all unique words in the corpus\n","vocab = cv_zh.get_feature_names_out()\n","print(vocab)\n"]},{"cell_type":"markdown","metadata":{"id":"iaro0odYVfj4"},"source":["### N-gram Bag-of-Words Text Representation"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1709151051318,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"tyI4-EQ5Vfj4","outputId":"e6d339ff-96e8-4026-c098-db125ccbef27"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bacon eggs</th>\n","      <th>beautiful sky</th>\n","      <th>beautiful today</th>\n","      <th>blue beautiful</th>\n","      <th>blue dog</th>\n","      <th>blue sky</th>\n","      <th>breakfast sausages</th>\n","      <th>brown fox</th>\n","      <th>dog lazy</th>\n","      <th>eggs ham</th>\n","      <th>...</th>\n","      <th>lazy dog</th>\n","      <th>love blue</th>\n","      <th>love green</th>\n","      <th>quick blue</th>\n","      <th>quick brown</th>\n","      <th>sausages bacon</th>\n","      <th>sausages ham</th>\n","      <th>sky beautiful</th>\n","      <th>sky blue</th>\n","      <th>toast beans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 29 columns</p>\n","</div>"],"text/plain":["   bacon eggs  beautiful sky  beautiful today  blue beautiful  blue dog  \\\n","0           0              0                0               1         0   \n","1           0              1                0               1         0   \n","2           0              0                0               0         0   \n","3           1              0                0               0         0   \n","4           0              0                0               0         0   \n","5           0              0                0               0         1   \n","6           0              0                1               0         0   \n","7           0              0                0               0         0   \n","\n","   blue sky  breakfast sausages  brown fox  dog lazy  eggs ham  ...  lazy dog  \\\n","0         0                   0          0         0         0  ...         0   \n","1         0                   0          0         0         0  ...         0   \n","2         0                   0          1         0         0  ...         1   \n","3         0                   1          0         0         0  ...         0   \n","4         0                   0          0         0         1  ...         0   \n","5         0                   0          1         1         0  ...         0   \n","6         1                   0          0         0         0  ...         0   \n","7         0                   0          1         1         0  ...         0   \n","\n","   love blue  love green  quick blue  quick brown  sausages bacon  \\\n","0          0           0           0            0               0   \n","1          1           0           0            0               0   \n","2          0           0           0            1               0   \n","3          0           0           0            0               0   \n","4          0           1           0            0               1   \n","5          0           0           1            0               0   \n","6          0           0           0            0               0   \n","7          0           0           0            0               0   \n","\n","   sausages ham  sky beautiful  sky blue  toast beans  \n","0             0              0         1            0  \n","1             0              0         0            0  \n","2             0              0         0            0  \n","3             1              0         0            1  \n","4             0              0         0            0  \n","5             0              0         0            0  \n","6             0              1         1            0  \n","7             0              0         0            0  \n","\n","[8 rows x 29 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n","bv = CountVectorizer(ngram_range=(2, 2))\n","bv_matrix = bv.fit_transform(norm_corpus)\n","\n","bv_matrix = bv_matrix.toarray()\n","vocab = bv.get_feature_names_out()\n","pd.DataFrame(bv_matrix, columns=vocab)"]},{"cell_type":"markdown","metadata":{"id":"aPOGspFXVfj4"},"source":["### TF-IDF Model"]},{"cell_type":"markdown","metadata":{"id":"w0RGbu_xVfj4"},"source":["- TF-IDF model is an extension of the bag-of-words model, whose main objective is to adjust the raw frequency counts of the lexical features by considering the **dispersion** of the words in the corpus.\n","- **Disperson** refers to how evenly each word/term is distributed across different documents of the corpus."]},{"cell_type":"markdown","metadata":{"id":"S0g_kDB7Vfj4"},"source":["- Interaction between Word Raw Frequency Counts and Dispersion:\n","    - Given a **high-frequency** word:\n","        - If the word is widely dispersed across different documents of the corpus (i.e., **high dispersion**)\n","            - it is more likely to be semantically general.\n","        - If the word is mostly centralized in a limited set of documents in the corpus (i.e., **low dispersion**)\n","            - it is more likely to be topic-specific.\n","- Dispersion rates of words can be used as weights for the importance of word frequency counts."]},{"cell_type":"markdown","metadata":{"id":"GFokdUcDVfj4"},"source":["- **Document Frequency** (**DF**) is an intuitive metric for measuring word dispersion across the corpus. DF refers to the number of documents where the word occurs (at least once).\n","- The inverse of the DF is referred to as **Inverse Document Frequency** (**IDF**). IDF is usually computed as follows:\n","\n","$$\n","\\textit{IDF} = 1 + log\\frac{N}{1+df}\n","$$\n","\n",":::{note}\n","\n","All these plus-1's in the above formula are to avoid potential division-by-zero errors.\n","\n",":::"]},{"cell_type":"markdown","metadata":{"id":"Hij3E4a1Vfj4"},"source":["- The raw absolute frequency counts of words in the BOW model are referred to as **Term Frequency** (**TF**).\n","- The **TF-IDF** Weighting Scheme:\n","\n","$$\n","\\textit{TF-IDF}_{normalized} = \\frac{tf \\times idf}{\\sqrt{(tf\\times idf)^2}}\n","$$\n","\n","- The `tfidf` is normalized using the L2 norm, i.e., the Euclidean norm (taking the square root of the sum of the square of `tfidf` metrics)."]},{"cell_type":"markdown","metadata":{"id":"J7G958-QVfj4"},"source":[":::{seealso}\n",":class: dropdown\n","\n","The L1 and L2 norms are mathematical techniques used in machine learning for regularization, specifically in the context of linear models like linear regression or logistic regression. They are used to penalize the size of the coefficients (weights) of the model to prevent overfitting and improve generalization performance.\n","\n","1. **L1 Norm (Lasso Regularization)**:\n","   - The L1 norm calculates the absolute values of the coefficients and sums them up. It is also known as the Manhattan distance or taxicab norm.\n","   - The L1 norm tends to drive some weights to exactly 0 during the optimization process. This induces sparsity in the weights, meaning that some features are completely ignored in the model. As a result, L1 regularization can be beneficial for memory efficiency and feature selection. It helps in reducing the model complexity by eliminating irrelevant features and focusing only on the most important ones.\n","\n","2. **L2 Norm (Ridge Regularization)**:\n","   - The L2 norm calculates the square of the coefficients, sums them up, and takes the square root of the result. It is also known as the Euclidean distance or the Frobenius norm.\n","   - Unlike the L1 norm, the L2 norm does not force the weights to be exactly 0 but instead reduces them towards 0. It penalizes large weights more severely than small ones, but it rarely forces them to be exactly 0.\n","   - The L2 norm regularization is less aggressive in inducing sparsity compared to L1 regularization. It is generally used when we want to retain all parameters and avoid overfitting by preventing any of the weights from becoming too large.\n","\n","In summary, L1 regularization tends to produce sparse models by driving some coefficients to exactly 0, while L2 regularization reduces the magnitude of all coefficients without necessarily eliminating any of them. The choice between L1 and L2 regularization depends on the specific problem and the desired properties of the resulting model.\n","\n","- The L1 norm will drive some weights to 0, inducing sparsity in the weights. This can be beneficial for memory efficiency or when feature selection is needed (i.e., we want to select only certain weights).\n","\n","- The L2 norm instead will reduce all weights but not all the way to 0. This is less memory efficient but can be useful if we want/need to retain all parameters.\n","\n",":::"]},{"cell_type":"markdown","metadata":{"id":"O7gqNj4RVfj4"},"source":["### `TfidfTransformer()` from `sklearn`"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1709151051318,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"Jqy41veQVfj5","outputId":"7c149c2d-5b58-40b5-e309-5179e0ab47b3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bacon</th>\n","      <th>beans</th>\n","      <th>beautiful</th>\n","      <th>blue</th>\n","      <th>breakfast</th>\n","      <th>brown</th>\n","      <th>dog</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>green</th>\n","      <th>ham</th>\n","      <th>jumps</th>\n","      <th>kings</th>\n","      <th>lazy</th>\n","      <th>love</th>\n","      <th>quick</th>\n","      <th>sausages</th>\n","      <th>sky</th>\n","      <th>toast</th>\n","      <th>today</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.43</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.57</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.32</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.47</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.37</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.36</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.72</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   bacon  beans  beautiful  blue  breakfast  brown   dog  eggs   fox  green  \\\n","0   0.00   0.00       0.60  0.53       0.00   0.00  0.00  0.00  0.00   0.00   \n","1   0.00   0.00       0.49  0.43       0.00   0.00  0.00  0.00  0.00   0.00   \n","2   0.00   0.00       0.00  0.00       0.00   0.38  0.38  0.00  0.38   0.00   \n","3   0.32   0.38       0.00  0.00       0.38   0.00  0.00  0.32  0.00   0.00   \n","4   0.39   0.00       0.00  0.00       0.00   0.00  0.00  0.39  0.00   0.47   \n","5   0.00   0.00       0.00  0.37       0.00   0.42  0.42  0.00  0.42   0.00   \n","6   0.00   0.00       0.36  0.32       0.00   0.00  0.00  0.00  0.00   0.00   \n","7   0.00   0.00       0.00  0.00       0.00   0.45  0.45  0.00  0.45   0.00   \n","\n","    ham  jumps  kings  lazy  love  quick  sausages   sky  toast  today  \n","0  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.60   0.00    0.0  \n","1  0.00   0.00   0.00  0.00  0.57   0.00      0.00  0.49   0.00    0.0  \n","2  0.00   0.53   0.00  0.38  0.00   0.38      0.00  0.00   0.00    0.0  \n","3  0.32   0.00   0.38  0.00  0.00   0.00      0.32  0.00   0.38    0.0  \n","4  0.39   0.00   0.00  0.00  0.39   0.00      0.39  0.00   0.00    0.0  \n","5  0.00   0.00   0.00  0.42  0.00   0.42      0.00  0.00   0.00    0.0  \n","6  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.72   0.00    0.5  \n","7  0.00   0.00   0.00  0.45  0.00   0.45      0.00  0.00   0.00    0.0  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","\n","tt = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n","tt_matrix = tt.fit_transform(cv_matrix)\n","\n","tt_matrix = tt_matrix.toarray()\n","vocab = cv.get_feature_names_out()\n","pd.DataFrame(np.round(tt_matrix, 2), columns=vocab)"]},{"cell_type":"markdown","metadata":{"id":"2MtV3O2SVfj5"},"source":["### `TfidfVectorizer()` from `sklearn`"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709151051318,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"g6NvjW6xVfj5","outputId":"c3ec2c3c-af7f-4666-e225-6c41df5d8772"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bacon</th>\n","      <th>beans</th>\n","      <th>beautiful</th>\n","      <th>blue</th>\n","      <th>breakfast</th>\n","      <th>brown</th>\n","      <th>dog</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>green</th>\n","      <th>ham</th>\n","      <th>jumps</th>\n","      <th>kings</th>\n","      <th>lazy</th>\n","      <th>love</th>\n","      <th>quick</th>\n","      <th>sausages</th>\n","      <th>sky</th>\n","      <th>toast</th>\n","      <th>today</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.60</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.43</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.57</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.49</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.32</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.47</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.37</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.36</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.72</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   bacon  beans  beautiful  blue  breakfast  brown   dog  eggs   fox  green  \\\n","0   0.00   0.00       0.60  0.53       0.00   0.00  0.00  0.00  0.00   0.00   \n","1   0.00   0.00       0.49  0.43       0.00   0.00  0.00  0.00  0.00   0.00   \n","2   0.00   0.00       0.00  0.00       0.00   0.38  0.38  0.00  0.38   0.00   \n","3   0.32   0.38       0.00  0.00       0.38   0.00  0.00  0.32  0.00   0.00   \n","4   0.39   0.00       0.00  0.00       0.00   0.00  0.00  0.39  0.00   0.47   \n","5   0.00   0.00       0.00  0.37       0.00   0.42  0.42  0.00  0.42   0.00   \n","6   0.00   0.00       0.36  0.32       0.00   0.00  0.00  0.00  0.00   0.00   \n","7   0.00   0.00       0.00  0.00       0.00   0.45  0.45  0.00  0.45   0.00   \n","\n","    ham  jumps  kings  lazy  love  quick  sausages   sky  toast  today  \n","0  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.60   0.00    0.0  \n","1  0.00   0.00   0.00  0.00  0.57   0.00      0.00  0.49   0.00    0.0  \n","2  0.00   0.53   0.00  0.38  0.00   0.38      0.00  0.00   0.00    0.0  \n","3  0.32   0.00   0.38  0.00  0.00   0.00      0.32  0.00   0.38    0.0  \n","4  0.39   0.00   0.00  0.00  0.39   0.00      0.39  0.00   0.00    0.0  \n","5  0.00   0.00   0.00  0.42  0.00   0.42      0.00  0.00   0.00    0.0  \n","6  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.72   0.00    0.5  \n","7  0.00   0.00   0.00  0.45  0.00   0.45      0.00  0.00   0.00    0.0  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tv = TfidfVectorizer(min_df=0.,\n","                     max_df=1.,\n","                     norm='l2',\n","                     use_idf=True,\n","                     smooth_idf=True)\n","tv_matrix = tv.fit_transform(norm_corpus)\n","tv_matrix = tv_matrix.toarray()\n","\n","vocab = tv.get_feature_names_out()\n","pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"]},{"cell_type":"markdown","metadata":{"id":"zul6T2JuVfj5"},"source":["### Intuition of TF-IDF (Self-Study)\n","\n","The following shows the creation and computation of the TFIDF matrix step by step. Please go over the codes on your own if you are interested."]},{"cell_type":"markdown","metadata":{"id":"96S4xazqVfj9"},"source":["#### Create Vocabulary Dictionary of the Corpus"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709151051319,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"wdA67X5XVfj9","outputId":"790665d5-8396-4f27-abef-f6b019440efe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Feature Names: ['jumps', 'sky', 'dog', 'today', 'lazy', 'kings', 'breakfast', 'sausages', 'brown', 'blue', 'love', 'beautiful', 'beans', 'eggs', 'fox', 'toast', 'green', 'quick', 'ham', 'bacon']\n","Default Feature Dict: {'jumps': 0, 'sky': 0, 'dog': 0, 'today': 0, 'lazy': 0, 'kings': 0, 'breakfast': 0, 'sausages': 0, 'brown': 0, 'blue': 0, 'love': 0, 'beautiful': 0, 'beans': 0, 'eggs': 0, 'fox': 0, 'toast': 0, 'green': 0, 'quick': 0, 'ham': 0, 'bacon': 0}\n"]}],"source":["# get unique words as feature names\n","unique_words = list(\n","    set([word for doc in [doc.split() for doc in norm_corpus]\n","         for word in doc]))\n","\n","# default dict\n","def_feature_dict = {w: 0 for w in unique_words}\n","\n","print('Feature Names:', unique_words)\n","print('Default Feature Dict:', def_feature_dict)"]},{"cell_type":"markdown","metadata":{"id":"sn1f5tOTVfj-"},"source":["#### Create Document-Word Matrix (Bag-of-Word Frequencies)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1709151051846,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"CbWICcoeVfj-","outputId":"22919eca-14aa-4763-b740-6efab4ca461a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sky  blue  beautiful  jumps  dog  today  lazy  kings  breakfast  sausages  \\\n","0    1     1          1      0    0      0     0      0          0         0   \n","1    1     1          1      0    0      0     0      0          0         0   \n","2    0     0          0      1    1      0     1      0          0         0   \n","3    0     0          0      0    0      0     0      1          1         1   \n","4    0     0          0      0    0      0     0      0          0         1   \n","5    0     1          0      0    1      0     1      0          0         0   \n","6    2     1          1      0    0      1     0      0          0         0   \n","7    0     0          0      0    1      0     1      0          0         0   \n","\n","   brown  love  beans  eggs  fox  toast  green  quick  ham  bacon  \n","0      0     0      0     0    0      0      0      0    0      0  \n","1      0     1      0     0    0      0      0      0    0      0  \n","2      1     0      0     0    1      0      0      1    0      0  \n","3      0     0      1     1    0      1      0      0    1      1  \n","4      0     1      0     1    0      0      1      0    1      1  \n","5      1     0      0     0    1      0      0      1    0      0  \n","6      0     0      0     0    0      0      0      0    0      0  \n","7      1     0      0     0    1      0      0      1    0      0  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from collections import Counter\n","# build bag of words features for each document - term frequencies\n","bow_features = []\n","for doc in norm_corpus:\n","    bow_feature_doc = Counter(doc.split())\n","    # initialize default corpus dictionary\n","    all_features = Counter(def_feature_dict)\n","\n","    # update default dict with current doc words\n","    bow_feature_doc.update(all_features)\n","\n","    # append cur doc dict\n","    bow_features.append(bow_feature_doc)\n","\n","bow_features = pd.DataFrame(bow_features)\n","bow_features"]},{"cell_type":"markdown","metadata":{"id":"alZnQkGYVfj-"},"source":["#### Compute Document Frequency of Words"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1709151051846,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"BjEIUjD8Vfj-","outputId":"9342a788-1c77-43c7-8536-549d2e2761e9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sky  blue  beautiful  jumps  dog  today  lazy  kings  breakfast  sausages  \\\n","0    4     5          4      2    4      2     4      2          2         3   \n","\n","   brown  love  beans  eggs  fox  toast  green  quick  ham  bacon  \n","0      4     3      2     3    4      2      2      4    3      3  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import scipy.sparse as sp\n","feature_names = list(bow_features.columns)\n","\n","# build the document frequency matrix\n","df = np.diff(sp.csc_matrix(bow_features, copy=True).indptr)\n","# `csc_matrix()` compress `bow_features` into sparse matrix based on columns\n","# `csc_matrix.indices` stores the matrix value indices in each column\n","# `csc_matrix.indptr` stores the accumulative numbers of values from column-0 to the right-most column\n","\n","df = 1 + df  # adding 1 to smoothen idf later\n","\n","# show smoothened document frequencies\n","pd.DataFrame([df], columns=feature_names)"]},{"cell_type":"markdown","metadata":{"id":"Edgv-YR8Vfj-"},"source":["#### Create Inverse Document Frequency of Words"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1709151051846,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"QzHV2IOhVfj-","outputId":"3e663047-5011-4445-e2a4-1701468a6d7e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.81</td>\n","      <td>1.59</td>\n","      <td>1.81</td>\n","      <td>2.5</td>\n","      <td>1.81</td>\n","      <td>2.5</td>\n","      <td>1.81</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>2.1</td>\n","      <td>1.81</td>\n","      <td>2.1</td>\n","      <td>2.5</td>\n","      <td>2.1</td>\n","      <td>1.81</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>1.81</td>\n","      <td>2.1</td>\n","      <td>2.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sky  blue  beautiful  jumps   dog  today  lazy  kings  breakfast  \\\n","0  1.81  1.59       1.81    2.5  1.81    2.5  1.81    2.5        2.5   \n","\n","   sausages  brown  love  beans  eggs   fox  toast  green  quick  ham  bacon  \n","0       2.1   1.81   2.1    2.5   2.1  1.81    2.5    2.5   1.81  2.1    2.1  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# compute inverse document frequencies for each term\n","total_docs = 1 + len(norm_corpus)\n","idf = 1.0 + np.log(float(total_docs) / df)\n","\n","# show smoothened idfs\n","pd.DataFrame([np.round(idf, 2)], columns=feature_names)"]},{"cell_type":"markdown","metadata":{"id":"x-zuGo14Vfj-"},"source":["#### Compute Raw TF-IDF for Each Document"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1709151051847,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"CLqnrqxgVfj-","outputId":"4ce7a339-c307-4407-8a13-28ba92629b67"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.81</td>\n","      <td>1.59</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.81</td>\n","      <td>1.59</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2.1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.5</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>2.1</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>2.5</td>\n","      <td>2.1</td>\n","      <td>0.00</td>\n","      <td>2.5</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2.1</td>\n","      <td>2.1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.1</td>\n","      <td>0.00</td>\n","      <td>2.1</td>\n","      <td>0.0</td>\n","      <td>2.1</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>2.5</td>\n","      <td>0.00</td>\n","      <td>2.1</td>\n","      <td>2.1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.00</td>\n","      <td>1.59</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3.62</td>\n","      <td>1.59</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2.5</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.81</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sky  blue  beautiful  jumps   dog  today  lazy  kings  breakfast  \\\n","0  1.81  1.59       1.81    0.0  0.00    0.0  0.00    0.0        0.0   \n","1  1.81  1.59       1.81    0.0  0.00    0.0  0.00    0.0        0.0   \n","2  0.00  0.00       0.00    2.5  1.81    0.0  1.81    0.0        0.0   \n","3  0.00  0.00       0.00    0.0  0.00    0.0  0.00    2.5        2.5   \n","4  0.00  0.00       0.00    0.0  0.00    0.0  0.00    0.0        0.0   \n","5  0.00  1.59       0.00    0.0  1.81    0.0  1.81    0.0        0.0   \n","6  3.62  1.59       1.81    0.0  0.00    2.5  0.00    0.0        0.0   \n","7  0.00  0.00       0.00    0.0  1.81    0.0  1.81    0.0        0.0   \n","\n","   sausages  brown  love  beans  eggs   fox  toast  green  quick  ham  bacon  \n","0       0.0   0.00   0.0    0.0   0.0  0.00    0.0    0.0   0.00  0.0    0.0  \n","1       0.0   0.00   2.1    0.0   0.0  0.00    0.0    0.0   0.00  0.0    0.0  \n","2       0.0   1.81   0.0    0.0   0.0  1.81    0.0    0.0   1.81  0.0    0.0  \n","3       2.1   0.00   0.0    2.5   2.1  0.00    2.5    0.0   0.00  2.1    2.1  \n","4       2.1   0.00   2.1    0.0   2.1  0.00    0.0    2.5   0.00  2.1    2.1  \n","5       0.0   1.81   0.0    0.0   0.0  1.81    0.0    0.0   1.81  0.0    0.0  \n","6       0.0   0.00   0.0    0.0   0.0  0.00    0.0    0.0   0.00  0.0    0.0  \n","7       0.0   1.81   0.0    0.0   0.0  1.81    0.0    0.0   1.81  0.0    0.0  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# compute tfidf feature matrix\n","tf = np.array(bow_features, dtype='float64')\n","tfidf = tf * idf  ## `tf.shape` = (8,20), `idf.shape`=(20,)\n","# view raw tfidf feature matrix\n","pd.DataFrame(np.round(tfidf, 2), columns=feature_names)"]},{"cell_type":"markdown","metadata":{"id":"QnrtuImmVfj-"},"source":["#### Get L2 Norms of TF-IDF"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1709151051847,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"_pwNJOPvVfj-","outputId":"94ac3d22-f07d-4685-af9e-406c5406b1d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[3.013 3.672 4.761 6.534 5.319 4.35  5.019 4.049]\n"]}],"source":["from numpy.linalg import norm\n","\n","# compute L2 norms\n","norms = norm(tfidf, axis=1)  # get the L2 forms of tfidf according to columns\n","\n","# print norms for each document\n","print(np.round(norms, 3))"]},{"cell_type":"markdown","metadata":{"id":"pkx0lZAzVfj-"},"source":["#### Compute Normalized TF-IDF for Each Document"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709151051847,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"VJFfMKhjVfj-","outputId":"c852c7af-23cb-4ae7-9945-3dff2eeec19d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.60</td>\n","      <td>0.53</td>\n","      <td>0.60</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.49</td>\n","      <td>0.43</td>\n","      <td>0.49</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.57</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.53</td>\n","      <td>0.38</td>\n","      <td>0.0</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.38</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.32</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>0.32</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.47</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.00</td>\n","      <td>0.37</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.0</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.72</td>\n","      <td>0.32</td>\n","      <td>0.36</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.0</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sky  blue  beautiful  jumps   dog  today  lazy  kings  breakfast  \\\n","0  0.60  0.53       0.60   0.00  0.00    0.0  0.00   0.00       0.00   \n","1  0.49  0.43       0.49   0.00  0.00    0.0  0.00   0.00       0.00   \n","2  0.00  0.00       0.00   0.53  0.38    0.0  0.38   0.00       0.00   \n","3  0.00  0.00       0.00   0.00  0.00    0.0  0.00   0.38       0.38   \n","4  0.00  0.00       0.00   0.00  0.00    0.0  0.00   0.00       0.00   \n","5  0.00  0.37       0.00   0.00  0.42    0.0  0.42   0.00       0.00   \n","6  0.72  0.32       0.36   0.00  0.00    0.5  0.00   0.00       0.00   \n","7  0.00  0.00       0.00   0.00  0.45    0.0  0.45   0.00       0.00   \n","\n","   sausages  brown  love  beans  eggs   fox  toast  green  quick   ham  bacon  \n","0      0.00   0.00  0.00   0.00  0.00  0.00   0.00   0.00   0.00  0.00   0.00  \n","1      0.00   0.00  0.57   0.00  0.00  0.00   0.00   0.00   0.00  0.00   0.00  \n","2      0.00   0.38  0.00   0.00  0.00  0.38   0.00   0.00   0.38  0.00   0.00  \n","3      0.32   0.00  0.00   0.38  0.32  0.00   0.38   0.00   0.00  0.32   0.32  \n","4      0.39   0.00  0.39   0.00  0.39  0.00   0.00   0.47   0.00  0.39   0.39  \n","5      0.00   0.42  0.00   0.00  0.00  0.42   0.00   0.00   0.42  0.00   0.00  \n","6      0.00   0.00  0.00   0.00  0.00  0.00   0.00   0.00   0.00  0.00   0.00  \n","7      0.00   0.45  0.00   0.00  0.00  0.45   0.00   0.00   0.45  0.00   0.00  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# compute normalized tfidf\n","norm_tfidf = tfidf / norms[:, None]\n","\n","# show final tfidf feature matrix\n","pd.DataFrame(np.round(norm_tfidf, 2), columns=feature_names)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"elapsed":628,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"06SVHctsVfj-","outputId":"43899c4a-3baa-4650-e0ee-37c794345a2f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bacon</th>\n","      <th>beans</th>\n","      <th>beautiful</th>\n","      <th>blue</th>\n","      <th>breakfast</th>\n","      <th>brown</th>\n","      <th>dog</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>green</th>\n","      <th>ham</th>\n","      <th>jumps</th>\n","      <th>kings</th>\n","      <th>lazy</th>\n","      <th>love</th>\n","      <th>quick</th>\n","      <th>sausages</th>\n","      <th>sky</th>\n","      <th>toast</th>\n","      <th>today</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.63</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.46</td>\n","      <td>0.0</td>\n","      <td>0.63</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   bacon  beans  beautiful  blue  breakfast  brown  dog  eggs  fox  green  \\\n","0    0.0    0.0        0.0   0.0        0.0    0.0  0.0   0.0  0.0   0.63   \n","\n","   ham  jumps  kings  lazy  love  quick  sausages   sky  toast  today  \n","0  0.0    0.0    0.0   0.0   0.0    0.0       0.0  0.46    0.0   0.63  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["new_doc = 'the sky is green today'\n","\n","pd.DataFrame(np.round(tv.transform([new_doc]).toarray(), 2),\n","             columns=tv.get_feature_names_out())"]},{"cell_type":"markdown","metadata":{"id":"-99XKq_qVfj_"},"source":["## Document Similarity"]},{"cell_type":"markdown","metadata":{"id":"45z7AiTnVfj_"},"source":["- Now each document in our corpus has been transformed into a **vectorized** representation using the naive Bag-of-Words method.\n","- And we believe that these vectorized representations are indicators of textual **semantics**.\n","- This vectorized text vectorization allows us to perform mathematical computation of the **semantic relationships** between documents."]},{"cell_type":"markdown","metadata":{"id":"ROE-7oduVfj_"},"source":["### Similarity/Distance Metrics and Intuition"]},{"cell_type":"markdown","metadata":{"id":"EuBlQVWsVfj_"},"source":["Take a two-dimensional space for instance. If we have vectors on this space, we can compute their distance/similarity mathematically:"]},{"cell_type":"markdown","metadata":{"id":"pU2kdWpVVfj_"},"source":["![](../images/text-vec/text-vec.001.jpeg)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"d2foX0_nVfj_"},"outputs":[],"source":["from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances, cosine_similarity"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"gEJWX6xlVfj_","outputId":"46e3cf37-e546-4ac2-ce52-17cd9b3a63f9"},"outputs":[{"data":{"text/plain":["array([[1, 9],\n","       [1, 3],\n","       [5, 1]])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["xyz = np.array([[1, 9], [1, 3], [5, 1]])\n","xyz"]},{"cell_type":"markdown","metadata":{"id":"7AFebl8PVfj_"},"source":["In Math, there are in general two types of metrics to measure the relationship between vectors: **distance**-based vs. **similarity**-based metrics."]},{"cell_type":"markdown","metadata":{"id":"4YztoJesVfj_"},"source":["### Distance-based Metrics"]},{"cell_type":"markdown","metadata":{"id":"Ey2KSX3FVfj_"},"source":["- Many distance measures of vectors are based on the following formula and differ in individual parameter settings.\n","\n","$$\n","\\big( \\sum_{i = 1}^{n}{|x_i - y_i|^y}\\big)^{\\frac{1}{y}}\n","$$\n","\n","- The *n* in the above formula refers to the number of dimensions of the vectors. (In other words, all the concepts we discuss here can be easily extended to vectors in multidimensional spaces.)"]},{"cell_type":"markdown","metadata":{"id":"2GqFkKcSVfj_"},"source":["- When *y* is set to 2, it computes the famous **Euclidean distance** of two vectors, i.e., the direct spatial distance between two points on the *n*-dimensional space.\n","\n","$$\n","\\sqrt{\\big( \\sum_{i = 1}^{n}{|x_i - y_i|^2}\\big)}\n","$$"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"BXBdEE97Vfj_","outputId":"6f63f14d-132a-4e7a-c10f-79a822434498"},"outputs":[{"data":{"text/plain":["array([[0.        , 6.        , 8.94427191],\n","       [6.        , 0.        , 4.47213595],\n","       [8.94427191, 4.47213595, 0.        ]])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["euclidean_distances(xyz)"]},{"cell_type":"markdown","metadata":{"id":"f4gadZFgVfj_"},"source":["- The geometrical meanings of the Euclidean distance are easy to conceptualize."]},{"cell_type":"markdown","metadata":{"id":"rbpIuH1fVfj_"},"source":["![](../images/text-vec-euclidean.gif)"]},{"cell_type":"markdown","metadata":{"id":"F4aVC1F9Vfj_"},"source":["### Similarity-based Metrics"]},{"cell_type":"markdown","metadata":{"id":"K5lncS9wVfj_"},"source":["- In addition to distance-based metrics, the other type is similarity-based metric, which often utilizes the idea of **correlations**.\n","- The most commonly used one is **Cosine Similarity**, which can be computed as follows:\n","\n","$$\n","cos(\\vec{x},\\vec{y}) = \\frac{\\sum_{i=1}^{n}{x_i\\times y_i}}{\\sqrt{\\sum_{i=1}^{n}x_i^2}\\times \\sqrt{\\sum_{i=1}^{n}y_i^2}}\n","$$\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"HloB5w9dVfj_","outputId":"72ecc204-ae23-472c-c1d2-44cd3c9840d9"},"outputs":[{"data":{"text/plain":["array([[1.        , 0.97780241, 0.30320366],\n","       [0.97780241, 1.        , 0.49613894],\n","       [0.30320366, 0.49613894, 1.        ]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["cosine_similarity(xyz)"]},{"cell_type":"markdown","metadata":{"id":"bdSlksnYVfkA"},"source":["- The geometric meanings of **cosines** of two vectors are connected to the **arcs** between the vectors.\n","- The greater their cosine similarity, the smaller the arcs, the closer (i.e., the more similar) they are."]},{"cell_type":"markdown","metadata":{"id":"6Jp5myPqVfkB"},"source":["![](../images/text-vec-similarity2.png)"]},{"cell_type":"markdown","metadata":{"id":"5p5mvZWNVfkB"},"source":["![](../images/text-vec-cosine.gif)"]},{"cell_type":"markdown","metadata":{"id":"IMFRbbdBVfkB"},"source":["### Which Metrics to Use then?"]},{"cell_type":"markdown","metadata":{"id":"5CMH5RzeVfkB"},"source":["- Please note that different metrics may lead to very different results.\n","- In our earlier examples, if we adopt **euclidean distance**, then y is closer to z than is to x.\n","- But if we adopt **cosine similarity**, then y is closer to x than is to z.\n","- The choice of distance/similarity metrics depends on:\n","    - Whether the magnitude of value differences on each dimension of the vectors matters (distance-based preferred)\n","    - Whether the values of each dimension of the vectors co-vary (cosine referred)"]},{"cell_type":"markdown","metadata":{"id":"xDDkuPj5VfkB"},"source":["### Pairwise Similarity Computation"]},{"cell_type":"markdown","metadata":{"id":"lbRPeJn2VfkC"},"source":["- The `cosine_similarity` automatically computes the **pairwise** similarities between the **rows** of the input matrix."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"3ruj9aKNVfkC","outputId":"223ccca3-4523-4cea-dfbd-88a16d2f0fb2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000000</td>\n","      <td>0.820599</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.192353</td>\n","      <td>0.817246</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.820599</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.225489</td>\n","      <td>0.157845</td>\n","      <td>0.670631</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.791821</td>\n","      <td>0.000000</td>\n","      <td>0.850516</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.506866</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.225489</td>\n","      <td>0.000000</td>\n","      <td>0.506866</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.192353</td>\n","      <td>0.157845</td>\n","      <td>0.791821</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.115488</td>\n","      <td>0.930989</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.817246</td>\n","      <td>0.670631</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.115488</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.850516</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.930989</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2         3         4         5         6  \\\n","0  1.000000  0.820599  0.000000  0.000000  0.000000  0.192353  0.817246   \n","1  0.820599  1.000000  0.000000  0.000000  0.225489  0.157845  0.670631   \n","2  0.000000  0.000000  1.000000  0.000000  0.000000  0.791821  0.000000   \n","3  0.000000  0.000000  0.000000  1.000000  0.506866  0.000000  0.000000   \n","4  0.000000  0.225489  0.000000  0.506866  1.000000  0.000000  0.000000   \n","5  0.192353  0.157845  0.791821  0.000000  0.000000  1.000000  0.115488   \n","6  0.817246  0.670631  0.000000  0.000000  0.000000  0.115488  1.000000   \n","7  0.000000  0.000000  0.850516  0.000000  0.000000  0.930989  0.000000   \n","\n","          7  \n","0  0.000000  \n","1  0.000000  \n","2  0.850516  \n","3  0.000000  \n","4  0.000000  \n","5  0.930989  \n","6  0.000000  \n","7  1.000000  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["similarity_doc_matrix = cosine_similarity(tv_matrix)\n","similarity_doc_df = pd.DataFrame(similarity_doc_matrix)\n","similarity_doc_df"]},{"cell_type":"markdown","metadata":{"id":"4xoOC2s7VfkC"},"source":["## Clustering Documents Using Similarity Features"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709151052466,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"lxaRP0z9VfkC"},"outputs":[],"source":["from scipy.cluster.hierarchy import dendrogram, linkage\n","\n","Z = linkage(similarity_doc_matrix, 'ward')\n","# pd.DataFrame(Z,\n","#              columns=[\n","#                  'Document\\Cluster 1', 'Document\\Cluster 2', 'Distance',\n","#                  'Cluster Size'\n","#              ],\n","#              dtype='object')"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"executionInfo":{"elapsed":813,"status":"ok","timestamp":1709151053273,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"MFDPv_BCVfkC","outputId":"91529980-e7e7-46e8-b82f-b96ddd5b9cfe","scrolled":true},"outputs":[{"data":{"text/plain":["<matplotlib.lines.Line2D at 0x177c963d0>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 360x216 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.figure(figsize=(5, 3))\n","plt.title('Hierarchical Clustering Dendrogram')\n","plt.xlabel('Data point')\n","plt.ylabel('Distance')\n","dendrogram(Z)\n","plt.axhline(y=1.0, c='k', ls='--', lw=0.5)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709151053273,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"rRH7VrP9VfkC","outputId":"0bf3df57-0a89-4ba4-b905-f51aac23e42f","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document</th>\n","      <th>Category</th>\n","      <th>ClusterLabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The sky is blue and beautiful.</td>\n","      <td>weather</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this blue and beautiful sky!</td>\n","      <td>weather</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The quick brown fox jumps over the lazy dog.</td>\n","      <td>animals</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n","      <td>food</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I love green eggs, ham, sausages and bacon!</td>\n","      <td>food</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The brown fox is quick and the blue dog is lazy!</td>\n","      <td>animals</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The sky is very blue and the sky is very beautiful today</td>\n","      <td>weather</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The dog is lazy but the brown fox is quick!</td>\n","      <td>animals</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                             Document  \\\n","0                                      The sky is blue and beautiful.   \n","1                                   Love this blue and beautiful sky!   \n","2                        The quick brown fox jumps over the lazy dog.   \n","3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n","4                         I love green eggs, ham, sausages and bacon!   \n","5                    The brown fox is quick and the blue dog is lazy!   \n","6            The sky is very blue and the sky is very beautiful today   \n","7                         The dog is lazy but the brown fox is quick!   \n","\n","  Category  ClusterLabel  \n","0  weather             2  \n","1  weather             2  \n","2  animals             1  \n","3     food             3  \n","4     food             3  \n","5  animals             1  \n","6  weather             2  \n","7  animals             1  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["## Convert hierarchical cluster into a flat cluster structure\n","\n","from scipy.cluster.hierarchy import fcluster\n","max_dist = 1.0\n","\n","cluster_labels = fcluster(Z, max_dist, criterion='distance')\n","cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n","pd.concat([corpus_df, cluster_labels], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"Ms_v2J_DVfkC"},"source":["## Clustering Words Using Similarity Features"]},{"cell_type":"markdown","metadata":{"id":"DSLzjUmVVfkC"},"source":["- We can also transpose the `tv_matrix` to get a Word-Document matrix.\n","- Each word can be represented as vectors based on their document distributions.\n","- Words that are semantically similar tend to show similar distributions.\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709151053273,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"4gdtNSvDVfkC","outputId":"740dbba2-431b-4d0e-9a6e-8a5f9721f41d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sky</th>\n","      <th>blue</th>\n","      <th>beautiful</th>\n","      <th>jumps</th>\n","      <th>dog</th>\n","      <th>today</th>\n","      <th>lazy</th>\n","      <th>kings</th>\n","      <th>breakfast</th>\n","      <th>sausages</th>\n","      <th>brown</th>\n","      <th>love</th>\n","      <th>beans</th>\n","      <th>eggs</th>\n","      <th>fox</th>\n","      <th>toast</th>\n","      <th>green</th>\n","      <th>quick</th>\n","      <th>ham</th>\n","      <th>bacon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sky</th>\n","      <td>1.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>blue</th>\n","      <td>0.631290</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>beautiful</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.899485</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.473517</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.951208</td>\n","      <td>0.00000</td>\n","      <td>0.420997</td>\n","    </tr>\n","    <tr>\n","      <th>jumps</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.899485</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.252766</td>\n","      <td>0.252766</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.252766</td>\n","      <td>0.425922</td>\n","      <td>0.252766</td>\n","      <td>0.000000</td>\n","      <td>0.855597</td>\n","      <td>0.00000</td>\n","      <td>0.378680</td>\n","    </tr>\n","    <tr>\n","      <th>dog</th>\n","      <td>0.631290</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>today</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>lazy</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>kings</th>\n","      <td>1.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>breakfast</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>sausages</th>\n","      <td>0.775547</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.775547</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.568135</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>brown</th>\n","      <td>1.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>love</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.528473</td>\n","      <td>0.528473</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.528473</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>beans</th>\n","      <td>0.631290</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>eggs</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>fox</th>\n","      <td>0.440615</td>\n","      <td>0.00000</td>\n","      <td>0.473517</td>\n","      <td>0.425922</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>0.568135</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.382602</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>toast</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.252766</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.528473</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>green</th>\n","      <td>1.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.775547</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","      <td>0.440615</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.63129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>quick</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.951208</td>\n","      <td>0.855597</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.382602</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.680330</td>\n","    </tr>\n","    <tr>\n","      <th>ham</th>\n","      <td>0.631290</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.631290</td>\n","      <td>0.000000</td>\n","      <td>1.00000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>bacon</th>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.420997</td>\n","      <td>0.378680</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.680330</td>\n","      <td>0.00000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                sky     blue  beautiful     jumps      dog     today  \\\n","sky        1.000000  0.63129   0.000000  0.000000  0.63129  0.000000   \n","blue       0.631290  1.00000   0.000000  0.000000  1.00000  0.000000   \n","beautiful  0.000000  0.00000   1.000000  0.899485  0.00000  0.000000   \n","jumps      0.000000  0.00000   0.899485  1.000000  0.00000  0.252766   \n","dog        0.631290  1.00000   0.000000  0.000000  1.00000  0.000000   \n","today      0.000000  0.00000   0.000000  0.252766  0.00000  1.000000   \n","lazy       0.000000  0.00000   0.000000  0.252766  0.00000  1.000000   \n","kings      1.000000  0.63129   0.000000  0.000000  0.63129  0.000000   \n","breakfast  0.000000  0.00000   0.000000  0.252766  0.00000  1.000000   \n","sausages   0.775547  0.00000   0.000000  0.000000  0.00000  0.000000   \n","brown      1.000000  0.63129   0.000000  0.000000  0.63129  0.000000   \n","love       0.000000  0.00000   0.000000  0.000000  0.00000  0.528473   \n","beans      0.631290  1.00000   0.000000  0.000000  1.00000  0.000000   \n","eggs       0.000000  0.00000   0.000000  0.252766  0.00000  1.000000   \n","fox        0.440615  0.00000   0.473517  0.425922  0.00000  0.000000   \n","toast      0.000000  0.00000   0.000000  0.252766  0.00000  1.000000   \n","green      1.000000  0.63129   0.000000  0.000000  0.63129  0.000000   \n","quick      0.000000  0.00000   0.951208  0.855597  0.00000  0.000000   \n","ham        0.631290  1.00000   0.000000  0.000000  1.00000  0.000000   \n","bacon      0.000000  0.00000   0.420997  0.378680  0.00000  0.000000   \n","\n","               lazy     kings  breakfast  sausages     brown      love  \\\n","sky        0.000000  1.000000   0.000000  0.775547  1.000000  0.000000   \n","blue       0.000000  0.631290   0.000000  0.000000  0.631290  0.000000   \n","beautiful  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n","jumps      0.252766  0.000000   0.252766  0.000000  0.000000  0.000000   \n","dog        0.000000  0.631290   0.000000  0.000000  0.631290  0.000000   \n","today      1.000000  0.000000   1.000000  0.000000  0.000000  0.528473   \n","lazy       1.000000  0.000000   1.000000  0.000000  0.000000  0.528473   \n","kings      0.000000  1.000000   0.000000  0.775547  1.000000  0.000000   \n","breakfast  1.000000  0.000000   1.000000  0.000000  0.000000  0.528473   \n","sausages   0.000000  0.775547   0.000000  1.000000  0.775547  0.000000   \n","brown      0.000000  1.000000   0.000000  0.775547  1.000000  0.000000   \n","love       0.528473  0.000000   0.528473  0.000000  0.000000  1.000000   \n","beans      0.000000  0.631290   0.000000  0.000000  0.631290  0.000000   \n","eggs       1.000000  0.000000   1.000000  0.000000  0.000000  0.528473   \n","fox        0.000000  0.440615   0.000000  0.568135  0.440615  0.000000   \n","toast      1.000000  0.000000   1.000000  0.000000  0.000000  0.528473   \n","green      0.000000  1.000000   0.000000  0.775547  1.000000  0.000000   \n","quick      0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n","ham        0.000000  0.631290   0.000000  0.000000  0.631290  0.000000   \n","bacon      0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n","\n","             beans      eggs       fox     toast     green     quick      ham  \\\n","sky        0.63129  0.000000  0.440615  0.000000  1.000000  0.000000  0.63129   \n","blue       1.00000  0.000000  0.000000  0.000000  0.631290  0.000000  1.00000   \n","beautiful  0.00000  0.000000  0.473517  0.000000  0.000000  0.951208  0.00000   \n","jumps      0.00000  0.252766  0.425922  0.252766  0.000000  0.855597  0.00000   \n","dog        1.00000  0.000000  0.000000  0.000000  0.631290  0.000000  1.00000   \n","today      0.00000  1.000000  0.000000  1.000000  0.000000  0.000000  0.00000   \n","lazy       0.00000  1.000000  0.000000  1.000000  0.000000  0.000000  0.00000   \n","kings      0.63129  0.000000  0.440615  0.000000  1.000000  0.000000  0.63129   \n","breakfast  0.00000  1.000000  0.000000  1.000000  0.000000  0.000000  0.00000   \n","sausages   0.00000  0.000000  0.568135  0.000000  0.775547  0.000000  0.00000   \n","brown      0.63129  0.000000  0.440615  0.000000  1.000000  0.000000  0.63129   \n","love       0.00000  0.528473  0.000000  0.528473  0.000000  0.000000  0.00000   \n","beans      1.00000  0.000000  0.000000  0.000000  0.631290  0.000000  1.00000   \n","eggs       0.00000  1.000000  0.000000  1.000000  0.000000  0.000000  0.00000   \n","fox        0.00000  0.000000  1.000000  0.000000  0.440615  0.382602  0.00000   \n","toast      0.00000  1.000000  0.000000  1.000000  0.000000  0.000000  0.00000   \n","green      0.63129  0.000000  0.440615  0.000000  1.000000  0.000000  0.63129   \n","quick      0.00000  0.000000  0.382602  0.000000  0.000000  1.000000  0.00000   \n","ham        1.00000  0.000000  0.000000  0.000000  0.631290  0.000000  1.00000   \n","bacon      0.00000  0.000000  0.000000  0.000000  0.000000  0.680330  0.00000   \n","\n","              bacon  \n","sky        0.000000  \n","blue       0.000000  \n","beautiful  0.420997  \n","jumps      0.378680  \n","dog        0.000000  \n","today      0.000000  \n","lazy       0.000000  \n","kings      0.000000  \n","breakfast  0.000000  \n","sausages   0.000000  \n","brown      0.000000  \n","love       0.000000  \n","beans      0.000000  \n","eggs       0.000000  \n","fox        0.000000  \n","toast      0.000000  \n","green      0.000000  \n","quick      0.680330  \n","ham        0.000000  \n","bacon      1.000000  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["similarity_term_matrix = cosine_similarity(np.transpose(tv_matrix))\n","similarity_term_df = pd.DataFrame(similarity_term_matrix,\n","                                  columns=feature_names,\n","                                  index=feature_names)\n","similarity_term_df"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709151053273,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"84M3xw4HVfkC"},"outputs":[],"source":["Z2 = linkage(similarity_term_matrix, 'ward')\n","# pd.DataFrame(Z2,\n","#              columns=[\n","#                  'Document\\Cluster 1', 'Document\\Cluster 2', 'Distance',\n","#                  'Cluster Size'\n","#              ],\n","#              dtype='object')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"executionInfo":{"elapsed":918,"status":"ok","timestamp":1709151054187,"user":{"displayName":"Alvin Chen","userId":"06244732172561186175"},"user_tz":-480},"id":"3Mu-SCksVfkC","outputId":"4b03fb97-5911-446a-dfb4-bbcad1bb9c2b","scrolled":true},"outputs":[{"data":{"text/plain":["<matplotlib.lines.Line2D at 0x177da9040>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 504x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.figure(figsize=(7, 4))\n","plt.title('Hierarchical Clustering Dendrogram')\n","plt.xlabel('Data point')\n","plt.ylabel('Distance')\n","dendrogram(Z2, labels=feature_names, leaf_rotation=90)\n","plt.axhline(y=1.0, c='k', ls='--', lw=0.5)"]},{"cell_type":"markdown","metadata":{"id":"tpQVZD04VfkC"},"source":["## Notes on Word Vectors"]},{"cell_type":"markdown","metadata":{"id":"odnzszvYVfkC"},"source":["- In the previous section, we talk about how we can utilize the **Word-Document Matrix** to create vectorized representations of words for a corpus.\n","- This initial effort of representing words using their frequency distributions is referred to as a traditional **count-based** approach to word representations.\n","- This **count-base**d feature engineering strategy can be further sophisticated in several ways:\n","    - We can further limit the Word-Document Matrix to a Word-Word Co-occurrence Matrix, where the counts refer to the number of times when the two words co-occur within a specific window frame.\n","    - We can transform the sparse word vectors in the Word-Document Matrix or Word-Word Co-occurrence Matrix using statistical methods (e.g., Latent Semantic Analysis) and build the dense word vectors.\n","- It should be noted that the count-based approach relies on the creation of the word distribution for the entire corpus in the first place. This can be difficult when we deal with a large corpus.\n","- In contrast to the traditional count-based approach, **predicative methods** like neural network based language models try to predict words from their neighboring words by looking at word sequences in the corpus in a piecemeal fashion. Through this process the model learns the distributed representations of words, i.e, word embeddings.\n","- We will come back to \"word embeddings\" when we work on the deep learning NLP.\n","- Recommended Reading: [Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors](https://www.aclweb.org/anthology/P14-1023.pdf) by Baroni et al."]},{"cell_type":"markdown","metadata":{"id":"rFCggGjuVfkC"},"source":[":::{tip}\n","Latent Semantic Analysis (aka. Latent Semantic Indexing) learns latent topics by performing a matrix decomposition on the document-term matrix using Singular value decomposition. LSA is typically used as a dimension reduction or noise reducing technique.\n",":::"]},{"cell_type":"markdown","metadata":{"id":"VA7eILtcVfkD"},"source":["## References\n","\n","- Based on Sarkar (2020), Ch 4 Feature Engineering and Text Representation"]}],"metadata":{"anaconda-cloud":{},"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"python-notes","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}
