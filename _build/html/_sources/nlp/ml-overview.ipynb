{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning: Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simply put, ML is the science of programming computers so that they can learn from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "```{epigraph}\n",
    "\n",
    "[Machine learning is the] field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "-- Arthur Samuel, 1959\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{epigraph}\n",
    "\n",
    "A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with eexperience E.\n",
    "\n",
    "-- Tom Mitchell, 1997\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why use machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Limitations of rules/heuristics-based systems:\n",
    "    - Rules are hard to be exhaustively listed.\n",
    "    - Tasks are simply too complex for rule generalization.\n",
    "    - The rule-based deductive approach is not helpful in discovering novel things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can categorize ML into four types according to the amount and type of supervision it gets during training:\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Semisupervised Learning\n",
    "- Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised Learning\n",
    "\n",
    "- The data we feed to the ML algorithm includes the desired solutions, i.e., labels.\n",
    "    - Classification task (e.g., spam filter): the target is a categorical label.\n",
    "    - Regression task (e.g., car price prediction): the target is a numeric value.\n",
    "- Classification and regression are two sides of the coin.\n",
    "    - We can sometimes utilize regression algorithms for classification.\n",
    "    - A classic example is Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Examples of Supervised Learning\n",
    "    - K-Nearest Neighbors\n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machines (SVMs)\n",
    "    - Decision Trees and Random Forests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "- The data is unlabeled. We are more interested in the underlying grouping patterns of the data.\n",
    "    - Clustering\n",
    "    - Anomaly/Novelty detection\n",
    "    - Dimensionality reduction\n",
    "    - Association learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Examples of Unsupervised Learning\n",
    "    - Clustering\n",
    "        - K-means\n",
    "        - Hierarchical Clustering\n",
    "    - Dimensionality reduction\n",
    "        - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Semisupervised Learning\n",
    "\n",
    "- It's a combination of supervised and unsupervised learning.\n",
    "- For example, we start with unlabeled training data and use unsupervised learning to find groups. Users then label these groups with meaningful labels and then transform the task into a supervised learning.\n",
    "- A classific example is the photo-hosting service (e.g., face tagging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "- This type of learning is often used in robots.\n",
    "- The learning system, called an Agent, will learn based on its observation of the environment. During the learning process, the agent will select and perform actions, and get rewards or penalties in return. Through this trial-and-error process, it will figure the most optimal strategy (i.e., policy) for the target task.\n",
    "- A classific example is DeepMind's AlphaGo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow for Building a Machine Learning Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In NLP, most often we deal with **classification** problems. In particular, we  deal with **supervised classifcation** learning problems.\n",
    "\n",
    "- Given a dataset of **texts** and their corresponding **labels**, the objectives of the classifier are:\n",
    "    - How can we identify particular features of language data that are salient for texts of each label?\n",
    "    - How can we construct models of language that can be used to perform the classification automatically?\n",
    "    - What can we learn about language from these classifiers?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A common workflow for classifier building as shown as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{figure} ../images/nltk-fig-6-1-classification-workflow.png\n",
    "\n",
    "Workflow for Building Classifiers (from NLTK Book Ch 6, Figure 6-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{tip}\n",
    "Most classification methods require that features be encoded using simple value types, such as booleans, numbers, and strings. But note that just because a feature has a simple type, this does not necessarily mean that the feature's value is simple to express or compute. Indeed, it is even possible to use very complex and informative values, such as the output of a second supervised classifier, as features.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Insufficient quantity of training data\n",
    "- Non-representative training data\n",
    "- Poor quality data\n",
    "- Irrelevant features\n",
    "- Overfitting the training data\n",
    "- Underfitting the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing and Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Hyperparameter tuning and model selection\n",
    "- Data mismatch"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
