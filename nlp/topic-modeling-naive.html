

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Topic Modeling: A Naive Example &#8212; ENC2045 Computational Linguistics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nlp/topic-modeling-naive';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neural Network From Scratch" href="dl-neural-network-from-scratch.html" />
    <link rel="prev" title="Emsemble Learning" href="ml-emsemble-learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/ntnu-word-2.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/ntnu-word-2.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">INTRODUCTION</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="nlp-primer.html">Natural Language Processing: A Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp-pipeline.html">NLP Pipeline</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Preprocessing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="text-preprocessing.html">Text Preprocessing</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="text-normalization-eng.html">Text Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-tokenization.html">Text Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-enrichment.html">Text Enrichment</a></li>
<li class="toctree-l2"><a class="reference internal" href="chinese-word-seg.html">Chinese Word Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="google-colab.html">Google Colab</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Vectorization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="text-vec-traditional.html">Text Vectorization Using Traditional Methods</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml-overview.html">Machine Learning: Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-simple-case.html">Machine Learning: A Simple Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-algorithm.html">Classification Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine-Learning NLP</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml-common-nlp-tasks.html">Common NLP Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-sklearn-classification.html">Sentiment Analysis Using Bag-of-Words</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-emsemble-learning.html">Emsemble Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Topic Modeling: A Naive Example</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning NLP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-neural-network-from-scratch.html">Neural Network From Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-simple-case.html">Deep Learning: A Simple Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-sentiment-case.html">Deep Learning: Sentiment Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Language Model and Embeddings</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-sequence-models-intuition.html">Sequence Models Intuition</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-neural-language-model-primer.html">Neural Language Model: A Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="text-vec-embedding.html">Word Embeddings</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequence Models, Attention, Transformers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dl-attention-transformer-intuition.html">Attention and Transformers: Intuitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl-seq-to-seq-attention-addition.html">Sequence Model with Attention for Addition Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="langchain-llm-intro.html">Large Language Model (Under Construction…)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercise/1-python-basics.html">1. Assignment I: Python Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/2-preprocessing.html">2. Assignment II: Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/3-chinese-nlp.html">3. Assignment III: Chinese Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/4-text-vectorization.html">4. Assignment IV: Text Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/5-machine-learning.html">5. Assignment V: Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/6-topic-modeling.html">6. Assignment VI: Topic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/7-dl-chinese-name-gender.html">7. Assignment VII: Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/8-sentiment-analysis-dl.html">8. Assignment VIII: Sentiment Analysis Using Deep Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exams</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercise/midterm-exam-112.html">Midterm Exam</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/nlp/topic-modeling-naive.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nlp/topic-modeling-naive.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Topic Modeling: A Naive Example</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-topic-modeling">What is Topic Modeling?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#flowchart-for-topic-modeling">Flowchart for Topic Modeling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation-and-preprocessing">Data Preparation and Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-necessary-dependencies-and-settings">Import Necessary Dependencies and Settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-corpus">Simple Corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-text-pre-processing">Simple Text Pre-processing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-vectorization">Text Vectorization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bag-of-words-model">Bag of Words Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-dirichlet-allocation">Latent Dirichlet Allocation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuition-of-lda">Intuition of LDA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-lda-model">Building LDA Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-performance-metrics">Model Performance Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#document-by-topic-matrix">Document-by-Topic Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-by-word-matrix">Topic-by-Word Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-meanings-of-topics">Interpreting the Meanings of Topics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topics-in-documents">Topics in Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-documents-using-topic-model-features">Clustering documents using topic model features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-topic-models">Visualizing Topic Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-for-topic-number">Grid Search for Topic Number</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-the-grid-search-results">Examining the Grid Search Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-prediction">Topic Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-notes">Additional Notes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="topic-modeling-a-naive-example">
<h1><a class="toc-backref" href="#id1">Topic Modeling: A Naive Example</a><a class="headerlink" href="#topic-modeling-a-naive-example" title="Permalink to this headline">#</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#topic-modeling-a-naive-example" id="id1">Topic Modeling: A Naive Example</a></p>
<ul>
<li><p><a class="reference internal" href="#what-is-topic-modeling" id="id2">What is Topic Modeling?</a></p></li>
<li><p><a class="reference internal" href="#flowchart-for-topic-modeling" id="id3">Flowchart for Topic Modeling</a></p></li>
<li><p><a class="reference internal" href="#data-preparation-and-preprocessing" id="id4">Data Preparation and Preprocessing</a></p>
<ul>
<li><p><a class="reference internal" href="#import-necessary-dependencies-and-settings" id="id5">Import Necessary Dependencies and Settings</a></p></li>
<li><p><a class="reference internal" href="#simple-corpus" id="id6">Simple Corpus</a></p></li>
<li><p><a class="reference internal" href="#simple-text-pre-processing" id="id7">Simple Text Pre-processing</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#text-vectorization" id="id8">Text Vectorization</a></p>
<ul>
<li><p><a class="reference internal" href="#bag-of-words-model" id="id9">Bag of Words Model</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#latent-dirichlet-allocation" id="id10">Latent Dirichlet Allocation</a></p>
<ul>
<li><p><a class="reference internal" href="#intuition-of-lda" id="id11">Intuition of LDA</a></p></li>
<li><p><a class="reference internal" href="#building-lda-model" id="id12">Building LDA Model</a></p></li>
<li><p><a class="reference internal" href="#model-performance-metrics" id="id13">Model Performance Metrics</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#interpretation" id="id14">Interpretation</a></p>
<ul>
<li><p><a class="reference internal" href="#document-by-topic-matrix" id="id15">Document-by-Topic Matrix</a></p></li>
<li><p><a class="reference internal" href="#topic-by-word-matrix" id="id16">Topic-by-Word Matrix</a></p></li>
<li><p><a class="reference internal" href="#interpreting-the-meanings-of-topics" id="id17">Interpreting the Meanings of Topics</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#topics-in-documents" id="id18">Topics in Documents</a></p></li>
<li><p><a class="reference internal" href="#clustering-documents-using-topic-model-features" id="id19">Clustering documents using topic model features</a></p></li>
<li><p><a class="reference internal" href="#visualizing-topic-models" id="id20">Visualizing Topic Models</a></p></li>
<li><p><a class="reference internal" href="#hyperparameter-tuning" id="id21">Hyperparameter Tuning</a></p>
<ul>
<li><p><a class="reference internal" href="#grid-search-for-topic-number" id="id22">Grid Search for Topic Number</a></p></li>
<li><p><a class="reference internal" href="#examining-the-grid-search-results" id="id23">Examining the Grid Search Results</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#topic-prediction" id="id24">Topic Prediction</a></p></li>
<li><p><a class="reference internal" href="#additional-notes" id="id25">Additional Notes</a></p></li>
<li><p><a class="reference internal" href="#challenges" id="id26">Challenges</a></p></li>
<li><p><a class="reference internal" href="#references" id="id27">References</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="what-is-topic-modeling">
<h2><a class="toc-backref" href="#id2">What is Topic Modeling?</a><a class="headerlink" href="#what-is-topic-modeling" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Topic modeling is an <strong>unsupervised</strong> learning method, whose objective is to extract the underlying semantic patterns among a collection of texts. These underlying semantic structures are commonly referred to as <strong>topics</strong> of the corpus.</p></li>
<li><p>In particular, topic modeling first extracts features from the words in the documents and use mathematical structures and frameworks like matrix factorization and SVD (Singular Value Decomposition) to identify clusters of words that share greater semantic coherence.</p></li>
<li><p>These clusters of words form the notions of <em>topics</em>.</p></li>
<li><p>Meanwhile, the mathematical framework will also determine the distribution of these <strong>topics</strong> for each document.</p></li>
</ul>
<ul class="simple">
<li><p>In short, an intuitive understanding of Topic Modeling:</p>
<ul>
<li><p>Each <strong>document</strong> consists of several <strong>topics</strong> (a distribution of different topics).</p></li>
<li><p>Each topic is connected to particular groups of <strong>words</strong> (a distribution of different words).</p></li>
<li><p>With our current data collection, we use the mathmeatical algorithm (i.e., Latent Dirichlet Allocation) to learn these document-by-topic and topic-by-word distributions in an unsupervised way.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Potential applications of LDA</p>
<ul>
<li><p>Topic discovery and document classication</p></li>
<li><p>Information retrievel based on topic clusters</p></li>
<li><p>Content recommendation by modeling the topics of interest to a user</p></li>
<li><p>Understanding trends over time</p></li>
</ul>
</li>
</ul>
</section>
<section id="flowchart-for-topic-modeling">
<h2><a class="toc-backref" href="#id3">Flowchart for Topic Modeling</a><a class="headerlink" href="#flowchart-for-topic-modeling" title="Permalink to this headline">#</a></h2>
<p><img alt="" src="../_images/topic-modeling-pipeline.jpeg" /></p>
</section>
<section id="data-preparation-and-preprocessing">
<h2><a class="toc-backref" href="#id4">Data Preparation and Preprocessing</a><a class="headerlink" href="#data-preparation-and-preprocessing" title="Permalink to this headline">#</a></h2>
<section id="import-necessary-dependencies-and-settings">
<h3><a class="toc-backref" href="#id5">Import Necessary Dependencies and Settings</a><a class="headerlink" href="#import-necessary-dependencies-and-settings" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> <span class="c1">## silent non-critical warnings</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># %matplotlib inline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simple-corpus">
<h3><a class="toc-backref" href="#id6">Simple Corpus</a><a class="headerlink" href="#simple-corpus" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>We will be using again a simple corpus for illustration.</p></li>
<li><p>It is a corpus consisting of eight documents, each of which consists of a simple sentence.</p></li>
<li><p>Please note that usually for the task of topic modeling, we do not have the topic categories for the documents in the corpus.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;The sky is blue and beautiful.&#39;</span><span class="p">,</span> <span class="s1">&#39;Love this blue and beautiful sky!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The quick brown fox jumps over the lazy dog.&#39;</span><span class="p">,</span>
    <span class="s2">&quot;A king&#39;s breakfast has sausages, ham, bacon, eggs, toast and beans&quot;</span><span class="p">,</span>
    <span class="s1">&#39;I love green eggs, ham, sausages and bacon!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The brown fox is quick and the blue dog is lazy!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The sky is very blue and the sky is very beautiful today&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The dog is lazy but the brown fox is quick!&#39;</span>
<span class="p">]</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">corpus_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Document&#39;</span><span class="p">:</span> <span class="n">corpus</span><span class="p">})</span>
<span class="n">corpus_df</span> <span class="o">=</span> <span class="n">corpus_df</span><span class="p">[[</span><span class="s1">&#39;Document&#39;</span><span class="p">]]</span>
<span class="n">corpus_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Document</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The sky is blue and beautiful.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Love this blue and beautiful sky!</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The quick brown fox jumps over the lazy dog.</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>
    </tr>
    <tr>
      <th>4</th>
      <td>I love green eggs, ham, sausages and bacon!</td>
    </tr>
    <tr>
      <th>5</th>
      <td>The brown fox is quick and the blue dog is lazy!</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The sky is very blue and the sky is very beautiful today</td>
    </tr>
    <tr>
      <th>7</th>
      <td>The dog is lazy but the brown fox is quick!</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="simple-text-pre-processing">
<h3><a class="toc-backref" href="#id7">Simple Text Pre-processing</a><a class="headerlink" href="#simple-text-pre-processing" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Depending on the nature of the raw corpus data, we may need to implement more specific steps in text preprocessing.</p></li>
<li><p>In our current naive example, we may consider:</p>
<ul>
<li><p>removing symbols and punctuations</p></li>
<li><p>normalizing the letter case</p></li>
<li><p>stripping unnecessary/redundant whitespaces</p></li>
<li><p>removing stopwords (which requires an intermediate tokenization step)</p></li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Other important considerations in text preprocessing include:</p>
<ul class="simple">
<li><p>whether to remove hyphens</p></li>
<li><p>whether to lemmatize word forms</p></li>
<li><p>whether to stemmatize word forms</p></li>
<li><p>whether to remove short word tokens (e.g., disyllabic or multisyllabic words)</p></li>
<li><p>whether to remove unknown words (e.g., words not listed in WordNet)</p></li>
<li><p>whether to remove functional words (e.g., including only content words, such as nouns, verbs, adjectives)</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Initialize word-tokenizer</span>
<span class="n">wpt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">WordPunctTokenizer</span><span class="p">()</span>

<span class="c1">## Prepare English stopword list</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">normalize_document</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[^a-zA-Z\s]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">I</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">A</span><span class="p">)</span> <span class="c1">## punks, symbols</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="c1">## casing</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1">## redundant spaces</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">wpt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="c1">## word-tokenize</span>
    <span class="n">filtered_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span> <span class="c1">## stopwords</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered_tokens</span><span class="p">)</span> <span class="c1">## concat</span>
    <span class="k">return</span> <span class="n">doc</span>

<span class="c1">## Vectorize the function (applicable to a list)</span>
<span class="n">normalize_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">normalize_document</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## proprocess corpus</span>
<span class="n">norm_corpus</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">norm_corpus</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;sky blue beautiful&#39;, &#39;love blue beautiful sky&#39;,
       &#39;quick brown fox jumps lazy dog&#39;,
       &#39;kings breakfast sausages ham bacon eggs toast beans&#39;,
       &#39;love green eggs ham sausages bacon&#39;,
       &#39;brown fox quick blue dog lazy&#39;, &#39;sky blue sky beautiful today&#39;,
       &#39;dog lazy brown fox quick&#39;], dtype=&#39;&lt;U51&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">norm_corpus</span></code> will be the input for our next step, text vectorization.</p></li>
</ul>
</section>
</section>
<section id="text-vectorization">
<h2><a class="toc-backref" href="#id8">Text Vectorization</a><a class="headerlink" href="#text-vectorization" title="Permalink to this headline">#</a></h2>
<section id="bag-of-words-model">
<h3><a class="toc-backref" href="#id9">Bag of Words Model</a><a class="headerlink" href="#bag-of-words-model" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In topic modeling, the simplest method of text vectorization involves using the naive Bag-of-Words (BOW) model.</p></li>
<li><p>Key characteristics of the BOW model:</p>
<ul>
<li><p>It converts texts into numeric representations by tallying the frequency of words in the corpus vocabulary.</p></li>
<li><p>Sequential word order is disregarded in this approach.</p></li>
<li><p>Various filtering techniques can be applied to the document-by-word matrix. (For more details, refer to the lecture notes on <a class="reference internal" href="text-vec-traditional.html"><span class="doc std std-doc">Lecture Notes: Text Vectorization</span></a>)</p></li>
</ul>
</li>
<li><p>For topic modeling, it’s advisable to utilize the <strong>count-based</strong> vectorizer. Most topic modeling algorithms will handle weightings during mathematical computations.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>We should use <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> instead of <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code> when fitting LDA  because LDA is based on term count and document count.</p></li>
<li><p>Fitting LDA with <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code> will result in rare words being dis-proportionally sampled.</p></li>
<li><p>As a result, they will have greater impact and influence on the final topic distribution.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Countvectorize</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;8x20 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 42 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Inspect BOA matrix</span>
<span class="c1">## warning might give a memory error if data is too big</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],
       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],
       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],
       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Check all lexical features</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>

<span class="c1">## View BOA in df</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="latent-dirichlet-allocation">
<h2><a class="toc-backref" href="#id10">Latent Dirichlet Allocation</a><a class="headerlink" href="#latent-dirichlet-allocation" title="Permalink to this headline">#</a></h2>
<section id="intuition-of-lda">
<h3><a class="toc-backref" href="#id11">Intuition of LDA</a><a class="headerlink" href="#intuition-of-lda" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Latent Dirichlet Allocation (LDA) is a method used to uncover the underlying themes or topics in a collection of documents.</p></li>
<li><p>In LDA, a “topic” represents a distribution of words across the entire vocabulary of the corpus. Essentially, it tells us which words are likely to co-occur together within a topic.</p></li>
<li><p>Specifically, LDA operates by assuming that each document is generated based on two crucial probabilistic models: document-by-topic and topic-by-word models.</p></li>
</ul>
<ul class="simple">
<li><p>LDA provides us with two main matrices:</p>
<ul>
<li><p>the Topic by Word Matrix, which shows the likelihood of words being associated with specific topics;</p></li>
<li><p>the Document by Topic Matrix, which indicates the likelihood of documents being associated with specific topics.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>To understand a topic, we look at the ranked list of the most probable words within that topic. However, since common words often rank high across multiple topics, it can be challenging to distinguish between them.</p></li>
<li><p>To overcome this, LDA offers insights into both the frequency of words within each topic and the exclusivity (i.e., the association) of words to a particular topic, helping us understand how strongly each word relates to its assigned topic.</p></li>
</ul>
</section>
<section id="building-lda-model">
<h3><a class="toc-backref" href="#id12">Building LDA Model</a><a class="headerlink" href="#building-lda-model" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span> 

<span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1">## Number of topics to generate by the LDA model.</span>
                                <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>  <span class="c1">## Maximum number of iterations for the optimization algorithm.</span>
                                <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1">## Random Seed</span>

<span class="n">doc_topic_matrix</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>  <span class="c1"># Fit the LDA model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1.81 s, sys: 1.87 ms, total: 1.81 s
Wall time: 1.83 s
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-performance-metrics">
<h3><a class="toc-backref" href="#id13">Model Performance Metrics</a><a class="headerlink" href="#model-performance-metrics" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In topic modeling, we can diagnose the model performance using <strong>perplexity</strong> and <strong>log-likelihood</strong>.</p>
<ul>
<li><p>The higher the log-likelihood, the better.</p></li>
<li><p>The lower the perplexity, the better.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## log-likelihood</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lda</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">))</span>

<span class="c1">## perplexity</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lda</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-138.9126330364425
25.292966412842105
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="interpretation">
<h2><a class="toc-backref" href="#id14">Interpretation</a><a class="headerlink" href="#interpretation" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>To properly interpret the results provided by LDA, we need to get the two important probabilistic models:</p>
<ul>
<li><p><strong>Document-by-Topic</strong> Matrix: This is the matrix returned by the <code class="docutils literal notranslate"><span class="pre">LatentDirichletAllocation</span></code> object when we <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> the model with the data.</p></li>
<li><p><strong>Word-by-Topic</strong> Matrix: We can retrieve this matrix from a fitted <code class="docutils literal notranslate"><span class="pre">LatentDirichletAllocation</span></code> object. i.e., <code class="docutils literal notranslate"><span class="pre">LatentDirichletAllocation.components_</span></code></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>We have 8 documents and our vocabulary size is 20 (words).</p></li>
<li><p>We can check the shapes of the two matrices.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">doc_topic_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">## doc-by-topic matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lda</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">## topic-by-word- matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8, 3)
(3, 20)
</pre></div>
</div>
</div>
</div>
<section id="document-by-topic-matrix">
<h3><a class="toc-backref" href="#id15">Document-by-Topic Matrix</a><a class="headerlink" href="#document-by-topic-matrix" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In <strong>Document-by-Topic</strong> matrix, we can see how each document in the corpus (<strong>row</strong>) is connected to each <strong>topic</strong>.</p></li>
<li><p>In particular, the numbers refer to the probability value of a specific document being connected to a particular topic.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## doc-topic matrix</span>
<span class="n">doc_topic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">doc_topic_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;T1&#39;</span><span class="p">,</span> <span class="s1">&#39;T2&#39;</span><span class="p">,</span> <span class="s1">&#39;T3&#39;</span><span class="p">])</span>
<span class="n">doc_topic_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T1</th>
      <th>T2</th>
      <th>T3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.832191</td>
      <td>0.083480</td>
      <td>0.084329</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.863554</td>
      <td>0.069100</td>
      <td>0.067346</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.047794</td>
      <td>0.047776</td>
      <td>0.904430</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.037243</td>
      <td>0.925559</td>
      <td>0.037198</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.049121</td>
      <td>0.903076</td>
      <td>0.047802</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.054902</td>
      <td>0.047778</td>
      <td>0.897321</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.888287</td>
      <td>0.055697</td>
      <td>0.056016</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.055704</td>
      <td>0.055689</td>
      <td>0.888607</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="topic-by-word-matrix">
<h3><a class="toc-backref" href="#id16">Topic-by-Word Matrix</a><a class="headerlink" href="#topic-by-word-matrix" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In <strong>Topic-by-Word</strong> matrix, we can see how each topic (<strong>row</strong>) is connected to each word in the BOW.</p></li>
<li><p>In particular, the numbers refer to the importance of the word with respect to each topic.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topic_word_matrix</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">components_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">topic_word_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.333699</td>
      <td>0.333647</td>
      <td>3.332365</td>
      <td>3.373774</td>
      <td>0.333647</td>
      <td>0.333891</td>
      <td>0.333891</td>
      <td>0.333699</td>
      <td>0.333891</td>
      <td>0.333793</td>
      <td>0.333699</td>
      <td>0.333814</td>
      <td>0.333647</td>
      <td>0.333891</td>
      <td>1.330416</td>
      <td>0.333891</td>
      <td>0.333699</td>
      <td>4.332439</td>
      <td>0.333647</td>
      <td>1.332558</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.332696</td>
      <td>1.332774</td>
      <td>0.333853</td>
      <td>0.334283</td>
      <td>1.332774</td>
      <td>0.333761</td>
      <td>0.333761</td>
      <td>2.332696</td>
      <td>0.333761</td>
      <td>1.332543</td>
      <td>2.332696</td>
      <td>0.333767</td>
      <td>1.332774</td>
      <td>0.333761</td>
      <td>1.335461</td>
      <td>0.333761</td>
      <td>2.332696</td>
      <td>0.333812</td>
      <td>1.332774</td>
      <td>0.333744</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.333606</td>
      <td>0.333579</td>
      <td>0.333782</td>
      <td>1.291942</td>
      <td>0.333579</td>
      <td>3.332347</td>
      <td>3.332347</td>
      <td>0.333606</td>
      <td>3.332347</td>
      <td>0.333664</td>
      <td>0.333606</td>
      <td>1.332419</td>
      <td>0.333579</td>
      <td>3.332347</td>
      <td>0.334123</td>
      <td>3.332347</td>
      <td>0.333606</td>
      <td>0.333749</td>
      <td>0.333579</td>
      <td>0.333698</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>We can transpose the matrix for clarity of inspection (With each topic on the column).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">topic_word_matrix</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bacon</th>
      <td>0.333699</td>
      <td>2.332696</td>
      <td>0.333606</td>
    </tr>
    <tr>
      <th>beans</th>
      <td>0.333647</td>
      <td>1.332774</td>
      <td>0.333579</td>
    </tr>
    <tr>
      <th>beautiful</th>
      <td>3.332365</td>
      <td>0.333853</td>
      <td>0.333782</td>
    </tr>
    <tr>
      <th>blue</th>
      <td>3.373774</td>
      <td>0.334283</td>
      <td>1.291942</td>
    </tr>
    <tr>
      <th>breakfast</th>
      <td>0.333647</td>
      <td>1.332774</td>
      <td>0.333579</td>
    </tr>
    <tr>
      <th>brown</th>
      <td>0.333891</td>
      <td>0.333761</td>
      <td>3.332347</td>
    </tr>
    <tr>
      <th>dog</th>
      <td>0.333891</td>
      <td>0.333761</td>
      <td>3.332347</td>
    </tr>
    <tr>
      <th>eggs</th>
      <td>0.333699</td>
      <td>2.332696</td>
      <td>0.333606</td>
    </tr>
    <tr>
      <th>fox</th>
      <td>0.333891</td>
      <td>0.333761</td>
      <td>3.332347</td>
    </tr>
    <tr>
      <th>green</th>
      <td>0.333793</td>
      <td>1.332543</td>
      <td>0.333664</td>
    </tr>
    <tr>
      <th>ham</th>
      <td>0.333699</td>
      <td>2.332696</td>
      <td>0.333606</td>
    </tr>
    <tr>
      <th>jumps</th>
      <td>0.333814</td>
      <td>0.333767</td>
      <td>1.332419</td>
    </tr>
    <tr>
      <th>kings</th>
      <td>0.333647</td>
      <td>1.332774</td>
      <td>0.333579</td>
    </tr>
    <tr>
      <th>lazy</th>
      <td>0.333891</td>
      <td>0.333761</td>
      <td>3.332347</td>
    </tr>
    <tr>
      <th>love</th>
      <td>1.330416</td>
      <td>1.335461</td>
      <td>0.334123</td>
    </tr>
    <tr>
      <th>quick</th>
      <td>0.333891</td>
      <td>0.333761</td>
      <td>3.332347</td>
    </tr>
    <tr>
      <th>sausages</th>
      <td>0.333699</td>
      <td>2.332696</td>
      <td>0.333606</td>
    </tr>
    <tr>
      <th>sky</th>
      <td>4.332439</td>
      <td>0.333812</td>
      <td>0.333749</td>
    </tr>
    <tr>
      <th>toast</th>
      <td>0.333647</td>
      <td>1.332774</td>
      <td>0.333579</td>
    </tr>
    <tr>
      <th>today</th>
      <td>1.332558</td>
      <td>0.333744</td>
      <td>0.333698</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="interpreting-the-meanings-of-topics">
<h3><a class="toc-backref" href="#id17">Interpreting the Meanings of Topics</a><a class="headerlink" href="#interpreting-the-meanings-of-topics" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>This is the most crucial step in topic modeling. The LDA does not give us a label for each topic.</p></li>
<li><p>It is the analyst who determines the <strong>meanings</strong> of the topics.</p></li>
<li><p>These decisions are based on the words under each topic that show high importance weights.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## customized function</span>

<span class="k">def</span> <span class="nf">get_topics_meanings</span><span class="p">(</span><span class="n">tw_m</span><span class="p">,</span>
                        <span class="n">vocab</span><span class="p">,</span>
                        <span class="n">display_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">weight_cutoff</span><span class="o">=</span><span class="mf">0.6</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function sorts the words importance under each topic and </span>
<span class="sd">    allows selecting words based on ranks or a cutoff on weights.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - tw_m : array-like</span>
<span class="sd">        Topic by Word matrix containing the weights of each word in each topic.</span>
<span class="sd">    - vocab : list</span>
<span class="sd">        List of words in the vocabulary.</span>
<span class="sd">    - display_weights : bool, optional (default=False)</span>
<span class="sd">        Flag to indicate whether to display words with their weights.</span>
<span class="sd">    - topn : int, optional (default=5)</span>
<span class="sd">        Number of top words to display for each topic if display_weights is False.</span>
<span class="sd">    - weight_cutoff : float, optional (default=0.6)</span>
<span class="sd">        Weight cutoff threshold for displaying words if display_weights is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic_weights</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tw_m</span><span class="p">):</span>
        <span class="n">topic</span> <span class="o">=</span> <span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">topic_weights</span><span class="p">)]</span>
        <span class="n">topic</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">display_weights</span><span class="p">:</span>
            <span class="n">topic</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">topic</span> <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">weight_cutoff</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic #</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> :</span><span class="se">\n</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">topic_topn</span> <span class="o">=</span> <span class="n">topic</span><span class="p">[:</span><span class="n">topn</span><span class="p">]</span>
            <span class="n">topic_topn</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">topic_topn</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic #</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> :</span><span class="se">\n</span><span class="si">{</span><span class="n">topic_topn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>To use the above function:</p>
<ul>
<li><p>If we are to display the weights of words, then we need to specify the <code class="docutils literal notranslate"><span class="pre">weight_cutoff</span></code>.</p></li>
<li><p>If we are to display only the top N words, then we need to specify the <code class="docutils literal notranslate"><span class="pre">topn</span></code>.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_topics_meanings</span><span class="p">(</span><span class="n">topic_word_matrix</span><span class="p">,</span>
                    <span class="n">vocab</span><span class="p">,</span>
                    <span class="n">display_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">weight_cutoff</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic #0 :
[(&#39;sky&#39;, 4.33), (&#39;blue&#39;, 3.37), (&#39;beautiful&#39;, 3.33)]
====================
Topic #1 :
[(&#39;bacon&#39;, 2.33), (&#39;eggs&#39;, 2.33), (&#39;ham&#39;, 2.33), (&#39;sausages&#39;, 2.33)]
====================
Topic #2 :
[(&#39;brown&#39;, 3.33), (&#39;dog&#39;, 3.33), (&#39;fox&#39;, 3.33), (&#39;lazy&#39;, 3.33), (&#39;quick&#39;, 3.33)]
====================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_topics_meanings</span><span class="p">(</span><span class="n">topic_word_matrix</span><span class="p">,</span> 
                    <span class="n">vocab</span><span class="p">,</span> 
                    <span class="n">display_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                    <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic #0 :
sky blue beautiful love today
====================
Topic #1 :
bacon eggs ham sausages love
====================
Topic #2 :
brown dog fox lazy quick
====================
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="topics-in-documents">
<h2><a class="toc-backref" href="#id18">Topics in Documents</a><a class="headerlink" href="#topics-in-documents" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>After we determine the meanings of the topics, we can now analyze how each document is associated to these topics.</p></li>
<li><p>That is, we can now look at the <strong>Document-by-Topic</strong> Matrix.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## interpretation of TOPICS</span>
<span class="n">topics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;weather&#39;</span><span class="p">,</span> <span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="s1">&#39;animal&#39;</span><span class="p">]</span>

<span class="c1">## Checking</span>
<span class="n">doc_topic_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">topics</span>
<span class="n">doc_topic_df</span><span class="p">[</span><span class="s1">&#39;corpus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm_corpus</span>
<span class="n">doc_topic_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weather</th>
      <th>food</th>
      <th>animal</th>
      <th>corpus</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.832191</td>
      <td>0.083480</td>
      <td>0.084329</td>
      <td>sky blue beautiful</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.863554</td>
      <td>0.069100</td>
      <td>0.067346</td>
      <td>love blue beautiful sky</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.047794</td>
      <td>0.047776</td>
      <td>0.904430</td>
      <td>quick brown fox jumps lazy dog</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.037243</td>
      <td>0.925559</td>
      <td>0.037198</td>
      <td>kings breakfast sausages ham bacon eggs toast beans</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.049121</td>
      <td>0.903076</td>
      <td>0.047802</td>
      <td>love green eggs ham sausages bacon</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.054902</td>
      <td>0.047778</td>
      <td>0.897321</td>
      <td>brown fox quick blue dog lazy</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.888287</td>
      <td>0.055697</td>
      <td>0.056016</td>
      <td>sky blue sky beautiful today</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.055704</td>
      <td>0.055689</td>
      <td>0.888607</td>
      <td>dog lazy brown fox quick</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>We can visualize the topics distribution for each document using stack plot.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## create stacked bar plot</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DOC&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">))]</span>
<span class="n">y_axis</span> <span class="o">=</span> <span class="n">doc_topic_df</span><span class="p">[[</span><span class="s1">&#39;weather&#39;</span><span class="p">,</span> <span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="s1">&#39;animal&#39;</span><span class="p">]]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Create stacked bar plot</span>
<span class="n">bottom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_axis</span><span class="p">))</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">y_axis</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">y_axis</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">bottom</span><span class="o">=</span><span class="n">bottom</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">col</span><span class="p">)</span>
    <span class="n">bottom</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_axis</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>

<span class="c1"># Move the legend outside of the chart</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center left&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e120c564244290551b9fdd3fea587f903e6313f81384db76e28c141c6640a108.png" src="../_images/e120c564244290551b9fdd3fea587f903e6313f81384db76e28c141c6640a108.png" />
</div>
</div>
</section>
<section id="clustering-documents-using-topic-model-features">
<h2><a class="toc-backref" href="#id19">Clustering documents using topic model features</a><a class="headerlink" href="#clustering-documents-using-topic-model-features" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>We can use the topic distributions of each document as our features to further group the documents into clusters.</p></li>
<li><p>Here is a quick example of k-means clustering.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## initialize kmeans</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">## fit kmeans</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">doc_topic_matrix</span><span class="p">)</span>

<span class="c1">## get cluster labels</span>

<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">## check results</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cluster_labels</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ClusterLabel&#39;</span><span class="p">])</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">corpus_df</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Document</th>
      <th>ClusterLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The sky is blue and beautiful.</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Love this blue and beautiful sky!</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The quick brown fox jumps over the lazy dog.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>I love green eggs, ham, sausages and bacon!</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>The brown fox is quick and the blue dog is lazy!</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The sky is very blue and the sky is very beautiful today</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>The dog is lazy but the brown fox is quick!</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="visualizing-topic-models">
<h2><a class="toc-backref" href="#id20">Visualizing Topic Models</a><a class="headerlink" href="#visualizing-topic-models" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyLDAvis</span>
<span class="kn">import</span> <span class="nn">pyLDAvis.gensim</span>
<span class="kn">import</span> <span class="nn">pyLDAvis.lda_model</span> <span class="c1">## for sklearn LDA; if gensim, use `pyLDAvis.gensim`</span>
<span class="kn">import</span> <span class="nn">dill</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">enable_notebook</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><style>.container { max-width:100% !important; }</style></div><div class="output text_html"><style>.output_result { max-width:100% !important; }</style></div><div class="output text_html"><style>.output_area { max-width:100% !important; }</style></div><div class="output text_html"><style>.input_area { max-width:100% !important; }</style></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">lda_model</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">cv_matrix</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">mds</span><span class="o">=</span><span class="s1">&#39;mmds&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css">


<div id="ldavis_el5706061172182241688164155" style="background-color:white;"></div>
<script type="text/javascript">

var ldavis_el5706061172182241688164155_data = {"mdsDat": {"x": [-0.008445793833628968, 0.1346209365077882, -0.12617514267415922], "y": [0.16901844967086976, -0.08524624913297574, -0.08377220053789404], "topics": [1, 2, 3], "cluster": [1, 1, 1], "Freq": [38.69857956361474, 33.674475344649736, 27.62694509173552]}, "tinfo": {"Term": ["sky", "beautiful", "blue", "lazy", "brown", "dog", "fox", "quick", "bacon", "sausages", "ham", "eggs", "today", "love", "kings", "beans", "breakfast", "toast", "green", "jumps", "quick", "brown", "dog", "fox", "lazy", "jumps", "blue", "today", "green", "toast", "breakfast", "beans", "kings", "love", "sausages", "bacon", "eggs", "ham", "beautiful", "sky", "bacon", "eggs", "sausages", "ham", "breakfast", "beans", "kings", "toast", "green", "love", "today", "jumps", "beautiful", "brown", "dog", "fox", "lazy", "quick", "sky", "blue", "sky", "beautiful", "blue", "today", "love", "green", "kings", "breakfast", "toast", "beans", "jumps", "sausages", "bacon", "eggs", "ham", "lazy", "fox", "quick", "dog", "brown"], "Freq": [3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.347269745904943, 2.347269745904943, 2.347269745904943, 2.347269745904943, 2.347269745904943, 0.9385419225967806, 0.9100303130835469, 0.23505339441456768, 0.2350291466569901, 0.23496968562811427, 0.23496968562811427, 0.23496968562811427, 0.23496968562811427, 0.23535274903672884, 0.23498814448787408, 0.23498814448787408, 0.23498814448787408, 0.23498814448787408, 0.23511251824933246, 0.23508911832772747, 1.634277741376904, 1.634277741376904, 1.634277741376904, 1.634277741376904, 0.9337359955049813, 0.9337359955049813, 0.9337359955049813, 0.9337359955049813, 0.9335746009613621, 0.9356188717354832, 0.23381967072922324, 0.2338355879726243, 0.23389603446125906, 0.23383196198973596, 0.23383196198973596, 0.23383196198973596, 0.23383196198973596, 0.23383196198973596, 0.23386718998892939, 0.2341976848742828, 2.751100663223356, 2.1160530513150566, 2.1423479111851953, 0.8461748182314354, 0.8448145411986039, 0.21195876118035797, 0.2118660813317044, 0.2118660813317044, 0.2118660813317044, 0.2118660813317044, 0.2119720351945211, 0.2118987506916116, 0.2118987506916116, 0.2118987506916116, 0.2118987506916116, 0.21202105596489695, 0.21202105596489695, 0.21202105596489695, 0.21202105596489695, 0.21202105596489695], "Total": [3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576, 1.384349545763926, 3.286575909143025, 1.3150478833752262, 1.3805625087987101, 1.3805717624648, 1.3805717624648, 1.3805717624648, 1.3805717624648, 2.0157861619708157, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 2.585061604025648, 3.220056971540013, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 1.3805717624648, 1.3805717624648, 1.3805717624648, 1.3805717624648, 1.3805625087987101, 2.0157861619708157, 1.3150478833752262, 1.384349545763926, 2.585061604025648, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576, 3.220056971540013, 3.286575909143025, 3.220056971540013, 2.585061604025648, 3.286575909143025, 1.3150478833752262, 2.0157861619708157, 1.3805625087987101, 1.3805717624648, 1.3805717624648, 1.3805717624648, 1.3805717624648, 1.384349545763926, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 2.0811646365563896, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576, 2.793122763859576], "Category": ["Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3"], "logprob": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.9586, -1.9586, -1.9586, -1.9586, -1.9586, -2.8753, -2.9061, -4.2598, -4.2599, -4.2601, -4.2601, -4.2601, -4.2601, -4.2585, -4.2601, -4.2601, -4.2601, -4.2601, -4.2595, -4.2596, -2.1816, -2.1816, -2.1816, -2.1816, -2.7413, -2.7413, -2.7413, -2.7413, -2.7415, -2.7393, -4.126, -4.1259, -4.1256, -4.1259, -4.1259, -4.1259, -4.1259, -4.1259, -4.1258, -4.1244, -1.4628, -1.7253, -1.7129, -2.6419, -2.6435, -4.0262, -4.0266, -4.0266, -4.0266, -4.0266, -4.0261, -4.0265, -4.0265, -4.0265, -4.0265, -4.0259, -4.0259, -4.0259, -4.0259, -4.0259], "loglift": [20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7755, 0.7755, 0.7755, 0.7755, 0.7755, 0.5607, -0.3348, -0.7724, -0.8212, -0.8214, -0.8214, -0.8214, -0.8214, -1.1983, -1.2318, -1.2318, -1.2318, -1.2318, -1.4481, -1.6678, 0.8467, 0.8467, 0.8467, 0.8467, 0.6974, 0.6974, 0.6974, 0.6974, 0.6972, 0.3209, -0.6386, -0.6899, -1.3142, -1.3919, -1.3919, -1.3919, -1.3919, -1.3919, -1.534, -1.553, 1.129, 1.0862, 0.8584, 0.8455, 0.4167, -0.5875, -0.5879, -0.5879, -0.5879, -0.5879, -0.5902, -0.9982, -0.9982, -0.9982, -0.9982, -1.2919, -1.2919, -1.2919, -1.2919, -1.2919]}, "token.table": {"Topic": [2, 2, 3, 1, 3, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3], "Freq": [0.961000376841551, 0.7243375731621895, 0.7736759529774659, 0.30426803690067517, 0.6085360738013503, 0.7243375731621895, 0.7160444309423665, 0.7160444309423665, 0.961000376841551, 0.7160444309423665, 0.72434242826871, 0.961000376841551, 0.7223609117075772, 0.7243375731621895, 0.7160444309423665, 0.4960843659241658, 0.4960843659241658, 0.7160444309423665, 0.961000376841551, 0.9316605347405487, 0.7243375731621895, 0.760428584116178], "Term": ["bacon", "beans", "beautiful", "blue", "blue", "breakfast", "brown", "dog", "eggs", "fox", "green", "ham", "jumps", "kings", "lazy", "love", "love", "quick", "sausages", "sky", "toast", "today"]}, "R": 20, "lambda.step": 0.01, "plot.opts": {"xlab": "PC1", "ylab": "PC2"}, "topic.order": [3, 2, 1]};

function LDAvis_load_lib(url, callback){
  var s = document.createElement('script');
  s.src = url;
  s.async = true;
  s.onreadystatechange = s.onload = callback;
  s.onerror = function(){console.warn("failed to load library " + url);};
  document.getElementsByTagName("head")[0].appendChild(s);
}

if(typeof(LDAvis) !== "undefined"){
   // already loaded: just create the visualization
   !function(LDAvis){
       new LDAvis("#" + "ldavis_el5706061172182241688164155", ldavis_el5706061172182241688164155_data);
   }(LDAvis);
}else if(typeof define === "function" && define.amd){
   // require.js is available: use it to load d3/LDAvis
   require.config({paths: {d3: "https://d3js.org/d3.v5"}});
   require(["d3"], function(d3){
      window.d3 = d3;
      LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js", function(){
        new LDAvis("#" + "ldavis_el5706061172182241688164155", ldavis_el5706061172182241688164155_data);
      });
    });
}else{
    // require.js not available: dynamically load d3 & LDAvis
    LDAvis_load_lib("https://d3js.org/d3.v5.js", function(){
         LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js", function(){
                 new LDAvis("#" + "ldavis_el5706061172182241688164155", ldavis_el5706061172182241688164155_data);
            })
         });
}
</script></div></div>
</div>
</section>
<section id="hyperparameter-tuning">
<h2><a class="toc-backref" href="#id21">Hyperparameter Tuning</a><a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>One thing we haven’t made explicit is that the <strong>number of topics</strong> so far has been pre-determined before the analysis.</p></li>
<li><p>How to find the optimal number of topics can be challenging in topic modeling.</p></li>
<li><p>We can take this as a hyperparameter of the model and use <strong>Grid Search</strong> to find the most optimal number of topics.</p></li>
<li><p>Similarly, we can fine tune the other hyperparameters of LDA as well (e.g., <code class="docutils literal notranslate"><span class="pre">learning_decay</span></code>).</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">learning_method</span></code>: The default is <code class="docutils literal notranslate"><span class="pre">batch</span></code>; that is, use all training data for parameter estimation. If it is <code class="docutils literal notranslate"><span class="pre">online</span></code>, the model will update the parameters on a token by token basis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_decay</span></code>: If the <code class="docutils literal notranslate"><span class="pre">learning_method</span></code> is <code class="docutils literal notranslate"><span class="pre">online</span></code>, we can specify a parameter that controls learning rate in the online learning method (usually set between [0.5, 1.0]).</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Doing Grid Search with LDA models can be very slow. There are some other topic modeling algorithms that are a lot faster. Please refer to Sarkar (2019) Chapter 6 for more information.</p>
</div>
<section id="grid-search-for-topic-number">
<h3><a class="toc-backref" href="#id22">Grid Search for Topic Number</a><a class="headerlink" href="#grid-search-for-topic-number" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="c1">## Prepare hyperparameters dict</span>
<span class="n">search_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_components&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="s1">&#39;learning_decay&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">.7</span><span class="p">]}</span>

<span class="c1">## Initialize LDA</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="c1">## `online` for large datasets</span>
                                  <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                                  <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">## Gridsearch</span>
<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                          <span class="n">param_grid</span><span class="o">=</span><span class="n">search_params</span><span class="p">,</span>
                          <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>

<span class="c1">## Save the best model</span>
<span class="n">best_lda</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 10 candidates, totalling 50 fits
CPU times: user 2.11 s, sys: 13.2 ms, total: 2.12 s
Wall time: 14.2 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># What did we find?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Model&#39;s Params: &quot;</span><span class="p">,</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Log Likelihood Score: &quot;</span><span class="p">,</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Model Perplexity: &#39;</span><span class="p">,</span> <span class="n">best_lda</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best Model&#39;s Params:  {&#39;learning_decay&#39;: 0.5, &#39;n_components&#39;: 3}
Best Log Likelihood Score:  -50.410868132698795
Best Model Perplexity:  25.292966412842105
</pre></div>
</div>
</div>
</div>
</section>
<section id="examining-the-grid-search-results">
<h3><a class="toc-backref" href="#id23">Examining the Grid Search Results</a><a class="headerlink" href="#examining-the-grid-search-results" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">gridsearch</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">cv_results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_fit_time</th>
      <th>std_fit_time</th>
      <th>mean_score_time</th>
      <th>std_score_time</th>
      <th>param_learning_decay</th>
      <th>param_n_components</th>
      <th>params</th>
      <th>split0_test_score</th>
      <th>split1_test_score</th>
      <th>split2_test_score</th>
      <th>split3_test_score</th>
      <th>split4_test_score</th>
      <th>mean_test_score</th>
      <th>std_test_score</th>
      <th>rank_test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.534712</td>
      <td>0.342016</td>
      <td>0.000322</td>
      <td>0.000025</td>
      <td>0.5</td>
      <td>3</td>
      <td>{'learning_decay': 0.5, 'n_components': 3}</td>
      <td>-45.022883</td>
      <td>-73.947625</td>
      <td>-60.589126</td>
      <td>-37.947911</td>
      <td>-34.546796</td>
      <td>-50.410868</td>
      <td>14.789188</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.991487</td>
      <td>0.781605</td>
      <td>0.000419</td>
      <td>0.000197</td>
      <td>0.5</td>
      <td>4</td>
      <td>{'learning_decay': 0.5, 'n_components': 4}</td>
      <td>-49.145599</td>
      <td>-82.726223</td>
      <td>-65.081852</td>
      <td>-42.126564</td>
      <td>-37.038050</td>
      <td>-55.223657</td>
      <td>16.689926</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.830407</td>
      <td>0.823932</td>
      <td>0.000411</td>
      <td>0.000164</td>
      <td>0.5</td>
      <td>5</td>
      <td>{'learning_decay': 0.5, 'n_components': 5}</td>
      <td>-50.024617</td>
      <td>-86.998110</td>
      <td>-70.381182</td>
      <td>-44.942218</td>
      <td>-42.224895</td>
      <td>-58.914204</td>
      <td>17.163750</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.613521</td>
      <td>0.476992</td>
      <td>0.000515</td>
      <td>0.000262</td>
      <td>0.5</td>
      <td>6</td>
      <td>{'learning_decay': 0.5, 'n_components': 6}</td>
      <td>-52.609495</td>
      <td>-93.522521</td>
      <td>-73.924983</td>
      <td>-47.956165</td>
      <td>-49.996366</td>
      <td>-63.601906</td>
      <td>17.621249</td>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.508645</td>
      <td>0.242184</td>
      <td>0.000381</td>
      <td>0.000128</td>
      <td>0.5</td>
      <td>7</td>
      <td>{'learning_decay': 0.5, 'n_components': 7}</td>
      <td>-54.878310</td>
      <td>-99.846527</td>
      <td>-77.129032</td>
      <td>-50.917763</td>
      <td>-46.861191</td>
      <td>-65.926565</td>
      <td>19.934270</td>
      <td>9</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2.602352</td>
      <td>0.392834</td>
      <td>0.000512</td>
      <td>0.000230</td>
      <td>0.7</td>
      <td>3</td>
      <td>{'learning_decay': 0.7, 'n_components': 3}</td>
      <td>-45.022883</td>
      <td>-73.947625</td>
      <td>-60.589126</td>
      <td>-37.947911</td>
      <td>-34.546796</td>
      <td>-50.410868</td>
      <td>14.789188</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2.955229</td>
      <td>0.633029</td>
      <td>0.000425</td>
      <td>0.000211</td>
      <td>0.7</td>
      <td>4</td>
      <td>{'learning_decay': 0.7, 'n_components': 4}</td>
      <td>-49.145599</td>
      <td>-82.726223</td>
      <td>-65.081852</td>
      <td>-42.126564</td>
      <td>-37.038050</td>
      <td>-55.223657</td>
      <td>16.689926</td>
      <td>3</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2.843962</td>
      <td>0.751603</td>
      <td>0.000349</td>
      <td>0.000029</td>
      <td>0.7</td>
      <td>5</td>
      <td>{'learning_decay': 0.7, 'n_components': 5}</td>
      <td>-50.024617</td>
      <td>-86.998110</td>
      <td>-70.381182</td>
      <td>-44.942218</td>
      <td>-42.224895</td>
      <td>-58.914204</td>
      <td>17.163750</td>
      <td>5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2.597273</td>
      <td>0.372056</td>
      <td>0.000321</td>
      <td>0.000039</td>
      <td>0.7</td>
      <td>6</td>
      <td>{'learning_decay': 0.7, 'n_components': 6}</td>
      <td>-52.609495</td>
      <td>-93.522521</td>
      <td>-73.924983</td>
      <td>-47.956165</td>
      <td>-49.996366</td>
      <td>-63.601906</td>
      <td>17.621249</td>
      <td>7</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2.111250</td>
      <td>0.215773</td>
      <td>0.000330</td>
      <td>0.000028</td>
      <td>0.7</td>
      <td>7</td>
      <td>{'learning_decay': 0.7, 'n_components': 7}</td>
      <td>-54.878310</td>
      <td>-99.846527</td>
      <td>-77.129032</td>
      <td>-50.917763</td>
      <td>-46.861191</td>
      <td>-65.926565</td>
      <td>19.934270</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">:</span><span class="mi">150</span><span class="p">,</span> <span class="s1">&#39;savefig.dpi&#39;</span><span class="p">:</span><span class="mi">150</span><span class="p">})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;param_n_components&quot;</span><span class="p">,</span>
              <span class="n">y</span><span class="o">=</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">,</span>
              <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;param_learning_decay&quot;</span><span class="p">,</span>
              <span class="n">data</span><span class="o">=</span><span class="n">cv_results_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;param_n_components&#39;, ylabel=&#39;mean_test_score&#39;&gt;
</pre></div>
</div>
<img alt="../_images/dea84e2996838bd65dede8c680e64506b1f66d77bbdcd7b2ba52f79bd7da2c23.png" src="../_images/dea84e2996838bd65dede8c680e64506b1f66d77bbdcd7b2ba52f79bd7da2c23.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">get_topics_meanings</span><span class="p">(</span><span class="n">best_lda</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>
                    <span class="n">vocab</span><span class="p">,</span>
                    <span class="n">display_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">weight_cutoff</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic #0 :
[(&#39;sky&#39;, 4.33), (&#39;blue&#39;, 3.37), (&#39;beautiful&#39;, 3.33)]
====================
Topic #1 :
[(&#39;bacon&#39;, 2.33), (&#39;eggs&#39;, 2.33), (&#39;ham&#39;, 2.33), (&#39;sausages&#39;, 2.33)]
====================
Topic #2 :
[(&#39;brown&#39;, 3.33), (&#39;dog&#39;, 3.33), (&#39;fox&#39;, 3.33), (&#39;lazy&#39;, 3.33), (&#39;quick&#39;, 3.33)]
====================
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="topic-prediction">
<h2><a class="toc-backref" href="#id24">Topic Prediction</a><a class="headerlink" href="#topic-prediction" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>We can use our LDA to make predictions of topics for new documents.</p></li>
<li><p>We need to perform the same procedures with the new document as we did with the training data:</p>
<ul>
<li><p>text preprocessing</p></li>
<li><p>count-vectorization</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_texts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;The sky is so blue&#39;</span><span class="p">,</span> <span class="s1">&#39;Love burger with ham&#39;</span><span class="p">]</span>

<span class="c1">## normalize</span>
<span class="n">new_texts_norm</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">new_texts</span><span class="p">)</span>

<span class="c1">## vectorize</span>
<span class="n">new_texts_cv</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_texts_norm</span><span class="p">)</span>

<span class="c1">## Check</span>
<span class="n">new_texts_cv</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2, 20)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Applied our trained LDA</span>
<span class="n">new_texts_doc_topic_matrix</span> <span class="o">=</span> <span class="n">best_lda</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_texts_cv</span><span class="p">)</span>

<span class="c1">## Check results</span>
<span class="n">topics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;weather&#39;</span><span class="p">,</span> <span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="s1">&#39;animal&#39;</span><span class="p">]</span>


<span class="n">new_texts_doc_topic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">new_texts_doc_topic_matrix</span><span class="p">,</span>
                                      <span class="n">columns</span><span class="o">=</span><span class="n">topics</span><span class="p">)</span>
<span class="n">new_texts_doc_topic_df</span><span class="p">[</span><span class="s1">&#39;predicted_topic&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">topics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">new_texts_doc_topic_df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">new_texts_doc_topic_df</span><span class="p">[</span><span class="s1">&#39;corpus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_texts_norm</span>
<span class="n">new_texts_doc_topic_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weather</th>
      <th>food</th>
      <th>animal</th>
      <th>predicted_topic</th>
      <th>corpus</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.775601</td>
      <td>0.111301</td>
      <td>0.113098</td>
      <td>weather</td>
      <td>sky blue</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.123415</td>
      <td>0.764965</td>
      <td>0.111620</td>
      <td>food</td>
      <td>love burger ham</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="additional-notes">
<h2><a class="toc-backref" href="#id25">Additional Notes</a><a class="headerlink" href="#additional-notes" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>We can calculate a metric to evaluate the coherence of each topic.</p></li>
<li><p>The coherence computation is implemented in <code class="docutils literal notranslate"><span class="pre">gensim</span></code>. To apply the coherence comptuation to a <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>-trained LDA, we need <code class="docutils literal notranslate"><span class="pre">tmtoolkit</span></code> (<code class="docutils literal notranslate"><span class="pre">tmtoolkit.topicmod.evaluate.metric_coherence_gensim</span></code>).</p></li>
<li><p>I leave notes here in case in the future we need to compute the coherence metrics.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">tmtoolkit</span></code> does not support <code class="docutils literal notranslate"><span class="pre">spacy</span></code> 3+. Also, <code class="docutils literal notranslate"><span class="pre">tmtoolkit</span></code> will downgrade several important packages to lower versions. Please use it with caution. I would suggest creating another virtual environment for this.</p>
</div>
<ul class="simple">
<li><p>The following codes demonstrate how to find the optimal topic number based on the coherence scores of the topic models.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 5: Calculate Coherence</span>
<span class="n">coherence_model</span> <span class="o">=</span> <span class="n">CoherenceModel</span><span class="p">(</span><span class="n">topics</span><span class="o">=</span><span class="n">top_words_per_topic</span><span class="p">,</span> <span class="n">texts</span><span class="o">=</span><span class="n">tokenized_text</span><span class="p">,</span> <span class="n">dictionary</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">coherence</span><span class="o">=</span><span class="s1">&#39;c_v&#39;</span><span class="p">)</span>
<span class="n">coherence_score</span> <span class="o">=</span> <span class="n">coherence_model</span><span class="o">.</span><span class="n">get_coherence</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tmtoolkit</span>
<span class="kn">from</span> <span class="nn">tmtoolkit.topicmod.evaluate</span> <span class="kn">import</span> <span class="n">metric_coherence_gensim</span>
<span class="k">def</span> <span class="nf">topic_model_coherence_generator</span><span class="p">(</span><span class="n">topic_num_start</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                    <span class="n">topic_num_end</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                                    <span class="n">norm_corpus</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
                                    <span class="n">cv_matrix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
                                    <span class="n">cv</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="n">norm_corpus_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_corpus</span><span class="p">]</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">coherence_scores</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">topic_num_start</span><span class="p">,</span> <span class="n">topic_num_end</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">cur_lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
                                            <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">cur_lda</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
        <span class="n">cur_coherence_score</span> <span class="o">=</span> <span class="n">metric_coherence_gensim</span><span class="p">(</span>
            <span class="n">measure</span><span class="o">=</span><span class="s1">&#39;c_v&#39;</span><span class="p">,</span>
            <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">topic_word_distrib</span><span class="o">=</span><span class="n">cur_lda</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span>
            <span class="n">dtm</span><span class="o">=</span><span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">),</span>
            <span class="n">vocab</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()),</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">norm_corpus_tokens</span><span class="p">)</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_lda</span><span class="p">)</span>
        <span class="n">coherence_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cur_coherence_score</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">models</span><span class="p">,</span> <span class="n">coherence_scores</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">ts</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">te</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">models</span><span class="p">,</span> <span class="n">coherence_scores</span> <span class="o">=</span> <span class="n">topic_model_coherence_generator</span><span class="p">(</span>
    <span class="n">ts</span><span class="p">,</span> <span class="n">te</span><span class="p">,</span> <span class="n">norm_corpus</span><span class="o">=</span><span class="n">norm_corpus</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">cv_matrix</span><span class="o">=</span><span class="n">cv_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
3
4
5
6
7
8
9
CPU times: user 17.5 s, sys: 463 ms, total: 18 s
Wall time: 45.8 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coherence_scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.6517493196892892,
 0.8866946211961687,
 0.765479848024043,
 0.8341252576008902,
 0.8572203857656319,
 0.7066394264220808,
 0.6391495323490347,
 0.6086551968156503]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coherence_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;TOPIC_NUMBER&#39;</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">te</span><span class="p">)],</span>
    <span class="s1">&#39;COHERENCE_SCORE&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">coherence_scores</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="p">})</span>

<span class="n">coherence_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;COHERENCE_SCORE&quot;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TOPIC_NUMBER</th>
      <th>COHERENCE_SCORE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>0.8867</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>0.8572</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>0.8341</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>0.7655</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7</td>
      <td>0.7066</td>
    </tr>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.6517</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8</td>
      <td>0.6391</td>
    </tr>
    <tr>
      <th>7</th>
      <td>9</td>
      <td>0.6087</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotnine</span>
<span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="n">ggplot</span><span class="p">,</span> <span class="n">aes</span><span class="p">,</span> <span class="n">geom_point</span><span class="p">,</span> <span class="n">geom_line</span><span class="p">,</span> <span class="n">labs</span>
<span class="n">plotnine</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">dpi</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">g</span> <span class="o">=</span> <span class="p">(</span><span class="n">ggplot</span><span class="p">(</span><span class="n">coherence_df</span><span class="p">)</span> <span class="o">+</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;TOPIC_NUMBER&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;COHERENCE_SCORE&quot;</span><span class="p">)</span> <span class="o">+</span>
     <span class="n">geom_point</span><span class="p">(</span><span class="n">stat</span><span class="o">=</span><span class="s2">&quot;identity&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">)</span> <span class="o">+</span>
     <span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Topics&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Average Coherence Score&quot;</span><span class="p">))</span>
<span class="n">g</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d588208955e87b54b41662a6241653daf5e1cdda9a4154795f7ee0d8b9030738.png" src="../_images/d588208955e87b54b41662a6241653daf5e1cdda9a4154795f7ee0d8b9030738.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure Size: (960 x 720)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="challenges">
<h2><a class="toc-backref" href="#id26">Challenges</a><a class="headerlink" href="#challenges" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>There are several challenges and limications with LDA:</p>
<ul>
<li><p>Choosing the number of topics</p></li>
<li><p>Interpretability</p></li>
<li><p>Scalability</p></li>
<li><p>Polysemy and context</p></li>
</ul>
</li>
<li><p>Maybe we can combine this exploratory method of topic model with LLM by feeding the key terms of topics to the LLM to prompt for more comprehensive desciption and interpretation of the topics.</p></li>
</ul>
</section>
<section id="references">
<h2><a class="toc-backref" href="#id27">References</a><a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Sarkar (2019), Chapter 6: Text Summarization and Topic Models</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1711.04305">Latent Dirichlet Allocation (LDA) and Topic Modeling: Models, Applications, and a Survey</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ml-emsemble-learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Emsemble Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="dl-neural-network-from-scratch.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Neural Network From Scratch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-topic-modeling">What is Topic Modeling?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#flowchart-for-topic-modeling">Flowchart for Topic Modeling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation-and-preprocessing">Data Preparation and Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-necessary-dependencies-and-settings">Import Necessary Dependencies and Settings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-corpus">Simple Corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-text-pre-processing">Simple Text Pre-processing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-vectorization">Text Vectorization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bag-of-words-model">Bag of Words Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-dirichlet-allocation">Latent Dirichlet Allocation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuition-of-lda">Intuition of LDA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-lda-model">Building LDA Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-performance-metrics">Model Performance Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#document-by-topic-matrix">Document-by-Topic Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-by-word-matrix">Topic-by-Word Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-meanings-of-topics">Interpreting the Meanings of Topics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topics-in-documents">Topics in Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-documents-using-topic-model-features">Clustering documents using topic model features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-topic-models">Visualizing Topic Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">Hyperparameter Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-for-topic-number">Grid Search for Topic Number</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-the-grid-search-results">Examining the Grid Search Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-prediction">Topic Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-notes">Additional Notes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alvin Cheng-Hsien Chen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023 Alvin Chen.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>