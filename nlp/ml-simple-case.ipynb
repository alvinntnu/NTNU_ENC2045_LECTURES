{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: A Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we have collected a list of personal names and we have their corresponding gender labels, i.e., whether the name is a male or female one.\n",
    "\n",
    "The goal of this example is to create a classifier that would automatically classify a given name into either male or female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Example: Name Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))\n",
    "classifier.classify(gender_features('Trinity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     36.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.3 : 1.0\n",
      "             last_letter = 'v'              male : female =     18.7 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.0 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(gender_features2, labeled_names[500:])\n",
    "test_set = apply_features(gender_features2, labeled_names[:500])\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     37.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     27.7 : 1.0\n",
      "             last_letter = 'v'              male : female =     16.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     12.7 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.3 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.6 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.4 : 1.0\n",
      "                count(v) = 2              female : male   =      7.6 : 1.0\n",
      "             last_letter = 'r'              male : female =      7.2 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.5 : 1.0\n",
      "                count(i) = 3                male : female =      5.2 : 1.0\n",
      "             last_letter = 'z'              male : female =      5.1 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.7 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.5 : 1.0\n",
      "                count(w) = 1                male : female =      4.4 : 1.0\n",
      "                count(a) = 3              female : male   =      4.3 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.3 : 1.0\n",
      "                  has(w) = True             male : female =      4.3 : 1.0\n",
      "             last_letter = 'j'              male : female =      4.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Development-Test Data Splits for Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n"
     ]
    }
   ],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]\n",
    "\n",
    "train_set = [(gender_features2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('error-analysis.csv', 'w') as f: \n",
    "      \n",
    "    # using csv.writer method from CSV package \n",
    "    write = csv.writer(f) \n",
    "    write.writerow(['tag','guess','name']) \n",
    "    write.writerows(errors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/confusion-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion Matrix:\n",
    "    - **True positives** are relevant items that we correctly identified as relevant.\n",
    "    - **True negatives** are irrelevant items that we correctly identified as irrelevant.\n",
    "    - **False positives** (or Type I errors) are irrelevant items that we incorrectly identified as relevant.\n",
    "    - **False negatives** (or Type II errors) are relevant items that we incorrectly identified as irrelevant.\n",
    "    Given these four numbers, we can define the following metrics:\n",
    "\n",
    "- Evaluation Metrics:\n",
    "    - **Precision**: how many of the items that we identified were relevant, is TP/(TP+FP).\n",
    "    - **Recall**: how many of the relevant items that we identified, is TP/(TP+FN).\n",
    "    - **F-Measure (or F-Score)**: the harmonic mean of the precision and recall,i.e.:\n",
    "    \n",
    "\n",
    "$$ \n",
    "\\frac{(2 × Precision × Recall)}{(Precision + Recall)} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_f = [feature for (feature, label) in test_set] # features of test set\n",
    "t_l = [label for (feature, label) in test_set] # labels of test set\n",
    "t_l_pr = [classifier.classify(f) for f in t_f] # predicted labels of test set\n",
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <54.4%>  8.2% |\n",
      "  male |  14.8% <22.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm=nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCM(classifier, test_set):\n",
    "    t_f = [feature for (feature, label) in test_set]\n",
    "    t_l = [label for (feature, label) in test_set]\n",
    "    t_l_pr = [classifier.classify(f) for f in t_f]\n",
    "    cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "    print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <54.4%>  8.2% |\n",
      "  male |  14.8% <22.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Maxent Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maxent is memory hungry, slower, and it requires `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 s, sys: 11.7 ms, total: 6.05 s\n",
      "Wall time: 6.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import MaxentClassifier\n",
    "classifier_maxent = MaxentClassifier.train(train_set, algorithm = 'gis', trace = 0, max_iter=10, min_lldelta=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The default algorithm for training is `iis` (Improved Iterative Scaling). Another alternative is `gis` (General Iterative Scaling), which is faster.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -0.175 last_letter=='a' and label is 'male'\n",
      "  -0.125 last_letter=='k' and label is 'female'\n",
      "  -0.111 count(v)==2 and label is 'male'\n",
      "  -0.111 last_letter=='v' and label is 'female'\n",
      "  -0.090 last_letter=='f' and label is 'female'\n",
      "  -0.084 last_letter=='p' and label is 'female'\n",
      "  -0.073 last_letter=='d' and label is 'female'\n",
      "  -0.068 count(a)==3 and label is 'male'\n",
      "  -0.066 last_letter=='m' and label is 'female'\n",
      "  -0.063 last_letter=='o' and label is 'female'\n",
      "  -0.057 last_letter=='i' and label is 'male'\n",
      "  -0.056 last_letter=='r' and label is 'female'\n",
      "  -0.053 count(l)==3 and label is 'male'\n",
      "  -0.053 count(k)==2 and label is 'male'\n",
      "  -0.052 count(a)==2 and label is 'male'\n",
      "  -0.049 count(p)==3 and label is 'male'\n",
      "  -0.048 count(i)==3 and label is 'female'\n",
      "  -0.048 last_letter=='w' and label is 'female'\n",
      "  -0.046 count(e)==3 and label is 'male'\n",
      "  -0.046 last_letter=='z' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "classifier_maxent.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <51.2%> 11.4% |\n",
      "  male |  11.8% <25.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameters:\n",
    "    - `binary`: whether the features are binary\n",
    "    - `entropy_cutoff`: a value used during tree refinement process (entropy=1 -> high-level uncertainty; entropy = 0 -> perfect model prediction)\n",
    "    - `depth_cutoff`: to control the depth of the tree\n",
    "    - `support_cutoff`: the mimimum number of instances that are required to make a decision about a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 17 ms, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier.train(train_set, binary=True, \n",
    "                                             entropy_cutoff=0.8, depth_cutoff=5, support_cutoff =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <58.8%>  3.8% |\n",
      "  male |  24.2% <13.2%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- NLTK Book, Chapter 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
