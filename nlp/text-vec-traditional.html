
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Text Vectorization Using Traditional Methods &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Machine Learning: Overview" href="ml-overview.html" />
    <link rel="prev" title="Chinese Word Segmentation" href="chinese-word-seg.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ml-overview.html">
   Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ml-simple-case.html">
   Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ml-algorithm.html">
   Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/ml-sklearn-classification.html">
   Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-classification-ml-newsgroups.html">
   Text Classification Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/topic-modeling-naive.html">
   Topic Modeling: A Naive Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ml-nlp-case.html">
   Machine Learning: NLP Tasks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-network-from-scratch.html">
   Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding.html">
   Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding-keras.html">
   Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-statistical-language-model.html">
   Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-sequence-models-intuition.html">
   Sequence Models Intuition
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types.html">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   1. Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   2. Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   3. Assignment III: Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   4. Assignment IV: Chinese Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   5. Assignment V: Text Vectorization
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nlp/text-vec-traditional.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/nlp/text-vec-traditional.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/nlp/text-vec-traditional.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-necessary-dependencies-and-settings">
   Import necessary dependencies and settings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-corpus-of-text-documents">
   Sample Corpus of Text Documents
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-text-preprocessing">
   Simple Text Preprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bag-of-words-model">
   Bag of Words Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#countvectorizer-from-sklearn">
     <code class="docutils literal notranslate">
      <span class="pre">
       CountVectorizer()
      </span>
     </code>
     from
     <code class="docutils literal notranslate">
      <span class="pre">
       sklearn
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#improving-bag-of-words-text-representation">
   Improving Bag-of-Words Text Representation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#n-gram-bag-of-words-text-representation">
   N-gram Bag-of-Words Text Representation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-idf-model">
   TF-IDF Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tfidftransformer-from-sklearn">
     <code class="docutils literal notranslate">
      <span class="pre">
       TfidfTransformer()
      </span>
     </code>
     from
     <code class="docutils literal notranslate">
      <span class="pre">
       sklearn
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tfidfvectorizer-from-sklearn">
     <code class="docutils literal notranslate">
      <span class="pre">
       TfidfVectorizer()
      </span>
     </code>
     from
     <code class="docutils literal notranslate">
      <span class="pre">
       sklearn
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intuition-of-tf-idf">
   Intuition of TF-IDF
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-vocabulary-dictionary-of-the-corpus">
     Create Vocabulary Dictionary of the Corpus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-document-word-matrix-bag-of-word-frequencies">
     Create Document-Word Matrix (Bag-of-Word Frequencies)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-document-frequency-of-words">
     Compute Document Frequency of Words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-inverse-document-frequency-of-words">
     Create Inverse Document Frequency of Words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-raw-tf-idf-for-each-document">
     Compute Raw TF-IDF for Each Document
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-l2-norms-of-tf-idf">
     Get L2 Norms of TF-IDF
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-normalized-tf-idf-for-each-document">
     Compute Normalized TF-IDF for Each Document
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#document-similarity">
   Document Similarity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#similarity-distance-metrics-and-intuition">
   Similarity/Distance Metrics and Intuition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distance-based-metrics">
     Distance-based Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similarity-based-metrics">
     Similarity-based Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-metrics-to-use-then">
     Which Metrics to Use then?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pairwise-similarity-computation">
   Pairwise Similarity Computation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clustering-documents-using-similarity-features">
   Clustering Documents Using Similarity Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clustering-words-using-similarity-features">
   Clustering Words Using Similarity Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="text-vectorization-using-traditional-methods">
<h1>Text Vectorization Using Traditional Methods<a class="headerlink" href="#text-vectorization-using-traditional-methods" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>There are many ways to vectorize a text into <strong>numeric</strong> representations.</p></li>
<li><p>In traditional linguistic studies, linguists may <strong>manually</strong> annotate a text based on self-defined linguistic properties. These heuristics-based annotations can be easily converted into numeric values, thus in turn, vectorizing the text.</p></li>
<li><p>In statistical language processing, it is important to reduce the effort of manual annotation and come up with ways to <strong>automatically</strong> vectorize a text.</p></li>
<li><p>In this tutorial, we will look at the most widely-used method in machine learning NLP, the <strong>bag-of-words</strong> method for text vectorization.</p></li>
</ul>
<div class="section" id="import-necessary-dependencies-and-settings">
<h2>Import necessary dependencies and settings<a class="headerlink" href="#import-necessary-dependencies-and-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import warnings</span>
<span class="c1"># warnings.filterwarnings(&#39;ignore&#39;)</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">## Default Style Settings</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1">#%matplotlib inline</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-corpus-of-text-documents">
<h2>Sample Corpus of Text Documents<a class="headerlink" href="#sample-corpus-of-text-documents" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>To have a quick intuition of how bag-of-words work, we start with a naive corpus, one consisting of eight documents. Each document is in fact a simple sentence.</p></li>
<li><p>Each document in the corpus has a label (potentially referring to its <strong>topic</strong>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;The sky is blue and beautiful.&#39;</span><span class="p">,</span> <span class="s1">&#39;Love this blue and beautiful sky!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The quick brown fox jumps over the lazy dog.&#39;</span><span class="p">,</span>
    <span class="s2">&quot;A king&#39;s breakfast has sausages, ham, bacon, eggs, toast and beans&quot;</span><span class="p">,</span>
    <span class="s1">&#39;I love green eggs, ham, sausages and bacon!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The brown fox is quick and the blue dog is lazy!&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The sky is very blue and the sky is very beautiful today&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The dog is lazy but the brown fox is quick!&#39;</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;weather&#39;</span><span class="p">,</span> <span class="s1">&#39;weather&#39;</span><span class="p">,</span> <span class="s1">&#39;animals&#39;</span><span class="p">,</span> <span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="s1">&#39;animals&#39;</span><span class="p">,</span> <span class="s1">&#39;weather&#39;</span><span class="p">,</span>
    <span class="s1">&#39;animals&#39;</span>
<span class="p">]</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="c1"># np.array better than list</span>
<span class="n">corpus_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Document&#39;</span><span class="p">:</span> <span class="n">corpus</span><span class="p">,</span> <span class="s1">&#39;Category&#39;</span><span class="p">:</span> <span class="n">labels</span><span class="p">})</span>
<span class="n">corpus_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Document</th>
      <th>Category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The sky is blue and beautiful.</td>
      <td>weather</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Love this blue and beautiful sky!</td>
      <td>weather</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The quick brown fox jumps over the lazy dog.</td>
      <td>animals</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>
      <td>food</td>
    </tr>
    <tr>
      <th>4</th>
      <td>I love green eggs, ham, sausages and bacon!</td>
      <td>food</td>
    </tr>
    <tr>
      <th>5</th>
      <td>The brown fox is quick and the blue dog is lazy!</td>
      <td>animals</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The sky is very blue and the sky is very beautiful today</td>
      <td>weather</td>
    </tr>
    <tr>
      <th>7</th>
      <td>The dog is lazy but the brown fox is quick!</td>
      <td>animals</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In text processing, people often cast <code class="docutils literal notranslate"><span class="pre">list</span></code> into <code class="docutils literal notranslate"><span class="pre">np.array</span></code> for efficiency. A numpy array is a lot faster than the native <code class="docutils literal notranslate"><span class="pre">list</span></code> in Python.</p>
<p>If you are interested, please check this <a class="reference external" href="https://www.youtube.com/watch?v=9JUAPgtkKpI&amp;t=1868s">YouTube Numpy Crash Course</a>.</p>
</div>
</div>
<div class="section" id="simple-text-preprocessing">
<h2>Simple Text Preprocessing<a class="headerlink" href="#simple-text-preprocessing" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>A few steps for text preprocessing</p>
<ul>
<li><p>Remove special characters</p></li>
<li><p>Normalize letter case</p></li>
<li><p>Remove redundant spaces</p></li>
<li><p>Tokenize each document into word-tokens</p></li>
<li><p>Remove stop words</p></li>
</ul>
</li>
<li><p>All these preprocessing steps are wrapped in one function, <code class="docutils literal notranslate"><span class="pre">normalize_document()</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wpt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">WordPunctTokenizer</span><span class="p">()</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">normalize_document</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># lower case and remove special characters\whitespaces</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[^a-zA-Z\s]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">I</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="c1"># tokenize document</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">wpt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="c1"># filter stopwords out of document</span>
    <span class="n">filtered_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="c1"># re-create document from filtered tokens</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered_tokens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">doc</span>


<span class="n">normalize_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">normalize_document</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">norm_corpus</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;The sky is blue and beautiful.&#39; &#39;Love this blue and beautiful sky!&#39;
 &#39;The quick brown fox jumps over the lazy dog.&#39;
 &quot;A king&#39;s breakfast has sausages, ham, bacon, eggs, toast and beans&quot;
 &#39;I love green eggs, ham, sausages and bacon!&#39;
 &#39;The brown fox is quick and the blue dog is lazy!&#39;
 &#39;The sky is very blue and the sky is very beautiful today&#39;
 &#39;The dog is lazy but the brown fox is quick!&#39;]
==================================================
[&#39;sky blue beautiful&#39; &#39;love blue beautiful sky&#39;
 &#39;quick brown fox jumps lazy dog&#39;
 &#39;kings breakfast sausages ham bacon eggs toast beans&#39;
 &#39;love green eggs ham sausages bacon&#39; &#39;brown fox quick blue dog lazy&#39;
 &#39;sky blue sky beautiful today&#39; &#39;dog lazy brown fox quick&#39;]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bag-of-words-model">
<h2>Bag of Words Model<a class="headerlink" href="#bag-of-words-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Bag-of-words model is the simplest way (i.e., easy to be automated) to vectorize texts into numeric representations.</p></li>
<li><p>In short, it is a method to represent a text using its word frequency list.</p></li>
</ul>
<p><img alt="" src="../_images/text-representation-bow.gif" /></p>
<div class="section" id="countvectorizer-from-sklearn">
<h3><code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code><a class="headerlink" href="#countvectorizer-from-sklearn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="c1"># get bag of words features in sparse format</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;8x20 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 42 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view non-zero feature positions in the sparse matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  (0, 17)	1
  (0, 3)	1
  (0, 2)	1
  (1, 17)	1
  (1, 3)	1
  (1, 2)	1
  (1, 14)	1
  (2, 15)	1
  (2, 5)	1
  (2, 8)	1
  (2, 11)	1
  (2, 13)	1
  (2, 6)	1
  (3, 12)	1
  (3, 4)	1
  (3, 16)	1
  (3, 10)	1
  (3, 0)	1
  (3, 7)	1
  (3, 18)	1
  (3, 1)	1
  (4, 14)	1
  (4, 16)	1
  (4, 10)	1
  (4, 0)	1
  (4, 7)	1
  (4, 9)	1
  (5, 3)	1
  (5, 15)	1
  (5, 5)	1
  (5, 8)	1
  (5, 13)	1
  (5, 6)	1
  (6, 17)	2
  (6, 3)	1
  (6, 2)	1
  (6, 19)	1
  (7, 15)	1
  (7, 5)	1
  (7, 8)	1
  (7, 13)	1
  (7, 6)	1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view dense representation</span>
<span class="c1"># warning might give a memory error if data is too big</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],
       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],
       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],
       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],
       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],
       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get all unique words in the corpus</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="c1"># show document feature vectors</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Issues with Bag-of-Words Text Representation</p>
<ul>
<li><p><strong>Word order</strong> is ignored.</p></li>
<li><p><strong>Raw</strong> absolute frequency counts of words do not necessarily represent the meaning of the text properly.</p></li>
<li><p><strong>Marginal</strong> frequencies play important roles. (Row and Columns)</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="improving-bag-of-words-text-representation">
<h2>Improving Bag-of-Words Text Representation<a class="headerlink" href="#improving-bag-of-words-text-representation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>In BOW text representation, the most crucial question is to identify words that are indeed <strong>representative</strong> of the semantics of texts.</p></li>
<li><p>To improve the BOW representation:</p>
<ul>
<li><p>We can extend from unigram-based BOW model to <strong>n-gram</strong> based BOW model to consider partially the word order in texts.</p></li>
<li><p>We can <strong>filter</strong> words based on the distributional criteria (e.g., term frequencies) or morphosyntactic patterns (e.g., morphological endings).</p></li>
<li><p>We can <strong>weight</strong> the BOW raw frequency counts.</p></li>
</ul>
</li>
</ul>
<p>In <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code>, we can utilize its parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_df</span></code>: When building the vocabulary, the vectorizer will ignore terms that have a <strong>document frequency</strong> strictly higher than the given threshold (corpus-specific stop words). <code class="docutils literal notranslate"><span class="pre">float</span></code> = the parameter represents a proportion of documents; <code class="docutils literal notranslate"><span class="pre">integer</span></code> = absolute counts.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_df</span></code>: When building the vocabulary, the vectorizer will ignore terms that have a <strong>document frequency</strong> strictly lower than the given threshold. <code class="docutils literal notranslate"><span class="pre">float</span></code> = the parameter represents a proportion of documents; <code class="docutils literal notranslate"><span class="pre">integer</span></code> = absolute counts.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code> : Build a vocabulary that only consider the top <code class="docutils literal notranslate"><span class="pre">max_features</span></code> ordered by term frequency across the corpus.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ngram_range</span></code> : The lower and upper boundary of the range of n-values for different word n-grams. <code class="docutils literal notranslate"><span class="pre">tuple</span></code> (min_n, max_n), default=(1, 1).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">token_pattern</span></code>: Regular expression denoting what constitutes a “token” in vocabulary. The default regexp select tokens of 2 or more alphanumeric characters (Note: <strong>punctuation</strong> is completely ignored and always treated as a token separator).</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>When applying the <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> to Chinese data, if you have word-segmented your corpus data, then remember to specify the <code class="docutils literal notranslate"><span class="pre">token_pattern</span></code> in <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> to ensure the integrity of the original word tokens.</p>
</div>
</div>
<div class="section" id="n-gram-bag-of-words-text-representation">
<h2>N-gram Bag-of-Words Text Representation<a class="headerlink" href="#n-gram-bag-of-words-text-representation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># you can set the n-gram range to 1,2 to get unigrams as well as bigrams</span>
<span class="n">bv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">bv_matrix</span> <span class="o">=</span> <span class="n">bv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>

<span class="n">bv_matrix</span> <span class="o">=</span> <span class="n">bv_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">bv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon eggs</th>
      <th>beautiful sky</th>
      <th>beautiful today</th>
      <th>blue beautiful</th>
      <th>blue dog</th>
      <th>blue sky</th>
      <th>breakfast sausages</th>
      <th>brown fox</th>
      <th>dog lazy</th>
      <th>eggs ham</th>
      <th>...</th>
      <th>lazy dog</th>
      <th>love blue</th>
      <th>love green</th>
      <th>quick blue</th>
      <th>quick brown</th>
      <th>sausages bacon</th>
      <th>sausages ham</th>
      <th>sky beautiful</th>
      <th>sky blue</th>
      <th>toast beans</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 29 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="tf-idf-model">
<h2>TF-IDF Model<a class="headerlink" href="#tf-idf-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>TF-IDF model is an extension of the bag-of-words model, whose main objective is to adjust the raw frequency counts by considering the <strong>dispersion</strong> of the words in the corpus.</p></li>
<li><p><strong>Disperson</strong> refers to how evenly each word/term is distributed across different documents of the corpus.</p></li>
</ul>
<ul class="simple">
<li><p>Interaction between Word Raw Frequency Counts and Dispersion:</p>
<ul>
<li><p>Given a <strong>high-frequency</strong> word:</p>
<ul>
<li><p>If the word is widely dispersed across different documents of the corpus (i.e., <strong>high dispersion</strong>)</p>
<ul>
<li><p>it is more likely to be semantically general.</p></li>
</ul>
</li>
<li><p>If the word is mostly centralized in a limited set of documents in the corpus (i.e., <strong>low dispersion</strong>)</p>
<ul>
<li><p>it is more likely to be topic-specific.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Dispersion rates of words can be used as weights for the importance of word frequency counts.</p></li>
</ul>
<ul class="simple">
<li><p><strong>Document Frequency</strong> (<strong>DF</strong>) is an intuitive metric for measuring word dispersion across the corpus. DF refers to the number of documents where the word occurs (at least once).</p></li>
<li><p>The inverse of the DF is referred to as <strong>Inverse Document Frequency</strong> (<strong>IDF</strong>). IDF is usually computed as follows:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ 
\textit{IDF} = 1 + log\frac{N}{1+df}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All these plus-1’s in the above formula are avoid potential division by zero errors.</p>
</div>
<ul class="simple">
<li><p>The raw absolute frequency counts of words in the BOW model are referred to as <strong>Term Frequency</strong> (<strong>TF</strong>).</p></li>
<li><p>The <strong>TF-IDF</strong> Weighting Scheme:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\textit{TF-IDF}_{normalized} = \frac{tf \times idf}{\sqrt{(tf\times idf)^2}}
\]</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">tfidf</span></code> is normalized using the L2 norm, i.e., the Euclidean norm (taking the square root of the sum of the square of <code class="docutils literal notranslate"><span class="pre">tfidf</span></code> metrics).</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<ul class="simple">
<li><p>The L1 norm will drive some weights to 0, inducing sparsity in the weights. This can be beneficial for memory efficiency or when feature selection is needed (i.e., we want to select only certain weights).</p></li>
<li><p>The L2 norm instead will reduce all weights but not all the way to 0. This is less memory efficient but can be useful if we want/need to retain all parameters.</p></li>
</ul>
</div>
<div class="section" id="tfidftransformer-from-sklearn">
<h3><code class="docutils literal notranslate"><span class="pre">TfidfTransformer()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code><a class="headerlink" href="#tfidftransformer-from-sklearn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>

<span class="n">tt</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tt_matrix</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>

<span class="n">tt_matrix</span> <span class="o">=</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tt_matrix</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.60</td>
      <td>0.53</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.60</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.49</td>
      <td>0.43</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.57</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.53</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.32</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.47</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.36</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.72</td>
      <td>0.00</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="tfidfvectorizer-from-sklearn">
<h3><code class="docutils literal notranslate"><span class="pre">TfidfVectorizer()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code><a class="headerlink" href="#tfidfvectorizer-from-sklearn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                     <span class="n">max_df</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                     <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                     <span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tv_matrix</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">tv_matrix</span> <span class="o">=</span> <span class="n">tv_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tv_matrix</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.60</td>
      <td>0.53</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.60</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.49</td>
      <td>0.43</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.57</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.53</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.32</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.47</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.36</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.72</td>
      <td>0.00</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="intuition-of-tf-idf">
<h2>Intuition of TF-IDF<a class="headerlink" href="#intuition-of-tf-idf" title="Permalink to this headline">¶</a></h2>
<p>The following shows the creation and computation of the TFIDF matrix step by step. Please go over the codes on your own if you are interested.</p>
<div class="section" id="create-vocabulary-dictionary-of-the-corpus">
<h3>Create Vocabulary Dictionary of the Corpus<a class="headerlink" href="#create-vocabulary-dictionary-of-the-corpus" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get unique words as feature names</span>
<span class="n">unique_words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
    <span class="nb">set</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_corpus</span><span class="p">]</span>
         <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]))</span>

<span class="c1"># default dict </span>
<span class="n">def_feature_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">unique_words</span><span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Feature Names:&#39;</span><span class="p">,</span> <span class="n">unique_words</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default Feature Dict:&#39;</span><span class="p">,</span> <span class="n">def_feature_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature Names: [&#39;brown&#39;, &#39;breakfast&#39;, &#39;blue&#39;, &#39;bacon&#39;, &#39;love&#39;, &#39;fox&#39;, &#39;quick&#39;, &#39;dog&#39;, &#39;sky&#39;, &#39;sausages&#39;, &#39;green&#39;, &#39;lazy&#39;, &#39;beautiful&#39;, &#39;kings&#39;, &#39;jumps&#39;, &#39;ham&#39;, &#39;today&#39;, &#39;toast&#39;, &#39;beans&#39;, &#39;eggs&#39;]
Default Feature Dict: {&#39;brown&#39;: 0, &#39;breakfast&#39;: 0, &#39;blue&#39;: 0, &#39;bacon&#39;: 0, &#39;love&#39;: 0, &#39;fox&#39;: 0, &#39;quick&#39;: 0, &#39;dog&#39;: 0, &#39;sky&#39;: 0, &#39;sausages&#39;: 0, &#39;green&#39;: 0, &#39;lazy&#39;: 0, &#39;beautiful&#39;: 0, &#39;kings&#39;: 0, &#39;jumps&#39;: 0, &#39;ham&#39;: 0, &#39;today&#39;: 0, &#39;toast&#39;: 0, &#39;beans&#39;: 0, &#39;eggs&#39;: 0}
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-document-word-matrix-bag-of-word-frequencies">
<h3>Create Document-Word Matrix (Bag-of-Word Frequencies)<a class="headerlink" href="#create-document-word-matrix-bag-of-word-frequencies" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="c1"># build bag of words features for each document - term frequencies</span>
<span class="n">bow_features</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_corpus</span><span class="p">:</span>
    <span class="n">bow_feature_doc</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="c1"># initialize default corpus dictionary</span>
    <span class="n">all_features</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">def_feature_dict</span><span class="p">)</span> 
    
    <span class="c1"># update default dict with current doc words</span>
    <span class="n">bow_feature_doc</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">all_features</span><span class="p">)</span>
    
    <span class="c1"># append cur doc dict</span>
    <span class="n">bow_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bow_feature_doc</span><span class="p">)</span>

<span class="n">bow_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bow_features</span><span class="p">)</span>
<span class="n">bow_features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="compute-document-frequency-of-words">
<h3>Compute Document Frequency of Words<a class="headerlink" href="#compute-document-frequency-of-words" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bow_features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># build the document frequency matrix</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">csc_matrix</span><span class="p">(</span><span class="n">bow_features</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">indptr</span><span class="p">)</span>
<span class="c1"># `csc_matrix()` compress `bow_features` into sparse matrix based on columns</span>
<span class="c1"># `csc_matrix.indices` stores the matrix value indices in each column</span>
<span class="c1"># `csc_matrix.indptr` stores the accumulative numbers of values from column-0 to the right-most column</span>

<span class="n">df</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">df</span>  <span class="c1"># adding 1 to smoothen idf later</span>

<span class="c1"># show smoothened document frequencies</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">df</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="create-inverse-document-frequency-of-words">
<h3>Create Inverse Document Frequency of Words<a class="headerlink" href="#create-inverse-document-frequency-of-words" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute inverse document frequencies for each term</span>
<span class="n">total_docs</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">idf</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">total_docs</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># show smoothened idfs</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">idf</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.81</td>
      <td>1.59</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>2.5</td>
      <td>2.1</td>
      <td>2.1</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>2.1</td>
      <td>2.5</td>
      <td>1.81</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>2.1</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>2.1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="compute-raw-tf-idf-for-each-document">
<h3>Compute Raw TF-IDF for Each Document<a class="headerlink" href="#compute-raw-tf-idf-for-each-document" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute tfidf feature matrix</span>
<span class="n">tf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bow_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">tf</span> <span class="o">*</span> <span class="n">idf</span>  <span class="c1">## `tf.shape` = (8,20), `idf.shape`=(20,)</span>
<span class="c1"># view raw tfidf feature matrix</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tfidf</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.81</td>
      <td>1.59</td>
      <td>1.81</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.81</td>
      <td>1.59</td>
      <td>1.81</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.1</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>2.5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>2.5</td>
      <td>2.1</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>2.1</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>2.5</td>
      <td>0.0</td>
      <td>2.1</td>
      <td>0.0</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>2.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>2.1</td>
      <td>2.1</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>2.1</td>
      <td>2.5</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>1.59</td>
      <td>0.00</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.62</td>
      <td>1.59</td>
      <td>1.81</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.81</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="get-l2-norms-of-tf-idf">
<h3>Get L2 Norms of TF-IDF<a class="headerlink" href="#get-l2-norms-of-tf-idf" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="c1"># compute L2 norms</span>
<span class="n">norms</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">tfidf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># get the L2 forms of tfidf according to columns</span>

<span class="c1"># print norms for each document</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">norms</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[3.013 3.672 4.761 6.534 5.319 4.35  5.019 4.049]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="compute-normalized-tf-idf-for-each-document">
<h3>Compute Normalized TF-IDF for Each Document<a class="headerlink" href="#compute-normalized-tf-idf-for-each-document" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute normalized tfidf</span>
<span class="n">norm_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span> <span class="o">/</span> <span class="n">norms</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># show final tfidf feature matrix</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">norm_tfidf</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.60</td>
      <td>0.53</td>
      <td>0.60</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.49</td>
      <td>0.43</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.57</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.38</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.53</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.00</td>
      <td>0.32</td>
      <td>0.0</td>
      <td>0.38</td>
      <td>0.38</td>
      <td>0.32</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.39</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.47</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.39</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.42</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.72</td>
      <td>0.32</td>
      <td>0.36</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.5</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.45</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.45</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_doc</span> <span class="o">=</span> <span class="s1">&#39;the sky is green today&#39;</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tv</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="n">new_doc</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="mi">2</span><span class="p">),</span>
             <span class="n">columns</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bacon</th>
      <th>beans</th>
      <th>beautiful</th>
      <th>blue</th>
      <th>breakfast</th>
      <th>brown</th>
      <th>dog</th>
      <th>eggs</th>
      <th>fox</th>
      <th>green</th>
      <th>ham</th>
      <th>jumps</th>
      <th>kings</th>
      <th>lazy</th>
      <th>love</th>
      <th>quick</th>
      <th>sausages</th>
      <th>sky</th>
      <th>toast</th>
      <th>today</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.63</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.46</td>
      <td>0.0</td>
      <td>0.63</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="document-similarity">
<h2>Document Similarity<a class="headerlink" href="#document-similarity" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Now each document in our corpus has been transformed into a <strong>vectorized</strong> representation using the naive Bag-of-Words method.</p></li>
<li><p>And we believe that these vectorized representations are indicators of textual <strong>semantics</strong>.</p></li>
<li><p>This vectorized text vectorization allows us to perform mathematical computation of the <strong>semantic relationships</strong> between documents.</p></li>
</ul>
</div>
<div class="section" id="similarity-distance-metrics-and-intuition">
<h2>Similarity/Distance Metrics and Intuition<a class="headerlink" href="#similarity-distance-metrics-and-intuition" title="Permalink to this headline">¶</a></h2>
<p>Take a two-dimensional space for instance. If we have vectors on this space, we can compute their distance/similarity mathematically:</p>
<p><img alt="" src="../_images/text-vec.001.jpeg" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">manhattan_distances</span><span class="p">,</span> <span class="n">euclidean_distances</span><span class="p">,</span> <span class="n">cosine_similarity</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xyz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">xyz</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 9],
       [1, 3],
       [5, 1]])
</pre></div>
</div>
</div>
</div>
<p>In Math, there are in general two types of metrics to measure the relationship between vectors: <strong>distance</strong>-based vs. <strong>similarity</strong>-based metrics.</p>
<div class="section" id="distance-based-metrics">
<h3>Distance-based Metrics<a class="headerlink" href="#distance-based-metrics" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Many distance measures of vectors are based on the following formula and differ in individual parameter settings.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\big( \sum_{i = 1}^{n}{|x_i - y_i|^y}\big)^{\frac{1}{y}}
\]</div>
<ul class="simple">
<li><p>The <em>n</em> in the above formula refers to the number of dimensions of the vectors. (In other words, all the concepts we discuss here can be easily extended to vectors in multidimensional spaces.)</p></li>
<li><p>When <em>y</em> is set to 2, it computes the famous <strong>Euclidean distance</strong> of two vectors, i.e., the direct spatial distance between two points on the <em>n</em>-dimensional space.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sqrt{\big( \sum_{i = 1}^{n}{|x_i - y_i|^2}\big)}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">xyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.        , 6.        , 8.94427191],
       [6.        , 0.        , 4.47213595],
       [8.94427191, 4.47213595, 0.        ]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The geometrical meanings of the Euclidean distance are easy to conceptualize.</p></li>
</ul>
<p><img alt="" src="../_images/text-vec-euclidean.gif" /></p>
</div>
<div class="section" id="similarity-based-metrics">
<h3>Similarity-based Metrics<a class="headerlink" href="#similarity-based-metrics" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>In addition to distance-based metrics, the other type is similarity-based metric, which often utilizes the idea of <strong>correlations</strong>.</p></li>
<li><p>The most commonly used one is <strong>Cosine Similarity</strong>, which can be computed as follows:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
cos(\vec{x},\vec{y}) = \frac{\sum_{i=1}^{n}{x_i\times y_i}}{\sqrt{\sum_{i=1}^{n}x_i^2}\times \sqrt{\sum_{i=1}^{n}y_i^2}}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">xyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.        , 0.97780241, 0.30320366],
       [0.97780241, 1.        , 0.49613894],
       [0.30320366, 0.49613894, 1.        ]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The geometric meanings of <strong>cosines</strong> of two vectors are connected to the <strong>arcs</strong> between the vectors.</p></li>
<li><p>The greater their cosine similarity, the smaller the arcs, the closer (i.e., the more similar) they are.</p></li>
</ul>
<p><img alt="" src="../_images/text-vec-similarity2.png" /></p>
<p><img alt="" src="../_images/text-vec-cosine.gif" /></p>
</div>
<div class="section" id="which-metrics-to-use-then">
<h3>Which Metrics to Use then?<a class="headerlink" href="#which-metrics-to-use-then" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Please note that different metrics may lead to very different results.</p></li>
<li><p>In our earlier examples, if we adopt <strong>euclidean distance</strong>, then y is closer to z than is to x.</p></li>
<li><p>But if we adopt <strong>cosine similarity</strong>, then y is closer to x than is to z.</p></li>
<li><p>The choice of distance/similarity metrics depends on:</p>
<ul>
<li><p>Whether the magnitude of value differences on each dimension of the vectors matters (distance-based preferred)</p></li>
<li><p>Whether the values of each dimension of the vectors co-vary (cosine referred)</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="pairwise-similarity-computation">
<h2>Pairwise Similarity Computation<a class="headerlink" href="#pairwise-similarity-computation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">cosine_similarity</span></code> automatically computes the <strong>pairwise</strong> similarities between the <strong>rows</strong> of the input matrix.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">similarity_doc_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tv_matrix</span><span class="p">)</span>
<span class="n">similarity_doc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">)</span>
<span class="n">similarity_doc_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>0.820599</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.192353</td>
      <td>0.817246</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.820599</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.225489</td>
      <td>0.157845</td>
      <td>0.670631</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.791821</td>
      <td>0.000000</td>
      <td>0.850516</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.506866</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000000</td>
      <td>0.225489</td>
      <td>0.000000</td>
      <td>0.506866</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.192353</td>
      <td>0.157845</td>
      <td>0.791821</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.115488</td>
      <td>0.930989</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.817246</td>
      <td>0.670631</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.115488</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.850516</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.930989</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="clustering-documents-using-similarity-features">
<h2>Clustering Documents Using Similarity Features<a class="headerlink" href="#clustering-documents-using-similarity-features" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="c1"># pd.DataFrame(Z,</span>
<span class="c1">#              columns=[</span>
<span class="c1">#                  &#39;Document\Cluster 1&#39;, &#39;Document\Cluster 2&#39;, &#39;Distance&#39;,</span>
<span class="c1">#                  &#39;Cluster Size&#39;</span>
<span class="c1">#              ],</span>
<span class="c1">#              dtype=&#39;object&#39;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Hierarchical Clustering Dendrogram&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Data point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7fa9192fa5c0&gt;
</pre></div>
</div>
<img alt="../_images/text-vec-traditional_79_1.png" src="../_images/text-vec-traditional_79_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Convert hierarchical cluster into a flat cluster structure</span>

<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">fcluster</span>
<span class="n">max_dist</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">max_dist</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cluster_labels</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ClusterLabel&#39;</span><span class="p">])</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">corpus_df</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Document</th>
      <th>Category</th>
      <th>ClusterLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The sky is blue and beautiful.</td>
      <td>weather</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Love this blue and beautiful sky!</td>
      <td>weather</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The quick brown fox jumps over the lazy dog.</td>
      <td>animals</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>
      <td>food</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>I love green eggs, ham, sausages and bacon!</td>
      <td>food</td>
      <td>3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>The brown fox is quick and the blue dog is lazy!</td>
      <td>animals</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The sky is very blue and the sky is very beautiful today</td>
      <td>weather</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>The dog is lazy but the brown fox is quick!</td>
      <td>animals</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="clustering-words-using-similarity-features">
<h2>Clustering Words Using Similarity Features<a class="headerlink" href="#clustering-words-using-similarity-features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We can also transpose the <code class="docutils literal notranslate"><span class="pre">tv_matrix</span></code> to get a Word-Document matrix.</p></li>
<li><p>Each word can be represented as vectors based on their document distributions.</p></li>
<li><p>Words that are semantically similar tend to show similar distributions.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">similarity_term_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tv_matrix</span><span class="p">))</span>
<span class="n">similarity_term_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_term_matrix</span><span class="p">,</span>
                                  <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
                                  <span class="n">index</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">similarity_term_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sky</th>
      <th>blue</th>
      <th>beautiful</th>
      <th>brown</th>
      <th>breakfast</th>
      <th>bacon</th>
      <th>love</th>
      <th>fox</th>
      <th>quick</th>
      <th>dog</th>
      <th>sausages</th>
      <th>green</th>
      <th>lazy</th>
      <th>kings</th>
      <th>jumps</th>
      <th>ham</th>
      <th>today</th>
      <th>toast</th>
      <th>beans</th>
      <th>eggs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sky</th>
      <td>1.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>blue</th>
      <td>0.631290</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>beautiful</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.899485</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.473517</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.951208</td>
      <td>0.00000</td>
      <td>0.420997</td>
    </tr>
    <tr>
      <th>brown</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.899485</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.252766</td>
      <td>0.252766</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.252766</td>
      <td>0.425922</td>
      <td>0.252766</td>
      <td>0.000000</td>
      <td>0.855597</td>
      <td>0.00000</td>
      <td>0.378680</td>
    </tr>
    <tr>
      <th>breakfast</th>
      <td>0.631290</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>bacon</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>love</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>fox</th>
      <td>1.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>quick</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>dog</th>
      <td>0.775547</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.775547</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.568135</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>sausages</th>
      <td>1.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>green</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.528473</td>
      <td>0.528473</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.528473</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>lazy</th>
      <td>0.631290</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>kings</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>jumps</th>
      <td>0.440615</td>
      <td>0.00000</td>
      <td>0.473517</td>
      <td>0.425922</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>0.568135</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.382602</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>ham</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.252766</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.528473</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>today</th>
      <td>1.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.775547</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
      <td>0.440615</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.63129</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>toast</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.951208</td>
      <td>0.855597</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.382602</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.680330</td>
    </tr>
    <tr>
      <th>beans</th>
      <td>0.631290</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.631290</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>eggs</th>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.420997</td>
      <td>0.378680</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.680330</td>
      <td>0.00000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z2</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">similarity_term_matrix</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="c1"># pd.DataFrame(Z2,</span>
<span class="c1">#              columns=[</span>
<span class="c1">#                  &#39;Document\Cluster 1&#39;, &#39;Document\Cluster 2&#39;, &#39;Distance&#39;,</span>
<span class="c1">#                  &#39;Cluster Size&#39;</span>
<span class="c1">#              ],</span>
<span class="c1">#              dtype=&#39;object&#39;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Document\Cluster 1</th>
      <th>Document\Cluster 2</th>
      <th>Distance</th>
      <th>Cluster Size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12</td>
      <td>21</td>
      <td>0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>6</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>23</td>
      <td>0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10</td>
      <td>20</td>
      <td>0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>6</th>
      <td>13</td>
      <td>24</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>16</td>
      <td>25</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>8</th>
      <td>15</td>
      <td>26</td>
      <td>0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>18</td>
      <td>22</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>10</th>
      <td>2</td>
      <td>17</td>
      <td>0.286718</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3</td>
      <td>30</td>
      <td>0.715754</td>
      <td>3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>9</td>
      <td>14</td>
      <td>1.17207</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13</th>
      <td>19</td>
      <td>31</td>
      <td>1.29113</td>
      <td>4</td>
    </tr>
    <tr>
      <th>14</th>
      <td>11</td>
      <td>28</td>
      <td>1.52639</td>
      <td>6</td>
    </tr>
    <tr>
      <th>15</th>
      <td>27</td>
      <td>32</td>
      <td>2.56361</td>
      <td>6</td>
    </tr>
    <tr>
      <th>16</th>
      <td>29</td>
      <td>35</td>
      <td>3.46249</td>
      <td>10</td>
    </tr>
    <tr>
      <th>17</th>
      <td>33</td>
      <td>34</td>
      <td>5.49711</td>
      <td>10</td>
    </tr>
    <tr>
      <th>18</th>
      <td>36</td>
      <td>37</td>
      <td>8.09818</td>
      <td>20</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Hierarchical Clustering Dendrogram&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Data point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z2</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">leaf_rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7fa909193518&gt;
</pre></div>
</div>
<img alt="../_images/text-vec-traditional_85_1.png" src="../_images/text-vec-traditional_85_1.png" />
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Based on Sarkar (2020), Ch 4 Feature Engineering and Text Representation</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chinese-word-seg.html" title="previous page">Chinese Word Segmentation</a>
    <a class='right-next' id="next-link" href="ml-overview.html" title="next page">Machine Learning: Overview</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>