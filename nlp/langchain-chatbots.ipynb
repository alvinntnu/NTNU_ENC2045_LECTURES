{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Using Langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chat model usually consists of several major components:\n",
    "\n",
    "* `chat model`: this refers to the chat model interface in LangChain, i.e., the large langauge models.\n",
    "* `prompt template`: Prompt templates make it easy to assemble prompts that combine default messages, user input, chat history, and (optionally) additional retrieved context.\n",
    "* `memory`: this refers to the control of memory in the previous conversations.\n",
    "* `retriever` (optional): These are useful if you want to build a chatbot with domain-specific knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set env var OPENAI_API_KEY or load from a .env file:\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/alvinchen/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart for a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a plain chat model, we can get chat completions by passing one or more messages to the model. The chat model will respond with a message.\n",
    "- The chat model interface is based around messages rather than raw text. The types of messages currently supported in LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`, `FunctionMessage` and `ChatMessage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='计算语言学非常具有挑战性。')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4', temperature= 0.6)\n",
    "chat(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to Chinese: Computational Linguistics is very challenging.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='計算語言學非常具有挑戰性！')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a professional translator that translates English to Taiwan Mandarin.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Computational linguistics is very challenging!\"),\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can wrap the chat model in a chain, which is designed with built-in memory for remembering the previous converstaional exhcanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"計算語言學非常具有挑戰性。\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(llm=chat)\n",
    "conversation.run('Translate this sentence from English to Taiwan Mandarin: Computational Linguistics is very challenging.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are two examples:\\n\\n1. 在機器翻譯領域，計算語言學非常具有挑戰性。例如，機器需要理解和分析語言的語義與語境，這對於人工智能來說是一項艱鉅的任務。\\n\\n2. 在語音識別技術中，計算語言學也非常具有挑戰性。例如，機器需要準確識別和轉錄人類的語音，並且需要處理各種方言和口音的差異。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run('Support the sentence with two examples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"What day is today?\")\n",
    "memory.chat_memory.add_ai_message(\"Sunday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What day is today?\\nAI: Sunday'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"Today is Sunday.\"}, {\"output\": \"Ok.\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"Today is November 26, 2023\"},\n",
    "    {\"output\": \"oh, thank you for telling me\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human states that today is Sunday and the AI acknowledges it. The human then informs the AI that today is November 26, 2023, and the AI expresses gratitude for the information.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put memory and llm in the conversation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, memory = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The day before yesterday was November 24, 2023.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"So what date was the day before yesterday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- This tutorial is based on the official documentations, [Chatbots](https://python.langchain.com/docs/use_cases/chatbots)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
