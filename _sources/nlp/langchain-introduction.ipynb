{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain: An Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/svg/langchain_stack.svg)\n",
    "*This image is from [Langchain official documentation](https://python.langchain.com/docs/get_started/introduction).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Langchain?\n",
    "\n",
    "Langchain is an open-source framework designed for developers working with artificial intelligence (AI). It facilitates the integration of large language models (LLMs) like GPT-4 with external sources of computation and data. Here's a breakdown of Langchain's key components and functionalities:\n",
    "\n",
    "### 1. Integration of Large Language Models (LLMs):\n",
    "- Langchain allows developers to seamlessly connect LLMs such as GPT-4 to external data sources and computation platforms.\n",
    "- This integration enables developers to leverage the vast knowledge and capabilities of LLMs in combination with their own data and applications.\n",
    "\n",
    "### 2. Addressing Specific Information Needs:\n",
    "- While LLMs like GPT-4 possess extensive general knowledge, Langchain addresses the need for specific information from proprietary or domain-specific data sources.\n",
    "- Developers can utilize Langchain to connect LLMs to their own datasets, including documents, PDF files, or proprietary databases.\n",
    "\n",
    "### 3. Dynamic Data Referencing:\n",
    "- Unlike traditional methods that involve pasting snippets of text into chat prompts, Langchain allows for referencing entire databases of proprietary data.\n",
    "- Developers can segment their data into smaller chunks and store them in a vector database as embeddings, enabling efficient referencing and retrieval.\n",
    "\n",
    "### 4. Pipeline for Language Model Applications:\n",
    "- Langchain facilitates the development of language model applications following a structured pipeline.\n",
    "- The pipeline typically involves:\n",
    "  - User input: Initial questions or queries from users.\n",
    "  - Language model interaction: Sending user input to the LLM for processing.\n",
    "  - Similarity search: Matching user queries with relevant data chunks in the vector database.\n",
    "  - Action or response: Providing answers or taking actions based on the combined information from the LLM and vector database.\n",
    "\n",
    "### 5. Practical Use Cases:\n",
    "- Langchain's capabilities enable a wide range of practical applications, particularly in personal assistance, education, and data analytics.\n",
    "- Examples include booking flights, transferring money, learning new subjects, and analyzing company data for insights.\n",
    "\n",
    "### 6. Key Components of Langchain:\n",
    "- **LLM Wrappers:** Facilitate connection to LLMs like GPT-4.\n",
    "- **Prompt Templates:** Dynamically generate prompts for LLMs based on user input.\n",
    "- **Indexes:** Extract relevant information from datasets for LLM processing.\n",
    "- **Chains:** Combine multiple components to build LLM applications following a specific task.\n",
    "- **Agents:** Enable LLMs to interact with external APIs for additional functionality.\n",
    "\n",
    "### 7. Continuous Development and Expansion:\n",
    "- Langchain is continually evolving, with new features and capabilities being added regularly.\n",
    "- The framework offers a flexible and scalable solution for developers looking to integrate LLMs into their applications.\n",
    "\n",
    "In summary, Langchain provides developers with a powerful framework for harnessing the capabilities of LLMs and integrating them with external data sources, enabling the development of sophisticated language model applications across various domains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install langchain-community\n",
    "# pip install langchain-core\n",
    "# pip install -U langchain-openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain openai weaviate-client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save environment variables in a `.env` file and use the `dotenv` library in Python to load them, follow these steps:\n",
    "\n",
    "### Saving Environment Variables in a `.env` File:\n",
    "1. Create a new file in your project directory and name it `.env`. This file will store your environment variables.\n",
    "2. Add your environment variables to the `.env` file in the format `VARIABLE_NAME=variable_value`. For example:\n",
    "   ```\n",
    "   OPENAI_API_KEY=your_api_key\n",
    "   DATABASE_URL=your_database_url\n",
    "   ```\n",
    "\n",
    "### Using `dotenv` in Python to Load Environment Variables:\n",
    "3. Install the `dotenv` library if you haven't already installed it. You can install it using pip:\n",
    "   ```\n",
    "   pip install python-dotenv\n",
    "   ```\n",
    "\n",
    "4. In your Python script, import the `dotenv` module:\n",
    "   ```python\n",
    "   from dotenv import load_dotenv\n",
    "   ```\n",
    "\n",
    "5. Load the environment variables from the `.env` file using the `load_dotenv()` function. Place this line at the beginning of your script:\n",
    "   ```python\n",
    "   load_dotenv()\n",
    "   ```\n",
    "\n",
    "6. Access the environment variables in your Python script using the `os.environ` dictionary. For example:\n",
    "   ```python\n",
    "   import os\n",
    "\n",
    "   api_key = os.environ.get('API_KEY')\n",
    "   database_url = os.environ.get('DATABASE_URL')\n",
    "\n",
    "   print(\"API Key:\", api_key)\n",
    "   print(\"Database URL:\", database_url)\n",
    "   ```\n",
    "\n",
    "### Notes:\n",
    "- Make sure to add the `.env` file to your project's `.gitignore` file to prevent sensitive information from being exposed.\n",
    "- You can also specify the path to the `.env` file if it's located in a different directory:\n",
    "  ```python\n",
    "  load_dotenv('/path/to/your/env/file/.env')\n",
    "  ```\n",
    "\n",
    "By following these steps, you can save environment variables in a `.env` file and use the `dotenv` library in Python to load them into your script. This approach helps keep sensitive information separate from your codebase and makes it easier to manage environment variables in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "load_dotenv('/Users/alvinchen/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alvinchen/.env'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/assets/images/model_io-e6fc0045b7eae0377a4ddeb90dc8cdb8.jpg)\n",
    "*This image is from [Langchain official documentation](https://python.langchain.com/docs/modules/model_io/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize Chat model\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name=\"gpt-4\",temperature=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models are advanced machine learning algorithms designed to understand and generate human-like text by being trained on a vast amount of data.\n"
     ]
    }
   ],
   "source": [
    "## Interact with the Chat model immediately\n",
    "response = chat.invoke(\"explain large language models in one sentence\")\n",
    "print(response.content,end='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    AIMessage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is an example Python script using the popular deep learning library TensorFlow to train a simple neural network on simulated data:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(100, 2)\n",
      "y = np.random.randint(0, 2, 100)\n",
      "\n",
      "# Define the neural network architecture\n",
      "model = tf.keras.models.Sequential([\n",
      "    tf.keras.layers.Dense(10, activation='relu', input_shape=(2,)),\n",
      "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
      "])\n",
      "\n",
      "# Compile the model\n",
      "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=32)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data with 2 features and binary labels. We then define a simple neural network with one hidden layer of 10 neurons and an output layer with a sigmoid activation function. We compile the model with binary crossentropy loss and train it on the simulated data for 10 epochs.\n",
      "\n",
      "Finally, we evaluate the model on the training data and print out the loss and accuracy. You can modify this script to experiment with different neural network architectures, loss functions, optimizers, and hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
    "]\n",
    "response=chat.invoke(messages)\n",
    "\n",
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt and define PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a college professor with an expertise in building deep learning models. \n",
    "Answer the answer of {question} like I am five.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LLM with PromptTemplate\n",
    "response = chat.invoke(prompt.format(question=\"What is backpropogation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropagation is like a teacher helping you learn how to ride a bike by telling you what you did wrong and how to fix it, so you can get better and better at riding without falling off.\n"
     ]
    }
   ],
   "source": [
    "print(response.content,end='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\": \"What is gradient descent?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you are trying to find the bottom of a hill by taking small steps downhill. Gradient descent is like a magical way to figure out which direction to step in order to get to the bottom of the hill faster. It helps us adjust our steps so we can reach the bottom of the hill (or the best solution) in the quickest way possible.\n"
     ]
    }
   ],
   "source": [
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain2 = prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you are trying to find the bottom of a big slide in a playground. Gradient descent is like taking small steps down the slide until you reach the bottom. It helps us find the best way to adjust our deep learning model to make it work better.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"question\": \"What is gradient descent?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining A Series of Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what is derivative?', 'text': \"Imagine you are playing with a toy car on a track that goes up and down hills. The derivative is like looking at how fast the car is going at different points on the track. If the car is going uphill, the derivative tells us how steep the hill is. If the car is going downhill, the derivative tells us how fast it's speeding up. It helps us understand how things are changing at different moments.\"}\n"
     ]
    }
   ],
   "source": [
    "# Import LLMChain and define chain with language model and prompt as arguments.\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.invoke(\"what is derivative?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a second prompt \n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"prev_ans\"],\n",
    "    template=\"Translate the answer description of {prev_ans} in traditional Chinese\",\n",
    ")\n",
    "chain_two = LLMChain(llm=chat, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mImagine you are trying to find the bottom of a hill by taking small steps downhill. Gradient descent is like taking tiny steps in the direction that will help you reach the bottom of the hill faster. It's a method used by computers to adjust and improve their predictions in deep learning models.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m想像一下，你正在尝试通过小步走下坡来找到山脚下。梯度下降就像是在朝着能让你更快到达山脚下的方向迈出微小步伐。这是计算机在深度学习模型中用来调整和改进预测的方法。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is gradient descent?', 'output': '想像一下，你正在尝试通过小步走下坡来找到山脚下。梯度下降就像是在朝着能让你更快到达山脚下的方向迈出微小步伐。这是计算机在深度学习模型中用来调整和改进预测的方法。'}\n"
     ]
    }
   ],
   "source": [
    "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "explanation = overall_chain.invoke(\"what is gradient descent?\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap  = 0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([explanation])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想像一下你盲目地试图找到山坡的底部。梯度下降就像是在感觉最陡峭的方向上小步往下走，这样你最终会到达最'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual text chunks can be accessed with \"page_content\"\n",
    "\n",
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/assets/images/data_connection-95ff2033a8faa5f3ba41376c0f6dd32a.jpg)\n",
    "*This image is from [Langchain official documentation](https://python.langchain.com/docs/modules/data_connection/).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../../../../ENC2045_demo_data/ENC2045Syllabus.pdf\") # /Users/alvinchen/Library/CloudStorage/GoogleDrive-alvinworks@gmail.com/My Drive/ENC2045_demo_data/ENC2045Syllabus.pdf\n",
    "pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ENC2045: Computational Linguistics\\nThis site is last-updated on 2024-02-23\\n Annoucements\\nImportant course information will be posted on this web page and announced in class. You are responsible for all material that appears\\nhere and should check this page for updates frequently.\\n2024-02-23: The current version of the course website is based on the Spring Semester, 2021. It will be updated for the spring\\nof 2024.\\n2023-12-24: This course is designed for linguistics majors. If you are NOT a linguistics major, please contact the instructor for\\ncourse enrollment.\\n2023-12-24: This course has prerequisites. A test on python basics will be conducted at the beginning of the semester. Please\\nread the FAQ (FAQ.html) very carefully. This course is NOT OPEN to auditors.\\n Course Description\\nComputational Linguistics (CL) is now a very active sub-discipline in applied linguistics. Its main focus is on the computational text\\nanalytics, which is essentially about leveraging computational tools, techniques, and algorithms to process and understand natural\\nlanguage data (in spoken or textual formats). Therefore, this course aims to introduce useful strategies and common work\\x00ows that\\nhave been widely adopted by data scientists to extract useful insights from natural language data. In this course, we will focus on\\ntextual data processing.\\nA selective collection of potential topics may include:\\nA Pipeline for Natural Language Processing\\nText Normalization\\nText Tokenization\\nParsing and Chunking\\nIssues for Chinese Language Processing (Word Segmentation)\\nFeature Engineering and Text Vectorization\\nTraditional Machine Learning\\nClassi\\x00cation Models (Naive Bayes, SVM, Logistic Regression)\\nCommon Computational Tasks:\\nSentiment Analysis\\nTex Clustering and Topic Modeling\\nDeep Learning and Neural Network\\nNeural Language Model\\nSequence Models\\nRNN\\nLSTM/GRU\\nSequence-to-sequence Model\\nAttention-based Models\\nTransfer Learning\\nLarge Language Models(LLM) & Retrieval-Augmented Generation (RAG)\\nMultimodal Processing\\nThis course is extremely hands-on and will guide the students through classic examples of many task-oriented implementations via in-\\nclass theme-based tutorial sessions. The main coding language used in this course is Python  (https://www.python.org/). We will\\nmake extensive use of the language. It is assumed that you know or will quickly learn how to code in Python. In fact, this course\\nassumes that every enrolled student has working knowledge of Python. (If you are not sure if you ful\\x00ll the prerequisite, please\\ncontact the instructor \\x00rst.)', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 0}),\n",
       " Document(page_content='A test on Python Basics will be conducted on the \\x00rst week of the class to ensure that every enrolled student ful\\x00lls the prerequisite.\\n(To be more speci\\x00c, you are assumed to have already had working knowledge of all the concepts included in the book, Lean Python:\\nLearn Just Enough Python to Build Useful Tools (https://www.amazon.com/Lean-Python-Learn-Enough-Useful/dp/1484223845)).\\nThose who fail on the Python basics test are NOT advised to take this course.\\nPlease note that this course is designed speci\\x00cally for linguistics majors in humanities. For computer science majors, please note that\\nthis course will not feature a thorough description of the mathematical operations behind the algorithms. We focus more on the\\npractical implementation.\\n Course Schedule\\n(The schedule is tentative and subject to change. Please pay attention to the announcements made during the class.)\\nWeek Date Topic\\nWeek 1 2023-02-23 Course Orientation and Computational Linguistics Overview\\nWeek 2 2023-03-01 NLP Pipeline\\nWeek 3 2023-03-08 Machine Learning Basics: Regression and Classi\\x00cation\\nWeek 4 2023-03-15 Naïve Bayes, Logistic Regression\\nWeek 5 2023-03-22 Feature Engineering and Text Vectorization\\nWeek 6 2023-03-29 Common NLP Tasks (Guest Speaker: Robin Lin from Droidtown Linguistic Tech. Co.\\xa0Ltd.\\xa0)\\nWeek 7 2023-04-05 Holiday\\nWeek 8 2023-04-12 Midterm Exam\\nWeek 9 2023-04-19 Neural Network: A Primer\\nWeek 10 2023-04-26 Deep Learning NLP and Word/Doc Embeddings\\nWeek 11 2023-05-03 Sequence Model I: RNN and Neural Language Model\\nWeek 12 2023-05-10 Sequence Model II: LSTM and GRU\\nWeek 13 2023-05-17 Sequence Model III: Sequence-to-Sequence Model & Attention\\nWeek 14 2023-05-24 Transformer, BERT, Transfer Learning, and Explainable AI\\nWeek 15 2023-05-31 LLM, RAG, and Multimodal Processing\\nWeek 16 2023-06-07 Final Exam\\n Course Requirement\\n', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 1}),\n",
       " Document(page_content=' Course Materials\\nAll the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\\nThey will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\\n Logistics\\nCourse Website: ENC2045 Computational Linguistics (https://alvinntnu.github.io/NTNU_ENC2045/)\\nInstructor’s Email Address: alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw)\\nInstructor’s Name: Alvin Chen\\nOf\\x00ce Hours: By appointment\\nIf you have any further questions related to the course, please consult FAQ (FAQ.html) on our course website or write me at any time\\nat alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw).\\n Disclaimer & Agreement\\nWhile I have made every attempt to ensure that the information contained on the Website is correct, I am not responsible for any\\nerrors or omissions, or for the results obtained from the use of this information. All information on the Website is provided “as is”, with\\nno guarantee of completeness, accuracy, timeliness or of the results obtained from the use of this information, and without warranty\\nof any kind, express or implied.\\nYou may print a copy of any part of this website for your personal or non-commercial use. Without the author’s prior written consent,\\nyou cannot disclose con\\x00dential information of the website (e.g., log-in username and password) to any third party.', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 2})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can load webpages as context documents\n",
    "# import bs4\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# loader = WebBaseLoader(\"https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/intro.html\")\n",
    "# pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ENC2045: Computational Linguistics\n",
      "This site is last-updated on 2024-02-23\n",
      " Annoucements\n",
      "Important course information will be posted on this web page and announced in class. You are responsible for all material that appears\n",
      "here and should check this page for updates frequently.\n",
      "2024-02-23: The curr\n",
      "2: Course Materials\n",
      "All the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\n",
      "They will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\n",
      " Logistics\n",
      "Course Website: E\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "\n",
    "documents = text_splitter.split_documents(pages)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "\n",
    "docs = vector.similarity_search(\"What is ENC2045?\", k=2)\n",
    "\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `create_stuff_documents_chain()`: This chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM. It passes ALL documents, so you should make sure it fits within the context window the LLM you are using.\n",
    "- `create_retrieval_chain()`: This chain takes in a user inquiry, which is then passed to the retriever to fetch relevant documents. Those documents (and original inputs) (done by the `create_stuff_documents_chain()`) are then passed to an LLM to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ENC2045: Computational Linguistics\\nThis site is last-updated on 2024-02-23\\n Annoucements\\nImportant course information will be posted on this web page and announced in class. You are responsible for all material that appears\\nhere and should check this page for updates frequently.\\n2024-02-23: The current version of the course website is based on the Spring Semester, 2021. It will be updated for the spring\\nof 2024.\\n2023-12-24: This course is designed for linguistics majors. If you are NOT a linguistics major, please contact the instructor for\\ncourse enrollment.\\n2023-12-24: This course has prerequisites. A test on python basics will be conducted at the beginning of the semester. Please\\nread the FAQ (FAQ.html) very carefully. This course is NOT OPEN to auditors.\\n Course Description\\nComputational Linguistics (CL) is now a very active sub-discipline in applied linguistics. Its main focus is on the computational text\\nanalytics, which is essentially about leveraging computational tools, techniques, and algorithms to process and understand natural\\nlanguage data (in spoken or textual formats). Therefore, this course aims to introduce useful strategies and common work\\x00ows that\\nhave been widely adopted by data scientists to extract useful insights from natural language data. In this course, we will focus on\\ntextual data processing.\\nA selective collection of potential topics may include:\\nA Pipeline for Natural Language Processing\\nText Normalization\\nText Tokenization\\nParsing and Chunking\\nIssues for Chinese Language Processing (Word Segmentation)\\nFeature Engineering and Text Vectorization\\nTraditional Machine Learning\\nClassi\\x00cation Models (Naive Bayes, SVM, Logistic Regression)\\nCommon Computational Tasks:\\nSentiment Analysis\\nTex Clustering and Topic Modeling\\nDeep Learning and Neural Network\\nNeural Language Model\\nSequence Models\\nRNN\\nLSTM/GRU\\nSequence-to-sequence Model\\nAttention-based Models\\nTransfer Learning\\nLarge Language Models(LLM) & Retrieval-Augmented Generation (RAG)\\nMultimodal Processing\\nThis course is extremely hands-on and will guide the students through classic examples of many task-oriented implementations via in-\\nclass theme-based tutorial sessions. The main coding language used in this course is Python  (https://www.python.org/). We will\\nmake extensive use of the language. It is assumed that you know or will quickly learn how to code in Python. In fact, this course\\nassumes that every enrolled student has working knowledge of Python. (If you are not sure if you ful\\x00ll the prerequisite, please\\ncontact the instructor \\x00rst.)', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 0}),\n",
       " Document(page_content='A test on Python Basics will be conducted on the \\x00rst week of the class to ensure that every enrolled student ful\\x00lls the prerequisite.\\n(To be more speci\\x00c, you are assumed to have already had working knowledge of all the concepts included in the book, Lean Python:\\nLearn Just Enough Python to Build Useful Tools (https://www.amazon.com/Lean-Python-Learn-Enough-Useful/dp/1484223845)).\\nThose who fail on the Python basics test are NOT advised to take this course.\\nPlease note that this course is designed speci\\x00cally for linguistics majors in humanities. For computer science majors, please note that\\nthis course will not feature a thorough description of the mathematical operations behind the algorithms. We focus more on the\\npractical implementation.\\n Course Schedule\\n(The schedule is tentative and subject to change. Please pay attention to the announcements made during the class.)\\nWeek Date Topic\\nWeek 1 2023-02-23 Course Orientation and Computational Linguistics Overview\\nWeek 2 2023-03-01 NLP Pipeline\\nWeek 3 2023-03-08 Machine Learning Basics: Regression and Classi\\x00cation\\nWeek 4 2023-03-15 Naïve Bayes, Logistic Regression\\nWeek 5 2023-03-22 Feature Engineering and Text Vectorization\\nWeek 6 2023-03-29 Common NLP Tasks (Guest Speaker: Robin Lin from Droidtown Linguistic Tech. Co.\\xa0Ltd.\\xa0)\\nWeek 7 2023-04-05 Holiday\\nWeek 8 2023-04-12 Midterm Exam\\nWeek 9 2023-04-19 Neural Network: A Primer\\nWeek 10 2023-04-26 Deep Learning NLP and Word/Doc Embeddings\\nWeek 11 2023-05-03 Sequence Model I: RNN and Neural Language Model\\nWeek 12 2023-05-10 Sequence Model II: LSTM and GRU\\nWeek 13 2023-05-17 Sequence Model III: Sequence-to-Sequence Model & Attention\\nWeek 14 2023-05-24 Transformer, BERT, Transfer Learning, and Explainable AI\\nWeek 15 2023-05-31 LLM, RAG, and Multimodal Processing\\nWeek 16 2023-06-07 Final Exam\\n Course Requirement', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 1}),\n",
       " Document(page_content='Course Materials\\nAll the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\\nThey will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\\n Logistics\\nCourse Website: ENC2045 Computational Linguistics (https://alvinntnu.github.io/NTNU_ENC2045/)\\nInstructor’s Email Address: alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw)\\nInstructor’s Name: Alvin Chen\\nOf\\x00ce Hours: By appointment\\nIf you have any further questions related to the course, please consult FAQ (FAQ.html) on our course website or write me at any time\\nat alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw).\\n Disclaimer & Agreement\\nWhile I have made every attempt to ensure that the information contained on the Website is correct, I am not responsible for any\\nerrors or omissions, or for the results obtained from the use of this information. All information on the Website is provided “as is”, with\\nno guarantee of completeness, accuracy, timeliness or of the results obtained from the use of this information, and without warranty\\nof any kind, express or implied.\\nYou may print a copy of any part of this website for your personal or non-commercial use. Without the author’s prior written consent,\\nyou cannot disclose con\\x00dential information of the website (e.g., log-in username and password) to any third party.', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENC2045 is a course on Computational Linguistics.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "## define prompt template\n",
    "prompt = PromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "\n",
    "## create chain\n",
    "document_chain = create_stuff_documents_chain(chat, prompt)\n",
    "\n",
    "## When invoking the caht, define `context`` documents\n",
    "\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"What is ENC2045?\",\n",
    "    \"context\": documents\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "## Specific setting for retriever\n",
    "# retriever = vector.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\", \n",
    "#     search_kwargs={\"score_threshold\": 0.3, \"k\":3})\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The instructor of the course ENC2045 is Alvin Chen.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"Who is the instructor of the course ENC2045?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat History Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In addition to retrieving external documents as context information, LLM also needs to consider the conversation history for more precise answers.\n",
    "- `create_history_aware_retriever()`: This chain takes in conversation history and then uses that to generate a search query which is passed to the underlying retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "\n",
    "history_chain = create_history_aware_retriever(chat, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A test on Python Basics will be conducted on the \\x00rst week of the class to ensure that every enrolled student ful\\x00lls the prerequisite.\\n(To be more speci\\x00c, you are assumed to have already had working knowledge of all the concepts included in the book, Lean Python:\\nLearn Just Enough Python to Build Useful Tools (https://www.amazon.com/Lean-Python-Learn-Enough-Useful/dp/1484223845)).\\nThose who fail on the Python basics test are NOT advised to take this course.\\nPlease note that this course is designed speci\\x00cally for linguistics majors in humanities. For computer science majors, please note that\\nthis course will not feature a thorough description of the mathematical operations behind the algorithms. We focus more on the\\npractical implementation.\\n Course Schedule\\n(The schedule is tentative and subject to change. Please pay attention to the announcements made during the class.)\\nWeek Date Topic\\nWeek 1 2023-02-23 Course Orientation and Computational Linguistics Overview\\nWeek 2 2023-03-01 NLP Pipeline\\nWeek 3 2023-03-08 Machine Learning Basics: Regression and Classi\\x00cation\\nWeek 4 2023-03-15 Naïve Bayes, Logistic Regression\\nWeek 5 2023-03-22 Feature Engineering and Text Vectorization\\nWeek 6 2023-03-29 Common NLP Tasks (Guest Speaker: Robin Lin from Droidtown Linguistic Tech. Co.\\xa0Ltd.\\xa0)\\nWeek 7 2023-04-05 Holiday\\nWeek 8 2023-04-12 Midterm Exam\\nWeek 9 2023-04-19 Neural Network: A Primer\\nWeek 10 2023-04-26 Deep Learning NLP and Word/Doc Embeddings\\nWeek 11 2023-05-03 Sequence Model I: RNN and Neural Language Model\\nWeek 12 2023-05-10 Sequence Model II: LSTM and GRU\\nWeek 13 2023-05-17 Sequence Model III: Sequence-to-Sequence Model & Attention\\nWeek 14 2023-05-24 Transformer, BERT, Transfer Learning, and Explainable AI\\nWeek 15 2023-05-31 LLM, RAG, and Multimodal Processing\\nWeek 16 2023-06-07 Final Exam\\n Course Requirement', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 1}),\n",
       " Document(page_content='ENC2045: Computational Linguistics\\nThis site is last-updated on 2024-02-23\\n Annoucements\\nImportant course information will be posted on this web page and announced in class. You are responsible for all material that appears\\nhere and should check this page for updates frequently.\\n2024-02-23: The current version of the course website is based on the Spring Semester, 2021. It will be updated for the spring\\nof 2024.\\n2023-12-24: This course is designed for linguistics majors. If you are NOT a linguistics major, please contact the instructor for\\ncourse enrollment.\\n2023-12-24: This course has prerequisites. A test on python basics will be conducted at the beginning of the semester. Please\\nread the FAQ (FAQ.html) very carefully. This course is NOT OPEN to auditors.\\n Course Description\\nComputational Linguistics (CL) is now a very active sub-discipline in applied linguistics. Its main focus is on the computational text\\nanalytics, which is essentially about leveraging computational tools, techniques, and algorithms to process and understand natural\\nlanguage data (in spoken or textual formats). Therefore, this course aims to introduce useful strategies and common work\\x00ows that\\nhave been widely adopted by data scientists to extract useful insights from natural language data. In this course, we will focus on\\ntextual data processing.\\nA selective collection of potential topics may include:\\nA Pipeline for Natural Language Processing\\nText Normalization\\nText Tokenization\\nParsing and Chunking\\nIssues for Chinese Language Processing (Word Segmentation)\\nFeature Engineering and Text Vectorization\\nTraditional Machine Learning\\nClassi\\x00cation Models (Naive Bayes, SVM, Logistic Regression)\\nCommon Computational Tasks:\\nSentiment Analysis\\nTex Clustering and Topic Modeling\\nDeep Learning and Neural Network\\nNeural Language Model\\nSequence Models\\nRNN\\nLSTM/GRU\\nSequence-to-sequence Model\\nAttention-based Models\\nTransfer Learning\\nLarge Language Models(LLM) & Retrieval-Augmented Generation (RAG)\\nMultimodal Processing\\nThis course is extremely hands-on and will guide the students through classic examples of many task-oriented implementations via in-\\nclass theme-based tutorial sessions. The main coding language used in this course is Python  (https://www.python.org/). We will\\nmake extensive use of the language. It is assumed that you know or will quickly learn how to code in Python. In fact, this course\\nassumes that every enrolled student has working knowledge of Python. (If you are not sure if you ful\\x00ll the prerequisite, please\\ncontact the instructor \\x00rst.)', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 0}),\n",
       " Document(page_content='Course Materials\\nAll the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\\nThey will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\\n Logistics\\nCourse Website: ENC2045 Computational Linguistics (https://alvinntnu.github.io/NTNU_ENC2045/)\\nInstructor’s Email Address: alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw)\\nInstructor’s Name: Alvin Chen\\nOf\\x00ce Hours: By appointment\\nIf you have any further questions related to the course, please consult FAQ (FAQ.html) on our course website or write me at any time\\nat alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw).\\n Disclaimer & Agreement\\nWhile I have made every attempt to ensure that the information contained on the Website is correct, I am not responsible for any\\nerrors or omissions, or for the results obtained from the use of this information. All information on the Website is provided “as is”, with\\nno guarantee of completeness, accuracy, timeliness or of the results obtained from the use of this information, and without warranty\\nof any kind, express or implied.\\nYou may print a copy of any part of this website for your personal or non-commercial use. Without the author’s prior written consent,\\nyou cannot disclose con\\x00dential information of the website (e.g., log-in username and password) to any third party.', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"How many assignments do students need to do?\"), \n",
    "                AIMessage(content=\"Four.\")]\n",
    "\n",
    "history_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What are the four assignments?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "## user query\n",
    "document_chain = create_stuff_documents_chain(chat, prompt)\n",
    "\n",
    "## combine user query, history chain\n",
    "retrieval_chain = create_retrieval_chain(history_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='How many assignments do students need to do?'),\n",
       "  AIMessage(content='Four.')],\n",
       " 'input': 'Are you saying four?',\n",
       " 'context': [Document(page_content='A test on Python Basics will be conducted on the \\x00rst week of the class to ensure that every enrolled student ful\\x00lls the prerequisite.\\n(To be more speci\\x00c, you are assumed to have already had working knowledge of all the concepts included in the book, Lean Python:\\nLearn Just Enough Python to Build Useful Tools (https://www.amazon.com/Lean-Python-Learn-Enough-Useful/dp/1484223845)).\\nThose who fail on the Python basics test are NOT advised to take this course.\\nPlease note that this course is designed speci\\x00cally for linguistics majors in humanities. For computer science majors, please note that\\nthis course will not feature a thorough description of the mathematical operations behind the algorithms. We focus more on the\\npractical implementation.\\n Course Schedule\\n(The schedule is tentative and subject to change. Please pay attention to the announcements made during the class.)\\nWeek Date Topic\\nWeek 1 2023-02-23 Course Orientation and Computational Linguistics Overview\\nWeek 2 2023-03-01 NLP Pipeline\\nWeek 3 2023-03-08 Machine Learning Basics: Regression and Classi\\x00cation\\nWeek 4 2023-03-15 Naïve Bayes, Logistic Regression\\nWeek 5 2023-03-22 Feature Engineering and Text Vectorization\\nWeek 6 2023-03-29 Common NLP Tasks (Guest Speaker: Robin Lin from Droidtown Linguistic Tech. Co.\\xa0Ltd.\\xa0)\\nWeek 7 2023-04-05 Holiday\\nWeek 8 2023-04-12 Midterm Exam\\nWeek 9 2023-04-19 Neural Network: A Primer\\nWeek 10 2023-04-26 Deep Learning NLP and Word/Doc Embeddings\\nWeek 11 2023-05-03 Sequence Model I: RNN and Neural Language Model\\nWeek 12 2023-05-10 Sequence Model II: LSTM and GRU\\nWeek 13 2023-05-17 Sequence Model III: Sequence-to-Sequence Model & Attention\\nWeek 14 2023-05-24 Transformer, BERT, Transfer Learning, and Explainable AI\\nWeek 15 2023-05-31 LLM, RAG, and Multimodal Processing\\nWeek 16 2023-06-07 Final Exam\\n Course Requirement', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 1}),\n",
       "  Document(page_content='ENC2045: Computational Linguistics\\nThis site is last-updated on 2024-02-23\\n Annoucements\\nImportant course information will be posted on this web page and announced in class. You are responsible for all material that appears\\nhere and should check this page for updates frequently.\\n2024-02-23: The current version of the course website is based on the Spring Semester, 2021. It will be updated for the spring\\nof 2024.\\n2023-12-24: This course is designed for linguistics majors. If you are NOT a linguistics major, please contact the instructor for\\ncourse enrollment.\\n2023-12-24: This course has prerequisites. A test on python basics will be conducted at the beginning of the semester. Please\\nread the FAQ (FAQ.html) very carefully. This course is NOT OPEN to auditors.\\n Course Description\\nComputational Linguistics (CL) is now a very active sub-discipline in applied linguistics. Its main focus is on the computational text\\nanalytics, which is essentially about leveraging computational tools, techniques, and algorithms to process and understand natural\\nlanguage data (in spoken or textual formats). Therefore, this course aims to introduce useful strategies and common work\\x00ows that\\nhave been widely adopted by data scientists to extract useful insights from natural language data. In this course, we will focus on\\ntextual data processing.\\nA selective collection of potential topics may include:\\nA Pipeline for Natural Language Processing\\nText Normalization\\nText Tokenization\\nParsing and Chunking\\nIssues for Chinese Language Processing (Word Segmentation)\\nFeature Engineering and Text Vectorization\\nTraditional Machine Learning\\nClassi\\x00cation Models (Naive Bayes, SVM, Logistic Regression)\\nCommon Computational Tasks:\\nSentiment Analysis\\nTex Clustering and Topic Modeling\\nDeep Learning and Neural Network\\nNeural Language Model\\nSequence Models\\nRNN\\nLSTM/GRU\\nSequence-to-sequence Model\\nAttention-based Models\\nTransfer Learning\\nLarge Language Models(LLM) & Retrieval-Augmented Generation (RAG)\\nMultimodal Processing\\nThis course is extremely hands-on and will guide the students through classic examples of many task-oriented implementations via in-\\nclass theme-based tutorial sessions. The main coding language used in this course is Python  (https://www.python.org/). We will\\nmake extensive use of the language. It is assumed that you know or will quickly learn how to code in Python. In fact, this course\\nassumes that every enrolled student has working knowledge of Python. (If you are not sure if you ful\\x00ll the prerequisite, please\\ncontact the instructor \\x00rst.)', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 0}),\n",
       "  Document(page_content='Course Materials\\nAll the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\\nThey will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\\n Logistics\\nCourse Website: ENC2045 Computational Linguistics (https://alvinntnu.github.io/NTNU_ENC2045/)\\nInstructor’s Email Address: alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw)\\nInstructor’s Name: Alvin Chen\\nOf\\x00ce Hours: By appointment\\nIf you have any further questions related to the course, please consult FAQ (FAQ.html) on our course website or write me at any time\\nat alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw).\\n Disclaimer & Agreement\\nWhile I have made every attempt to ensure that the information contained on the Website is correct, I am not responsible for any\\nerrors or omissions, or for the results obtained from the use of this information. All information on the Website is provided “as is”, with\\nno guarantee of completeness, accuracy, timeliness or of the results obtained from the use of this information, and without warranty\\nof any kind, express or implied.\\nYou may print a copy of any part of this website for your personal or non-commercial use. Without the author’s prior written consent,\\nyou cannot disclose con\\x00dential information of the website (e.g., log-in username and password) to any third party.', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 2})],\n",
       " 'answer': 'The text does not provide information on the number of assignments students need to do in the course.'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Are you saying four?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [HumanMessage(content=\"How many assignments do students need to do?\"), \n",
    "                AIMessage(content=\"Four.\"),\n",
    "                HumanMessage(content='I am telling you that these four assignments include coding, reviewing, testing, and presentation.'),\n",
    "                AIMessage(content='Thank you for the information.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='How many assignments do students need to do?'),\n",
       "  AIMessage(content='Four.'),\n",
       "  HumanMessage(content='I am telling you that these four assignments include coding, reviewing, testing, and presentation.'),\n",
       "  AIMessage(content='Thank you for the information.')],\n",
       " 'input': 'Can you repeat the four assignments?',\n",
       " 'context': [Document(page_content='A test on Python Basics will be conducted on the \\x00rst week of the class to ensure that every enrolled student ful\\x00lls the prerequisite.\\n(To be more speci\\x00c, you are assumed to have already had working knowledge of all the concepts included in the book, Lean Python:\\nLearn Just Enough Python to Build Useful Tools (https://www.amazon.com/Lean-Python-Learn-Enough-Useful/dp/1484223845)).\\nThose who fail on the Python basics test are NOT advised to take this course.\\nPlease note that this course is designed speci\\x00cally for linguistics majors in humanities. For computer science majors, please note that\\nthis course will not feature a thorough description of the mathematical operations behind the algorithms. We focus more on the\\npractical implementation.\\n Course Schedule\\n(The schedule is tentative and subject to change. Please pay attention to the announcements made during the class.)\\nWeek Date Topic\\nWeek 1 2023-02-23 Course Orientation and Computational Linguistics Overview\\nWeek 2 2023-03-01 NLP Pipeline\\nWeek 3 2023-03-08 Machine Learning Basics: Regression and Classi\\x00cation\\nWeek 4 2023-03-15 Naïve Bayes, Logistic Regression\\nWeek 5 2023-03-22 Feature Engineering and Text Vectorization\\nWeek 6 2023-03-29 Common NLP Tasks (Guest Speaker: Robin Lin from Droidtown Linguistic Tech. Co.\\xa0Ltd.\\xa0)\\nWeek 7 2023-04-05 Holiday\\nWeek 8 2023-04-12 Midterm Exam\\nWeek 9 2023-04-19 Neural Network: A Primer\\nWeek 10 2023-04-26 Deep Learning NLP and Word/Doc Embeddings\\nWeek 11 2023-05-03 Sequence Model I: RNN and Neural Language Model\\nWeek 12 2023-05-10 Sequence Model II: LSTM and GRU\\nWeek 13 2023-05-17 Sequence Model III: Sequence-to-Sequence Model & Attention\\nWeek 14 2023-05-24 Transformer, BERT, Transfer Learning, and Explainable AI\\nWeek 15 2023-05-31 LLM, RAG, and Multimodal Processing\\nWeek 16 2023-06-07 Final Exam\\n Course Requirement', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 1}),\n",
       "  Document(page_content='ENC2045: Computational Linguistics\\nThis site is last-updated on 2024-02-23\\n Annoucements\\nImportant course information will be posted on this web page and announced in class. You are responsible for all material that appears\\nhere and should check this page for updates frequently.\\n2024-02-23: The current version of the course website is based on the Spring Semester, 2021. It will be updated for the spring\\nof 2024.\\n2023-12-24: This course is designed for linguistics majors. If you are NOT a linguistics major, please contact the instructor for\\ncourse enrollment.\\n2023-12-24: This course has prerequisites. A test on python basics will be conducted at the beginning of the semester. Please\\nread the FAQ (FAQ.html) very carefully. This course is NOT OPEN to auditors.\\n Course Description\\nComputational Linguistics (CL) is now a very active sub-discipline in applied linguistics. Its main focus is on the computational text\\nanalytics, which is essentially about leveraging computational tools, techniques, and algorithms to process and understand natural\\nlanguage data (in spoken or textual formats). Therefore, this course aims to introduce useful strategies and common work\\x00ows that\\nhave been widely adopted by data scientists to extract useful insights from natural language data. In this course, we will focus on\\ntextual data processing.\\nA selective collection of potential topics may include:\\nA Pipeline for Natural Language Processing\\nText Normalization\\nText Tokenization\\nParsing and Chunking\\nIssues for Chinese Language Processing (Word Segmentation)\\nFeature Engineering and Text Vectorization\\nTraditional Machine Learning\\nClassi\\x00cation Models (Naive Bayes, SVM, Logistic Regression)\\nCommon Computational Tasks:\\nSentiment Analysis\\nTex Clustering and Topic Modeling\\nDeep Learning and Neural Network\\nNeural Language Model\\nSequence Models\\nRNN\\nLSTM/GRU\\nSequence-to-sequence Model\\nAttention-based Models\\nTransfer Learning\\nLarge Language Models(LLM) & Retrieval-Augmented Generation (RAG)\\nMultimodal Processing\\nThis course is extremely hands-on and will guide the students through classic examples of many task-oriented implementations via in-\\nclass theme-based tutorial sessions. The main coding language used in this course is Python  (https://www.python.org/). We will\\nmake extensive use of the language. It is assumed that you know or will quickly learn how to code in Python. In fact, this course\\nassumes that every enrolled student has working knowledge of Python. (If you are not sure if you ful\\x00ll the prerequisite, please\\ncontact the instructor \\x00rst.)', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 0}),\n",
       "  Document(page_content='Course Materials\\nAll the course materials are available on the course website. Please consult the instructor for the direct link to the course materials.\\nThey will be provided as a series of online packets (i.e., handouts, script source codes etc.) on the course website.\\n Logistics\\nCourse Website: ENC2045 Computational Linguistics (https://alvinntnu.github.io/NTNU_ENC2045/)\\nInstructor’s Email Address: alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw)\\nInstructor’s Name: Alvin Chen\\nOf\\x00ce Hours: By appointment\\nIf you have any further questions related to the course, please consult FAQ (FAQ.html) on our course website or write me at any time\\nat alvinchen@ntnu.edu.tw (mailto:alvinchen@ntnu.edu.tw).\\n Disclaimer & Agreement\\nWhile I have made every attempt to ensure that the information contained on the Website is correct, I am not responsible for any\\nerrors or omissions, or for the results obtained from the use of this information. All information on the Website is provided “as is”, with\\nno guarantee of completeness, accuracy, timeliness or of the results obtained from the use of this information, and without warranty\\nof any kind, express or implied.\\nYou may print a copy of any part of this website for your personal or non-commercial use. Without the author’s prior written consent,\\nyou cannot disclose con\\x00dential information of the website (e.g., log-in username and password) to any third party.', metadata={'source': '../../../../ENC2045_demo_data/ENC2045Syllabus.pdf', 'page': 2})],\n",
       " 'answer': 'The four assignments include coding, reviewing, testing, and presentation.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Can you repeat the four assignments?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right now, the module `Memory` i still under active development.\n",
    "- To work with Memory, we will use the legacy chain, `langchain.chains.LLMChain()`, which is still under development of its compatibility with the [LCEL](https://python.langchain.com/docs/expression_language) framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "# Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice college professor having a conversation with a student.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New student's question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# Notice that we need to align the `memory_key`\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", k = 1)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True, ## see the original prompts\n",
    "    memory=memory\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice college professor having a conversation with a student.\n",
      "\n",
      "Previous conversation:\n",
      "\n",
      "\n",
      "New student's question: what is your name?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is your name?',\n",
       " 'chat_history': '',\n",
       " 'text': \"My name is Professor Johnson. It's nice to meet you.\"}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.chat_memory.add_user_message(\"I think your name is Alvin Chen, right?\")\n",
    "memory.chat_memory.add_ai_message(\"Yes. My name is Alvin Chen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice college professor having a conversation with a student.\n",
      "\n",
      "Previous conversation:\n",
      "Human: what is your name?\n",
      "AI: My name is Professor Johnson. It's nice to meet you.\n",
      "Human: I think your name is Alvin Chen, right?\n",
      "AI: Yes. My name is Alvin Chen.\n",
      "\n",
      "New student's question: So what is your name really?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'So what is your name really?',\n",
       " 'chat_history': \"Human: what is your name?\\nAI: My name is Professor Johnson. It's nice to meet you.\\nHuman: I think your name is Alvin Chen, right?\\nAI: Yes. My name is Alvin Chen.\",\n",
       " 'text': 'My name is Alvin Chen. I apologize for any confusion earlier.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"So what is your name really?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: what is your name?\\nAI: My name is Professor Johnson. It's nice to meet you.\\nHuman: I think your name is Alvin Chen, right?\\nAI: Yes. My name is Alvin Chen.\\nHuman: So what is your name really?\\nAI: My name is Alvin Chen. I apologize for any confusion earlier.\"}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## somehow the k window size is not working?\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Langchain Crash Course for Beginners](https://youtu.be/lG7Uxts9SXs?si=07gr6zeB9tDkHjGm)\n",
    "- [Langchain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [Langchain Quickstart](https://python.langchain.com/docs/get_started/quickstart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
