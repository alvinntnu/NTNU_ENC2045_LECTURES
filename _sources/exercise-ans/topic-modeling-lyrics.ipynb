{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment X: Topic Modeling Dcard Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary dependencies and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#, category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk, random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample corpus of text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jay Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('jay_seg.pickle', 'rb') as f:\n",
    "    jay_seg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df =pd.read_csv('../../../RepositoryData/data/data-chinese-songs-jaychou.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我是如此相信</td>\n",
       "      <td>鳥群離開了森林 整座天空很灰心\\n蝴蝶不再被吸引 玫瑰盛開的很安靜\\n遠方的風雨不停 城市蒼白而孤寂\\n徘徊無助的人群 焦慮著何時放晴\\n故事裡能毀壞的只有風景\\n誰也摧毀不了我們的夢境\\n弦月旁的流星劃過了天際\\n我許下的願望該向誰去說明\\n隕石在浩瀚的宇宙間旅行\\n璀璨的夜空裡漫天的水晶\\n我的禱告終於有了回音\\n我是如此相信 在背後支撐的是你\\n一直與我並肩而行 仰望等太陽升起\\n聽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>英雄</td>\n",
       "      <td>人生不是ㄧ個人的遊戲\\nㄧ起奮鬥ㄧ起超越ㄧ起殺吧sup兄弟\\n好戰好勝戰勝逆命\\n管他天賦夠不夠我們都還需要再努力\\n你的劍就是我的劍\\n艾希的箭可不可以準ㄧ點  嘿\\n你打野我來控兵線\\n不要隨便慌張就交閃現\\n旋轉跳躍你閉著眼\\n卡特轉完會讓你閉上眼\\n悟空蓋倫也轉圈圈\\n盲僧李先生ㄧ腳把你  踢回老家\\n擊殺  雙殺  三殺  Penta kill\\n扛塔  偷拆  插眼讓我傳送\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>雙截棍</td>\n",
       "      <td>岩燒店的煙味瀰漫  隔壁是國術館\\n店裡面的媽媽桑  茶道  有三段\\n教拳腳武術的老板  練鐵沙掌  耍楊家槍\\n硬底子功夫最擅長  還會金鐘罩鐵布衫\\n他們兒子我習慣  從小就耳濡目染\\n什麼刀槍跟棍棒  我都耍的有模有樣\\n什麼兵器最喜歡  雙截棍柔中帶剛\\n想要去河南嵩山  學少林跟武當\\n幹什麼(客)  幹什麼(客)  呼吸吐納心自在\\n幹什麼(客)  幹什麼(客)  氣沉丹田手...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>開不了口</td>\n",
       "      <td>才離開沒多久就開始  擔心今天的妳過得好不好\\n整個畫面是妳  想妳想的睡不著\\n嘴嘟嘟那可愛的模樣  還有在妳身上香香的味道\\n我的快樂是妳  想妳想的都會笑\\n沒有妳在我有多難熬(沒有妳在我有多難熬多煩惱)\\n沒有妳煩我有多煩惱(沒有妳煩我有多煩惱多難熬)\\n穿過雲層  我試著努力向妳奔跑\\n愛才送到  妳卻已在別人懷抱\\n就是開不了口  讓她知道\\n我一定會呵護著妳  也逗妳笑\\n妳...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>床邊故事</td>\n",
       "      <td>從前從前有隻貓頭鷹  牠站在屋頂\\n屋頂後面一遍森林  森林很安靜\\n安靜的鋼琴在大廳  閣樓裡  仔細聽\\n仔細聽  叮叮叮  什麼聲音\\n乖乖睡  不要怕  聽我說\\n乖乖睡  醒來就  吃蘋果\\n不睡覺  的時候  有傳說\\n會有人  咬你的  小指頭\\n這故事  繼續翻頁  再翻頁\\n你繼續  不想睡  我卻想睡\\n然後我準備  去打開衣櫃\\n去看看  躲著誰  去看看  躲著誰\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title  \\\n",
       "0  我是如此相信   \n",
       "1      英雄   \n",
       "2     雙截棍   \n",
       "3    開不了口   \n",
       "4    床邊故事   \n",
       "\n",
       "                                                                                                                                                                                                     lyric  \n",
       "0  鳥群離開了森林 整座天空很灰心\\n蝴蝶不再被吸引 玫瑰盛開的很安靜\\n遠方的風雨不停 城市蒼白而孤寂\\n徘徊無助的人群 焦慮著何時放晴\\n故事裡能毀壞的只有風景\\n誰也摧毀不了我們的夢境\\n弦月旁的流星劃過了天際\\n我許下的願望該向誰去說明\\n隕石在浩瀚的宇宙間旅行\\n璀璨的夜空裡漫天的水晶\\n我的禱告終於有了回音\\n我是如此相信 在背後支撐的是你\\n一直與我並肩而行 仰望等太陽升起\\n聽...  \n",
       "1  人生不是ㄧ個人的遊戲\\nㄧ起奮鬥ㄧ起超越ㄧ起殺吧sup兄弟\\n好戰好勝戰勝逆命\\n管他天賦夠不夠我們都還需要再努力\\n你的劍就是我的劍\\n艾希的箭可不可以準ㄧ點  嘿\\n你打野我來控兵線\\n不要隨便慌張就交閃現\\n旋轉跳躍你閉著眼\\n卡特轉完會讓你閉上眼\\n悟空蓋倫也轉圈圈\\n盲僧李先生ㄧ腳把你  踢回老家\\n擊殺  雙殺  三殺  Penta kill\\n扛塔  偷拆  插眼讓我傳送\\n...  \n",
       "2  岩燒店的煙味瀰漫  隔壁是國術館\\n店裡面的媽媽桑  茶道  有三段\\n教拳腳武術的老板  練鐵沙掌  耍楊家槍\\n硬底子功夫最擅長  還會金鐘罩鐵布衫\\n他們兒子我習慣  從小就耳濡目染\\n什麼刀槍跟棍棒  我都耍的有模有樣\\n什麼兵器最喜歡  雙截棍柔中帶剛\\n想要去河南嵩山  學少林跟武當\\n幹什麼(客)  幹什麼(客)  呼吸吐納心自在\\n幹什麼(客)  幹什麼(客)  氣沉丹田手...  \n",
       "3  才離開沒多久就開始  擔心今天的妳過得好不好\\n整個畫面是妳  想妳想的睡不著\\n嘴嘟嘟那可愛的模樣  還有在妳身上香香的味道\\n我的快樂是妳  想妳想的都會笑\\n沒有妳在我有多難熬(沒有妳在我有多難熬多煩惱)\\n沒有妳煩我有多煩惱(沒有妳煩我有多煩惱多難熬)\\n穿過雲層  我試著努力向妳奔跑\\n愛才送到  妳卻已在別人懷抱\\n就是開不了口  讓她知道\\n我一定會呵護著妳  也逗妳笑\\n妳...  \n",
       "4  從前從前有隻貓頭鷹  牠站在屋頂\\n屋頂後面一遍森林  森林很安靜\\n安靜的鋼琴在大廳  閣樓裡  仔細聽\\n仔細聽  叮叮叮  什麼聲音\\n乖乖睡  不要怕  聽我說\\n乖乖睡  醒來就  吃蘋果\\n不睡覺  的時候  有傳說\\n會有人  咬你的  小指頭\\n這故事  繼續翻頁  再翻頁\\n你繼續  不想睡  我卻想睡\\n然後我準備  去打開衣櫃\\n去看看  躲著誰  去看看  躲著誰\\...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus = [' '.join([w for w,p in d if p in ['Na','VC']]) for d in jay_seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'鳥群 離開 森林 灰心 蝴蝶 玫瑰 風雨 人群 故事 毀壞 風景 摧毀不了 夢境 弦月 流星 劃過 許下 願望 隕石 宇宙 水晶 回音 支撐 仰望 太陽 鳥群 聲音 守候 人 信心 雙手 彈奏 出 鳥群 離開 森林 蝴蝶 玫瑰 風雨 人群 故事 毀壞 風景 摧毀不了 夢境 弦月 流星 許下 願望 隕石 宇宙 水晶 回音 支撐 仰望 等 太陽 鳥群 聲音 守候 人 信心 雙手 彈奏 出 支撐 仰望 等 太陽 鳥群 聲音 守候 人 信心 雙手 彈奏出'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bag-of-words model is the simplest way to vectorize texts into numeric representations.\n",
    "- In short, it is a method to represent a text using its word frequency list.\n",
    "- The sequential order of words in the text is therefore naively ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<212x1353 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6039 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# get bag of words features in sparse format\n",
    "cv = CountVectorizer(min_df=2, max_df=1.0,token_pattern=r'[^\\s0-9]+')\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dense representation \n",
    "# warning might give a memory error if data is too big\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>一</th>\n",
       "      <th>一生</th>\n",
       "      <th>一統</th>\n",
       "      <th>上</th>\n",
       "      <th>上帝</th>\n",
       "      <th>下</th>\n",
       "      <th>世事</th>\n",
       "      <th>世人</th>\n",
       "      <th>...</th>\n",
       "      <th>默</th>\n",
       "      <th>默劇</th>\n",
       "      <th>默契</th>\n",
       "      <th>默片</th>\n",
       "      <th>點</th>\n",
       "      <th>點亮</th>\n",
       "      <th>點心</th>\n",
       "      <th>鼻子</th>\n",
       "      <th>龍</th>\n",
       "      <th>龍捲風</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 1353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ..  ...  一  一生  一統  上  上帝  下  世事  世人  ...  默  默劇  默契  默片  點  點亮  點心  鼻子  \\\n",
       "0     0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "1     0    0  0   0   0  0   0  0   0   0  ...  0   0   0   1  0   0   0   0   \n",
       "2     0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "3     0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "4     0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "..   ..  ... ..  ..  .. ..  .. ..  ..  ..  ... ..  ..  ..  .. ..  ..  ..  ..   \n",
       "207   0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "208   0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "209   0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "210   0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "211   0    0  0   0   0  0   0  0   0   0  ...  0   0   0   0  0   0   0   0   \n",
       "\n",
       "     龍  龍捲風  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "..  ..  ...  \n",
       "207  0    0  \n",
       "208  0    0  \n",
       "209  0    0  \n",
       "210  0    0  \n",
       "211  0    0  \n",
       "\n",
       "[212 rows x 1353 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = np.array(cv.get_feature_names())\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find optimal topic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 126.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 149.6min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Options to try with our LDA\n",
    "# Beware it will try *all* of the combinations, so it'll take ages\n",
    "search_params = {\n",
    "  'n_components': [4,5,6,7,8],\n",
    "  'learning_decay': [.5, .7]\n",
    "}\n",
    "\n",
    "# Set up LDA with the options we'll keep static\n",
    "model = LatentDirichletAllocation(learning_method='batch', max_iter = 10000, random_state=0)\n",
    "\n",
    "# Try all of the options\n",
    "gridsearch = GridSearchCV(model, param_grid=search_params, n_jobs=-1, verbose=1)\n",
    "gridsearch.fit(cv_matrix)\n",
    "\n",
    "## Save the best model\n",
    "best_lda = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(gridsearch.cv_results_)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pointplot(x=\"param_n_components\", y=\"mean_test_score\", hue=\"param_learning_decay\", data=cv_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topic = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=num_of_topic, max_iter=10000, random_state=0,\n",
    "                               max_doc_update_iter=50, learning_method='online',\n",
    "                               batch_size=50, learning_offset = 50, n_jobs = -1)\n",
    "dt_matrix = lda.fit_transform(cv_matrix) # document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(dt_matrix, columns = [\"T\"+str(n) for n in range(1,num_of_topic+1)])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show topics and their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt_matrix = lda.components_ # topic matrix\n",
    "# for topic_weights in tt_matrix:\n",
    "#     topic = [(token, weight) for token, weight in zip(vocab, topic_weights)]\n",
    "#     topic = sorted(topic, key=lambda x: -x[1])\n",
    "#     topic = [item for item in topic if item[1] > 0.6]\n",
    "#     print(topic)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = lda.components_\n",
    "top_terms = 20\n",
    "topic_keywords_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:,:top_terms]\n",
    "topic_keywords = vocab[topic_keywords_idxs]\n",
    "topics = [', '.join(w) for w in topic_keywords]\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "topics_df = pd.DataFrame(topics,\n",
    "                        columns = ['Keywords per Topic'],\n",
    "                        index = [\"Topic\"+str(n) for n in range(1,num_of_topic+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n",
    "dt_df = pd.DataFrame(dt_matrix,\n",
    "                    columns=[\"Topic\"+str(n) for n in range(1,num_of_topic+1)])\n",
    "\n",
    "max_contrib_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_contrib_topics.index\n",
    "contrib_perc = max_contrib_topics.values\n",
    "document_numbers = [dt_df[dt_df[t]==max_contrib_topics.loc[t]].index[0]\n",
    "                    for t in dominant_topics]\n",
    "documents = [norm_corpus[i] for i in document_numbers]\n",
    "\n",
    "documents_df = pd.DataFrame({'Dominant Topic': dominant_topics,\n",
    "                            'Contribution%': contrib_perc,\n",
    "                            'DOCID': document_numbers,\n",
    "                            'Topic': topics_df['Keywords per Topic'],\n",
    "                            'Text': documents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import dill\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "cv_matrix2 = np.matrix(cv_matrix)\n",
    "pyLDAvis.sklearn.prepare(lda, cv_matrix2, cv, mds=\"mmds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering documents using topic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=num_of_topic, random_state=0)\n",
    "km.fit_transform(features)\n",
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = corpus_df.index\n",
    "y_axis = features\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "# Plot a stackplot - https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/stackplot_demo.html\n",
    "ax.stackplot(x_axis, y_axis.T, baseline='wiggle', labels=y_axis.columns)\n",
    "\n",
    "# Move the legend off of the chart\n",
    "ax.legend(loc=(1.04,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "# lda_model - LatentDirichletAllocation()\n",
    "# vect - CountVectorizer()\n",
    "# texts - the list of tokenized words\n",
    "norm_corpus\n",
    "norm_corpus_tokens = [doc.split() for doc in norm_corpus]\n",
    "\n",
    "\n",
    "metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=10, \n",
    "                        topic_word_distrib= lda.components_, \n",
    "                        dtm=cv.fit_transform(norm_corpus), \n",
    "                        vocab=np.array(cv.get_feature_names()), \n",
    "                        texts=norm_corpus_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
