{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "- Trigram-based Neural LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text\n",
    "\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "    sequence = encoded[i - 2:i + 1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length - 1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Line-based LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 23\n",
      "Total Sequences: 21\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text\n",
    "\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "            To fetch a pail of water\\n\n",
    "            Jack fell down and broke his crown\\n\n",
    "            And Jill came tumbling after\\n \"\"\"\n",
    "# prepare the tokenizer on the source text\n",
    "tokenizer = Tokenizer(oov_token=1)  ## specify the word id for unknown words\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# determine the vocabulary size\n",
    "## zero index is reserved in keras as the padding token (+1) and one unknown word id\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# create line-based sequences\n",
    "sequences = list()\n",
    "for line in data.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    ## For each line, after converting words into indexes\n",
    "    ## prepare sequences for training\n",
    "    ## given a line, w1,w2,w3,w4\n",
    "    ## create input sequences:\n",
    "    ## w1,w2\n",
    "    ## w1,w2,w3\n",
    "    ## w1,w2,w3,w4\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i + 1]\n",
    "        sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 7\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 6, 10)             230       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 23)                1173      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "1/1 - 0s - loss: 3.1351 - accuracy: 0.0952\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 3.1335 - accuracy: 0.1905\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 3.1319 - accuracy: 0.1905\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 3.1302 - accuracy: 0.1429\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 3.1286 - accuracy: 0.1429\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 3.1269 - accuracy: 0.0952\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 3.1251 - accuracy: 0.0952\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 3.1233 - accuracy: 0.0952\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 3.1214 - accuracy: 0.0952\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 3.1195 - accuracy: 0.0952\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 3.1174 - accuracy: 0.0952\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 3.1153 - accuracy: 0.0952\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 3.1130 - accuracy: 0.0952\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 3.1106 - accuracy: 0.0952\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 3.1081 - accuracy: 0.0952\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 3.1054 - accuracy: 0.0952\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 3.1026 - accuracy: 0.0952\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 3.0995 - accuracy: 0.0952\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 3.0963 - accuracy: 0.0952\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 3.0928 - accuracy: 0.0952\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 3.0890 - accuracy: 0.0952\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 3.0850 - accuracy: 0.0952\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 3.0806 - accuracy: 0.0952\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 3.0760 - accuracy: 0.0952\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 3.0709 - accuracy: 0.0952\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 3.0654 - accuracy: 0.0952\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 3.0595 - accuracy: 0.0952\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 3.0531 - accuracy: 0.0952\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 3.0462 - accuracy: 0.0952\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 3.0387 - accuracy: 0.0952\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 3.0306 - accuracy: 0.0952\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 3.0218 - accuracy: 0.0952\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 3.0124 - accuracy: 0.0952\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 3.0023 - accuracy: 0.0952\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 2.9915 - accuracy: 0.0952\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 2.9800 - accuracy: 0.0952\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 2.9679 - accuracy: 0.0952\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 2.9554 - accuracy: 0.0952\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 2.9426 - accuracy: 0.0952\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 2.9297 - accuracy: 0.0952\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 2.9171 - accuracy: 0.0952\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 2.9051 - accuracy: 0.0952\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 2.8939 - accuracy: 0.0952\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 2.8837 - accuracy: 0.0952\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 2.8743 - accuracy: 0.0952\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 2.8652 - accuracy: 0.0952\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 2.8559 - accuracy: 0.0952\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 2.8460 - accuracy: 0.0952\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 2.8352 - accuracy: 0.0952\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 2.8236 - accuracy: 0.0952\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 2.8114 - accuracy: 0.0952\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 2.7989 - accuracy: 0.0952\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 2.7863 - accuracy: 0.1429\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 2.7737 - accuracy: 0.1429\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 2.7610 - accuracy: 0.1429\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 2.7482 - accuracy: 0.1429\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 2.7350 - accuracy: 0.1905\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 2.7213 - accuracy: 0.1905\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 2.7067 - accuracy: 0.1905\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 2.6914 - accuracy: 0.1905\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 2.6754 - accuracy: 0.1905\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 2.6587 - accuracy: 0.1905\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 2.6416 - accuracy: 0.1905\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 2.6241 - accuracy: 0.1905\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 2.6062 - accuracy: 0.2381\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 2.5878 - accuracy: 0.2381\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 2.5688 - accuracy: 0.2381\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 2.5490 - accuracy: 0.2857\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 2.5282 - accuracy: 0.2857\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 2.5065 - accuracy: 0.2857\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 2.4840 - accuracy: 0.2857\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 2.4610 - accuracy: 0.2857\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 2.4374 - accuracy: 0.2857\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 2.4132 - accuracy: 0.2857\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 2.3883 - accuracy: 0.3810\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 2.3626 - accuracy: 0.4286\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 2.3362 - accuracy: 0.4286\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 2.3093 - accuracy: 0.4286\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 2.2821 - accuracy: 0.4286\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 2.2544 - accuracy: 0.4762\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 2.2263 - accuracy: 0.4762\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 2.1977 - accuracy: 0.4762\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 2.1689 - accuracy: 0.4762\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 2.1399 - accuracy: 0.4762\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 2.1108 - accuracy: 0.4286\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 2.0815 - accuracy: 0.4286\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 2.0521 - accuracy: 0.4762\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 2.0230 - accuracy: 0.4762\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 1.9939 - accuracy: 0.4762\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 1.9650 - accuracy: 0.4286\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 1.9365 - accuracy: 0.4286\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 1.9084 - accuracy: 0.4762\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 1.8806 - accuracy: 0.4762\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 1.8533 - accuracy: 0.4762\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 1.8267 - accuracy: 0.4762\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 1.8010 - accuracy: 0.4762\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 1.7764 - accuracy: 0.4762\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 1.7527 - accuracy: 0.5238\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 1.7298 - accuracy: 0.5714\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 1.7078 - accuracy: 0.6190\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 1.6864 - accuracy: 0.5714\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 1.6656 - accuracy: 0.5238\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 1.6453 - accuracy: 0.5238\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 1.6257 - accuracy: 0.5238\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 1.6064 - accuracy: 0.5238\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 1.5876 - accuracy: 0.5714\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 1.5692 - accuracy: 0.5714\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 1.5514 - accuracy: 0.6190\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 1.5341 - accuracy: 0.6190\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 1.5174 - accuracy: 0.6190\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 1.5012 - accuracy: 0.6190\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 1.4856 - accuracy: 0.6190\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 1.4705 - accuracy: 0.6190\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 1.4558 - accuracy: 0.6190\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 1.4416 - accuracy: 0.5714\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 1.4279 - accuracy: 0.6190\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 1.4145 - accuracy: 0.6190\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 1.4016 - accuracy: 0.6190\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 1.3889 - accuracy: 0.5714\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 1.3766 - accuracy: 0.5714\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 1.3646 - accuracy: 0.5714\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 1.3527 - accuracy: 0.5714\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 1.3412 - accuracy: 0.5714\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 1.3298 - accuracy: 0.6190\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 1.3187 - accuracy: 0.6667\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 1.3077 - accuracy: 0.6667\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 1.2968 - accuracy: 0.6190\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 1.2861 - accuracy: 0.6190\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 1.2755 - accuracy: 0.6190\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 1.2651 - accuracy: 0.6190\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 1.2549 - accuracy: 0.6190\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 1.2448 - accuracy: 0.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 1.2349 - accuracy: 0.6190\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 1.2253 - accuracy: 0.6190\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 1.2160 - accuracy: 0.6190\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 1.2066 - accuracy: 0.6667\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 1.1966 - accuracy: 0.6190\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 1.1866 - accuracy: 0.6667\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 1.1777 - accuracy: 0.6667\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 1.1688 - accuracy: 0.6190\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 1.1591 - accuracy: 0.6667\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 1.1499 - accuracy: 0.6667\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 1.1413 - accuracy: 0.6667\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 1.1322 - accuracy: 0.7143\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 1.1229 - accuracy: 0.7143\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 1.1143 - accuracy: 0.7143\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 1.1057 - accuracy: 0.7143\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 1.0969 - accuracy: 0.7143\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 1.0882 - accuracy: 0.7143\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 1.0801 - accuracy: 0.7143\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 1.0719 - accuracy: 0.7619\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 1.0635 - accuracy: 0.7143\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 1.0554 - accuracy: 0.8095\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 1.0476 - accuracy: 0.8095\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 1.0397 - accuracy: 0.8095\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 1.0317 - accuracy: 0.8095\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 1.0238 - accuracy: 0.8095\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 1.0161 - accuracy: 0.8095\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 1.0084 - accuracy: 0.8095\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 1.0007 - accuracy: 0.8095\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.9929 - accuracy: 0.8095\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.9853 - accuracy: 0.8095\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.9778 - accuracy: 0.8095\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.9704 - accuracy: 0.8095\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.9629 - accuracy: 0.8095\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.9554 - accuracy: 0.8095\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.9480 - accuracy: 0.8095\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.9407 - accuracy: 0.8095\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.9335 - accuracy: 0.8095\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.9263 - accuracy: 0.8095\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.9191 - accuracy: 0.8095\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.9119 - accuracy: 0.8095\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.9048 - accuracy: 0.8095\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.8977 - accuracy: 0.8095\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.8906 - accuracy: 0.8095\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.8836 - accuracy: 0.8095\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.8766 - accuracy: 0.8571\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.8697 - accuracy: 0.8571\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.8628 - accuracy: 0.8571\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.8560 - accuracy: 0.8571\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.8492 - accuracy: 0.8571\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.8425 - accuracy: 0.8571\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.8359 - accuracy: 0.8571\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.8292 - accuracy: 0.8571\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.8226 - accuracy: 0.8571\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.8160 - accuracy: 0.8571\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.8095 - accuracy: 0.8571\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.8030 - accuracy: 0.8571\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.7966 - accuracy: 0.8571\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.7904 - accuracy: 0.8571\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.7842 - accuracy: 0.8571\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.7780 - accuracy: 0.8571\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.7720 - accuracy: 0.8571\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.7661 - accuracy: 0.8571\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.7604 - accuracy: 0.8571\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.7550 - accuracy: 0.8571\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.7499 - accuracy: 0.8571\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.7452 - accuracy: 0.8571\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.7392 - accuracy: 0.8571\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.7325 - accuracy: 0.8571\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.7263 - accuracy: 0.8571\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.7218 - accuracy: 0.8571\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.7174 - accuracy: 0.8571\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.7114 - accuracy: 0.8571\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.7056 - accuracy: 0.8571\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.7011 - accuracy: 0.8571\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.6966 - accuracy: 0.8571\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.6912 - accuracy: 0.8571\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.6860 - accuracy: 0.8571\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.6817 - accuracy: 0.8571\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.6773 - accuracy: 0.8571\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.6722 - accuracy: 0.8571\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.6675 - accuracy: 0.8571\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.6633 - accuracy: 0.8571\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.6590 - accuracy: 0.8571\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.6543 - accuracy: 0.8571\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.6499 - accuracy: 0.8571\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.6458 - accuracy: 0.8571\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.6417 - accuracy: 0.8571\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.6373 - accuracy: 0.8571\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.6331 - accuracy: 0.8571\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.6291 - accuracy: 0.8571\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.6252 - accuracy: 0.8571\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.6211 - accuracy: 0.8571\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.6170 - accuracy: 0.8571\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.6131 - accuracy: 0.8571\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.6093 - accuracy: 0.8571\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.6055 - accuracy: 0.8571\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.6016 - accuracy: 0.8571\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.5978 - accuracy: 0.8571\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.5941 - accuracy: 0.8571\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.5905 - accuracy: 0.8571\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.5868 - accuracy: 0.8571\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.5831 - accuracy: 0.8571\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.5795 - accuracy: 0.8571\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.5759 - accuracy: 0.8571\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.5724 - accuracy: 0.8571\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.5689 - accuracy: 0.8571\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.5654 - accuracy: 0.8571\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.5619 - accuracy: 0.8571\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.5585 - accuracy: 0.8571\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.5551 - accuracy: 0.8571\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.5518 - accuracy: 0.8571\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.5484 - accuracy: 0.8571\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.5451 - accuracy: 0.8571\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.5418 - accuracy: 0.8571\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.5386 - accuracy: 0.8571\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.5353 - accuracy: 0.8571\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.5321 - accuracy: 0.8571\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.5289 - accuracy: 0.8571\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.5258 - accuracy: 0.8571\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.5226 - accuracy: 0.8571\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.5195 - accuracy: 0.8571\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.5164 - accuracy: 0.8571\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.5133 - accuracy: 0.8571\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.5103 - accuracy: 0.8571\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.5073 - accuracy: 0.8571\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.5043 - accuracy: 0.8571\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.5013 - accuracy: 0.8571\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.4983 - accuracy: 0.8571\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.4954 - accuracy: 0.9048\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.4924 - accuracy: 0.8571\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.4895 - accuracy: 0.9048\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.4866 - accuracy: 0.9048\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.4838 - accuracy: 0.9048\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.4809 - accuracy: 0.9048\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.4781 - accuracy: 0.9048\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.4753 - accuracy: 0.9048\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.4725 - accuracy: 0.9048\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.4698 - accuracy: 0.9048\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.4670 - accuracy: 0.9048\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.4643 - accuracy: 0.9048\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.4616 - accuracy: 0.9048\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.4589 - accuracy: 0.9048\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.4562 - accuracy: 0.9048\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.4536 - accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.4510 - accuracy: 0.9048\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.4484 - accuracy: 0.9048\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.4459 - accuracy: 0.9048\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.4434 - accuracy: 0.9048\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.4411 - accuracy: 0.9048\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.4387 - accuracy: 0.9048\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.4364 - accuracy: 0.9048\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.4338 - accuracy: 0.9048\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.4311 - accuracy: 0.9048\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.4282 - accuracy: 0.9048\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.4256 - accuracy: 0.9048\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.4232 - accuracy: 0.9048\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.4210 - accuracy: 0.9048\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.4187 - accuracy: 0.9048\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.4163 - accuracy: 0.9048\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.4137 - accuracy: 0.9048\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.4113 - accuracy: 0.9048\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.4090 - accuracy: 0.9048\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.4068 - accuracy: 0.9048\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.4045 - accuracy: 0.9048\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.4022 - accuracy: 0.9048\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.3998 - accuracy: 0.9048\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.3975 - accuracy: 0.9048\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.3953 - accuracy: 0.9048\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.3932 - accuracy: 0.9048\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.3910 - accuracy: 0.9048\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.3888 - accuracy: 0.9048\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.3866 - accuracy: 0.9048\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.3844 - accuracy: 0.9048\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.3823 - accuracy: 0.9048\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.3802 - accuracy: 0.9048\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.3780 - accuracy: 0.9048\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.3759 - accuracy: 0.9048\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.3738 - accuracy: 0.9048\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.3717 - accuracy: 0.9048\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.3697 - accuracy: 0.9048\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.3676 - accuracy: 0.9048\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.3656 - accuracy: 0.9048\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.3635 - accuracy: 0.9048\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.3615 - accuracy: 0.9048\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.3594 - accuracy: 0.9048\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.3575 - accuracy: 0.9048\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.3555 - accuracy: 0.9048\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.3535 - accuracy: 0.9048\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.3515 - accuracy: 0.9048\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.3495 - accuracy: 0.9048\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.3476 - accuracy: 0.9048\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.3456 - accuracy: 0.9048\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.3437 - accuracy: 0.9048\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.3418 - accuracy: 0.9048\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.3399 - accuracy: 0.9048\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.3380 - accuracy: 0.9048\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.3361 - accuracy: 0.9048\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.3342 - accuracy: 0.9048\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.3323 - accuracy: 0.9048\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.3304 - accuracy: 0.9048\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.3286 - accuracy: 0.9048\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.3267 - accuracy: 0.9048\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.3249 - accuracy: 0.9048\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.3231 - accuracy: 0.9048\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.3213 - accuracy: 0.9048\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.3194 - accuracy: 0.9048\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.3176 - accuracy: 0.9048\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.3159 - accuracy: 0.9048\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.3141 - accuracy: 0.9048\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.3123 - accuracy: 0.9048\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.3105 - accuracy: 0.9048\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.3088 - accuracy: 0.9048\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.3070 - accuracy: 0.9048\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.3053 - accuracy: 0.9048\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.3035 - accuracy: 0.9048\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.3018 - accuracy: 0.9048\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.3001 - accuracy: 0.9048\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.2984 - accuracy: 0.9048\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.2967 - accuracy: 0.9048\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.2950 - accuracy: 0.9048\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.2933 - accuracy: 0.9048\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.2916 - accuracy: 0.9048\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.2900 - accuracy: 0.9048\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.2883 - accuracy: 0.9048\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.2866 - accuracy: 0.9048\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.2850 - accuracy: 0.9524\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.2833 - accuracy: 0.9524\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.2817 - accuracy: 0.9524\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.2801 - accuracy: 0.9524\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.2784 - accuracy: 0.9524\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.2768 - accuracy: 0.9524\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.2752 - accuracy: 0.9524\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.2736 - accuracy: 0.9524\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.2720 - accuracy: 0.9524\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.2704 - accuracy: 0.9524\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.2688 - accuracy: 0.9524\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.2672 - accuracy: 0.9524\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.2657 - accuracy: 0.9524\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.2641 - accuracy: 0.9524\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.2625 - accuracy: 0.9524\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.2610 - accuracy: 0.9524\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.2594 - accuracy: 0.9524\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.2579 - accuracy: 0.9524\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.2563 - accuracy: 0.9524\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.2548 - accuracy: 0.9524\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.2532 - accuracy: 0.9524\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.2517 - accuracy: 0.9524\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.2502 - accuracy: 0.9524\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.2487 - accuracy: 0.9524\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.2472 - accuracy: 0.9524\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.2457 - accuracy: 0.9524\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.2442 - accuracy: 0.9524\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.2427 - accuracy: 0.9524\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.2413 - accuracy: 0.9524\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.2398 - accuracy: 0.9524\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.2383 - accuracy: 0.9524\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.2369 - accuracy: 0.9524\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.2354 - accuracy: 0.9524\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.2340 - accuracy: 0.9524\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.2326 - accuracy: 0.9524\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.2312 - accuracy: 0.9524\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.2298 - accuracy: 0.9524\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.2284 - accuracy: 0.9524\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.2270 - accuracy: 0.9524\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.2256 - accuracy: 0.9524\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.2242 - accuracy: 0.9524\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.2228 - accuracy: 0.9524\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.2215 - accuracy: 0.9524\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.2201 - accuracy: 0.9524\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.2188 - accuracy: 0.9524\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.2175 - accuracy: 0.9524\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.2161 - accuracy: 0.9524\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.2148 - accuracy: 0.9524\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.2135 - accuracy: 0.9524\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.2122 - accuracy: 0.9524\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.2109 - accuracy: 0.9524\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.2097 - accuracy: 0.9524\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.2084 - accuracy: 0.9524\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.2071 - accuracy: 0.9524\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.2059 - accuracy: 0.9524\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.2047 - accuracy: 0.9524\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.2034 - accuracy: 0.9524\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.2022 - accuracy: 0.9524\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.2010 - accuracy: 0.9524\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.1998 - accuracy: 0.9524\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.1986 - accuracy: 0.9524\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.1974 - accuracy: 0.9524\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.1963 - accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.1951 - accuracy: 0.9524\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.1940 - accuracy: 0.9524\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.1928 - accuracy: 0.9524\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.1917 - accuracy: 0.9524\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.1906 - accuracy: 0.9524\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.1895 - accuracy: 0.9524\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.1884 - accuracy: 0.9524\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.1873 - accuracy: 0.9524\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.1862 - accuracy: 0.9524\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.1852 - accuracy: 0.9524\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.1841 - accuracy: 0.9524\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.1831 - accuracy: 0.9524\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.1820 - accuracy: 0.9524\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.1810 - accuracy: 0.9524\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.1800 - accuracy: 0.9524\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.1790 - accuracy: 0.9524\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.1780 - accuracy: 0.9524\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.1770 - accuracy: 0.9524\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.1760 - accuracy: 0.9524\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.1751 - accuracy: 0.9524\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.1741 - accuracy: 0.9524\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.1731 - accuracy: 0.9524\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.1722 - accuracy: 0.9524\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.1713 - accuracy: 0.9524\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.1703 - accuracy: 0.9524\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.1694 - accuracy: 0.9524\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.1685 - accuracy: 0.9524\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.1676 - accuracy: 0.9524\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.1667 - accuracy: 0.9524\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.1658 - accuracy: 0.9524\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.1650 - accuracy: 0.9524\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.1641 - accuracy: 0.9524\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.1632 - accuracy: 0.9524\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.1624 - accuracy: 0.9524\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.1615 - accuracy: 0.9524\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.1607 - accuracy: 0.9524\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.1599 - accuracy: 0.9524\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.1591 - accuracy: 0.9524\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.1582 - accuracy: 0.9524\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.1574 - accuracy: 0.9524\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.1567 - accuracy: 0.9524\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.1559 - accuracy: 0.9524\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.1551 - accuracy: 0.9524\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.1543 - accuracy: 0.9524\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.1536 - accuracy: 0.9524\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.1528 - accuracy: 0.9524\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.1521 - accuracy: 0.9524\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.1513 - accuracy: 0.9524\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.1506 - accuracy: 0.9524\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.1499 - accuracy: 0.9524\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.1492 - accuracy: 0.9524\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.1485 - accuracy: 0.9524\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.1478 - accuracy: 0.9524\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.1471 - accuracy: 0.9524\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.1464 - accuracy: 0.9524\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.1457 - accuracy: 0.9524\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.1451 - accuracy: 0.9524\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.1444 - accuracy: 0.9524\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.1437 - accuracy: 0.9524\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.1431 - accuracy: 0.9524\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.1425 - accuracy: 0.9524\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 0.9524\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.1412 - accuracy: 0.9524\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.1406 - accuracy: 0.9524\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.1400 - accuracy: 0.9524\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.1394 - accuracy: 0.9524\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.1388 - accuracy: 0.9524\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.1382 - accuracy: 0.9524\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.1376 - accuracy: 0.9524\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.1370 - accuracy: 0.9524\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.1364 - accuracy: 0.9524\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.1359 - accuracy: 0.9524\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.1353 - accuracy: 0.9524\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.1347 - accuracy: 0.9524\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.1342 - accuracy: 0.9524\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.1337 - accuracy: 0.9524\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.1331 - accuracy: 0.9524\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.1326 - accuracy: 0.9524\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.1321 - accuracy: 0.9524\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.1315 - accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbdc1777f60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad input sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length - 1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack fell down and broke\n",
      "Jill jill came tumbling after\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
