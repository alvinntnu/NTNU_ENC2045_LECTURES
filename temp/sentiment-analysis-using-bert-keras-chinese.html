
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sentiment Analysis Using BERT on Chinese Dataset &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/google-colab.html">
     Google Colab
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   1. Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   2. Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   3. Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-sklearn-classification.html">
   1. Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/topic-modeling-naive.html">
   2. Topic Modeling: A Naive Example
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-neural-network-from-scratch.html">
   1. Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-simple-case.html">
   2. Deep Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sentiment-case.html">
   3. Deep Learning: Sentiment Analysis
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Neural Language Model and Embeddings
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sequence-models-intuition.html">
   1. Sequence Models Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="text-vec-embedding.html">
   2. Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="text-vec-embedding-keras.html">
   3. Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-statistical-language-model.html">
   4. Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-neural-language-model-primer.html">
   5. Neural Language Model: A Start
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Seq2Seq, Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="dl-seq-to-seq-types.html">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-seq-to-seq-attention-addition.html">
   Seqeunce Model with Attention for Addition Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-transformers-keras.html">
   Text Classification with Transformer
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   Assignment III: Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   Assignment IV: Chinese Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   Assignment V: Text Vectorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/6-machine-learning.html">
   Assignment VI: Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/midterm-exam.html">
   Midterm Exam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/7-topic-modeling.html">
   Assignment VII: Topic Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/8-dl-chinese-name-gender.html">
   Assignment VIII: Deep Learning
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/temp/sentiment-analysis-using-bert-keras-chinese.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/temp/sentiment-analysis-using-bert-keras-chinese.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/temp/sentiment-analysis-using-bert-keras-chinese.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bert-in-short">
   BERT in Short
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-loading">
   Data Loading
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preprocessing">
   Data Preprocessing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bert-tokenizer">
   BERT Tokenizer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#from-text-to-bert-input">
   From Text to BERT Input
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-test-split">
   Train-Test Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-setup">
   Model Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-training">
   Model Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation-using-tensorbaord">
   Model Evaluation Using Tensorbaord
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation-metrics">
   Model Evaluation: Metrics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-model-with-bert">
   Custom Model with BERT
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-model-structure">
     Define Model Structure
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sentiment-analysis-using-bert-on-chinese-dataset">
<h1>Sentiment Analysis Using BERT on Chinese Dataset<a class="headerlink" href="#sentiment-analysis-using-bert-on-chinese-dataset" title="Permalink to this headline">Â¶</a></h1>
<p>In this tutorial, we show how to perform text classification of spammed mails using the pre-trained BERT model.</p>
<p>This example also shows the effectiveness of <strong>transfer learning</strong>.</p>
<div class="section" id="bert-in-short">
<h2>BERT in Short<a class="headerlink" href="#bert-in-short" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>BERT is a model with absolute position embeddings so itâ€™s usually advised to pad the inputs on the right rather than the left.</p></li>
<li><p>The BERT model was proposed in <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.</p></li>
<li><p>Itâ€™s a bidirectional transformer pretrained using a combination of masked language modeling objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia.</p></li>
<li><p>In particular, BERT was trained with the masked language modeling (MLM) and next sentence prediction (NSP) objectives. It is efficient at predicting masked tokens and at NLU in general, but is not optimal for text generation.</p></li>
<li><p>The size of the large BERT model:</p>
<ul>
<li><p>Transformer blocks: 24</p></li>
<li><p>Embedding dimension: 1024</p></li>
<li><p>Attention heads: 16</p></li>
<li><p>Total number of parameters: 340M</p></li>
</ul>
</li>
<li><p>The size of GPT-2 Model:</p>
<ul>
<li><p>Transformer blocks: 48</p></li>
<li><p>Sequence length: 1024</p></li>
<li><p>Embedding dimension: 1600</p></li>
<li><p>Total number of parameters: 1.5B</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-loading">
<h2>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># def unicode_to_ascii(s):</span>
<span class="c1">#     return &#39;&#39;.join(c for c in unicodedata.normalize(&#39;NFD&#39;, s) if unicodedata.category(c) != &#39;Mn&#39;)</span>

<span class="c1"># def clean_stopwords_shortwords(w):</span>
<span class="c1">#     stopwords_list=stopwords.words(&#39;english&#39;)</span>
<span class="c1">#     words = w.split() </span>
<span class="c1">#     clean_words = [word for word in words if (word not in stopwords_list) and len(word) &gt; 2]</span>
<span class="c1">#     return &quot; &quot;.join(clean_words) </span>

<span class="c1"># def preprocess_sentence(w):</span>
<span class="c1">#     w = unicode_to_ascii(w.lower().strip())</span>
<span class="c1">#     w = re.sub(r&quot;([?.!,Â¿])&quot;, r&quot; &quot;, w)</span>
<span class="c1">#     w = re.sub(r&#39;[&quot; &quot;]+&#39;, &quot; &quot;, w)</span>
<span class="c1">#     w = re.sub(r&quot;[^a-zA-Z?.!,Â¿]+&quot;, &quot; &quot;, w)</span>
<span class="c1">#     w=clean_stopwords_shortwords(w)</span>
<span class="c1">#     w=re.sub(r&#39;@\w+&#39;, &#39;&#39;,w)</span>
<span class="c1">#     return w</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_file</span><span class="o">=</span><span class="s1">&#39;../../../RepositoryData/data/marc_movie_review_metadata.csv&#39;</span>
<span class="n">csv_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">csv_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewID</th>
      <th>title_CH</th>
      <th>title_EN</th>
      <th>genre</th>
      <th>rating</th>
      <th>reviews</th>
      <th>reviews_sentiword_seg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Review_1</td>
      <td>ç´«ç¾…è˜­æ°¸æ†èŠ±åœ’å¤–å‚³ï¼æ°¸é èˆ‡è‡ªå‹•æ‰‹è¨˜äººå¶ï¼</td>
      <td>Violet Evergarden - Eternity and the Auto Memo...</td>
      <td>å‹•ç•«</td>
      <td>negative</td>
      <td>å”‰ï¼Œè¸©é›·äº†ï¼Œæµªè²»æ™‚é–“ï¼Œä¸æ¨ å”‰ï¼Œè¸©é›·äº†ï¼Œæµªè²»æ™‚é–“ï¼Œä¸æ¨</td>
      <td>å”‰ ï¼Œ è¸© é›· äº† ï¼Œ æµªè²» æ™‚é–“ ï¼Œ ä¸ æ¨ å”‰ ï¼Œ è¸© é›· äº† ï¼Œ æµªè²» æ™‚é–“ ï¼Œ ä¸ æ¨</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Review_2</td>
      <td>å¾©ä»‡è€…è¯ç›Ÿï¼šçµ‚å±€ä¹‹æˆ°</td>
      <td>Avengers: Endgame</td>
      <td>å‹•ä½œ_å†’éšª</td>
      <td>negative</td>
      <td>ç‰‡é•·ä¸‰å€‹å°æ™‚ï¼Œåªæœ‰æœ€å¾ŒåŠå°æ™‚èƒ½çœ‹ï¼Œå‰é¢çœŸçš„é‹ªé™³å¤ªä¹…ï¼Œæˆ‘æ—é‚Šçš„éƒ½çœ‹åˆ°æ‰“å‘¼</td>
      <td>ç‰‡é•· ä¸‰å€‹ å°æ™‚ ï¼Œ åªæœ‰ æœ€å¾Œ åŠ å°æ™‚ èƒ½ çœ‹ ï¼Œ å‰é¢ çœŸçš„ é‹ªé™³ å¤ªä¹… ï¼Œ æˆ‘ æ—é‚Š...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Review_3</td>
      <td>å¾©ä»‡è€…è¯ç›Ÿï¼šçµ‚å±€ä¹‹æˆ°</td>
      <td>Avengers: Endgame</td>
      <td>å‹•ä½œ_å†’éšª</td>
      <td>negative</td>
      <td>å²ä¸Šä¹‹æœ€ï¼ŒåŠ‡æƒ…æ‹–å¤ªé•·ï¼Œé‚Šçœ‹é‚Šæƒ³ç¡è¦º......  1.æµ©å…‹ç«Ÿç„¶å­¸æœƒè·Ÿæ—äººä¸€èµ·åˆç…§ã€‚ 2.ç´¢çˆ¾...</td>
      <td>å²ä¸Š ä¹‹ æœ€ ï¼Œ åŠ‡æƒ… æ‹– å¤ªé•· ï¼Œ é‚Šçœ‹é‚Š æƒ³ ç¡è¦º . . . . . . 1. æµ©å…‹ ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Review_4</td>
      <td>å¾©ä»‡è€…è¯ç›Ÿï¼šçµ‚å±€ä¹‹æˆ°</td>
      <td>Avengers: Endgame</td>
      <td>å‹•ä½œ_å†’éšª</td>
      <td>negative</td>
      <td>é›£çœ‹æ­»ã„Œ é›£çœ‹æ­»äº† é›£çœ‹æ­»ã„Œ çœ‹åˆ°ç¡è‘— æ‹–æˆ²æ‹–å¾ˆé•· çˆ›åˆ°çˆ†</td>
      <td>é›£çœ‹ æ­» ã„Œ é›£çœ‹ æ­» äº† é›£çœ‹ æ­» ã„Œ çœ‹åˆ° ç¡è‘— æ‹–æˆ² æ‹– å¾ˆé•· çˆ› åˆ° çˆ†</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Review_5</td>
      <td>å¾©ä»‡è€…è¯ç›Ÿï¼šçµ‚å±€ä¹‹æˆ°</td>
      <td>Avengers: Endgame</td>
      <td>å‹•ä½œ_å†’éšª</td>
      <td>negative</td>
      <td>é€£çºŒä¸‰åº¦ç¡è‘—ï¼ŒçœŸçš„æ¼”çš„å¤ªå¥½ç¡äº†</td>
      <td>é€£çºŒ ä¸‰åº¦ ç¡è‘— ï¼Œ çœŸçš„ æ¼” çš„ å¤ª å¥½ ç¡ äº†</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="data-preprocessing">
<h2>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;File has </span><span class="si">{}</span><span class="s1"> rows and </span><span class="si">{}</span><span class="s1"> columns&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">csv_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">csv_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>File has 3200 rows and 7 columns
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># csv_data = csv_data.loc[:, ~csv_data.columns.str.contains(&#39;Unnamed: 2&#39;, case=False)] </span>
<span class="c1"># csv_data = csv_data.loc[:, ~csv_data.columns.str.contains(&#39;Unnamed: 3&#39;, case=False)] </span>
<span class="c1"># csv_data = csv_data.loc[:, ~csv_data.columns.str.contains(&#39;Unnamed: 4&#39;, case=False)] </span>
<span class="c1"># csv_data.head()</span>
<span class="c1"># csv_data=csv_data.dropna() </span>
<span class="c1"># csv_data=csv_data.reset_index(drop=True)  # Reset index after dropping the columns/rows with NaN values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;rating&#39;</span><span class="p">:</span><span class="s1">&#39;label&#39;</span><span class="p">,</span><span class="s1">&#39;reviews&#39;</span><span class="p">:</span><span class="s1">&#39;text&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_data</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">csv_data</span><span class="p">)</span>                                                         <span class="c1"># Shuffle the dataset</span>
<span class="c1">#print(&#39;Available labels: &#39;,data.label.unique())                              # Print all the unique labels in the dataset</span>
<span class="c1"># csv_data[&#39;text&#39;]=csv_data[&#39;text&#39;].map(preprocess_sentence)                           # Clean the text column using preprocess_sentence function defined above</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;File has </span><span class="si">{}</span><span class="s1"> rows and </span><span class="si">{}</span><span class="s1"> columns&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">csv_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">csv_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">csv_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>File has 3200 rows and 7 columns
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewID</th>
      <th>title_CH</th>
      <th>title_EN</th>
      <th>genre</th>
      <th>label</th>
      <th>text</th>
      <th>reviews_sentiword_seg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1694</th>
      <td>Review_1695</td>
      <td>è¬è¬æ²’æƒ³åˆ°</td>
      <td>Chhichhore</td>
      <td>åŠ‡æƒ…_å–œåŠ‡</td>
      <td>positive</td>
      <td>çœ‹å®Œé€™éƒ¨ä»¥å¾Œ,æˆ‘äººç”Ÿä¸­æœ€å¥½çœ‹çš„åŠ‡åˆå¢åŠ äº†ä¸€éƒ¨,ä¸Šä¸€éƒ¨æ˜¯ä¸‰å€‹å‚»ç“œ,èª å¿ƒæ¨è–¦</td>
      <td>çœ‹å®Œ é€™éƒ¨ ä»¥å¾Œ , æˆ‘ äººç”Ÿ ä¸­ æœ€ å¥½çœ‹ çš„ åŠ‡ åˆ å¢åŠ  äº† ä¸€éƒ¨ , ä¸Šä¸€éƒ¨ æ˜¯ ä¸‰...</td>
    </tr>
    <tr>
      <th>2819</th>
      <td>Review_2820</td>
      <td>è­‰äºº</td>
      <td>Innocent Witness</td>
      <td>åŠ‡æƒ…</td>
      <td>positive</td>
      <td>ä¹‹æ–¼é©šå¥‡éšŠé•·ï¼Œæˆ‘æœƒé¸æ“‡è­‰äººï¼ŒåŠ‡æƒ…å¤ªå¤šå±¤äº†</td>
      <td>ä¹‹æ–¼ é©šå¥‡éšŠé•· ï¼Œ æˆ‘ æœƒ é¸æ“‡ è­‰äºº ï¼Œ åŠ‡æƒ… å¤ªå¤š å±¤ äº†</td>
    </tr>
    <tr>
      <th>2833</th>
      <td>Review_2834</td>
      <td>è¿”æ ¡</td>
      <td>Detention</td>
      <td>æ‡¸ç–‘/é©šæ‚š</td>
      <td>positive</td>
      <td>å¥½çœ‹ ä¸€å †ä¸­åœ‹äººå’ŒéŸ“ç²‰åˆ¥ä¾†äº‚åˆ·è² è©•é˜¿ äº‹å¯¦ä¹Ÿæ˜¯æŠ¹æ»…ä¸äº†é˜¿</td>
      <td>å¥½çœ‹ ä¸€å † ä¸­åœ‹ äºº å’Œ éŸ“ç²‰ åˆ¥ä¾† äº‚ åˆ· è² è©• é˜¿ äº‹å¯¦ ä¹Ÿæ˜¯ æŠ¹æ»… ä¸äº† é˜¿</td>
    </tr>
    <tr>
      <th>2904</th>
      <td>Review_2905</td>
      <td>ä½ çš„æƒ…æ­Œ</td>
      <td>Your love song</td>
      <td>åŠ‡æƒ…</td>
      <td>positive</td>
      <td>æ¼”å“¡æ¼”æŠ€å¯¦åŠ›éƒ½å¾ˆå¥½ï¼ŒåŠ‡æƒ…æ¶æ§‹ä¹Ÿå¾ˆæ£’ï¼</td>
      <td>æ¼”å“¡ æ¼”æŠ€ å¯¦åŠ› éƒ½ å¾ˆ å¥½ ï¼Œ åŠ‡æƒ… æ¶æ§‹ ä¹Ÿ å¾ˆæ£’ ï¼</td>
    </tr>
    <tr>
      <th>2304</th>
      <td>Review_2305</td>
      <td>è‚¥é¾éæ±Ÿ</td>
      <td>Enter The Fat Dragon</td>
      <td>å‹•ä½œ_å–œåŠ‡</td>
      <td>positive</td>
      <td>è¶…æƒ³çœ‹ ã€Šè‚¥é¾éæ±Ÿã€‹ï¼Œå› ç‚ºé€™éƒ¨é›»å½±æ„Ÿè¦ºå¥½çœ‹ã€å¥½ç¬‘ã€å¾ˆæœ‰æ„æ€ï¼Œéçœ‹ä¸å¯ï¼ğŸ™‹</td>
      <td>è¶… æƒ³ çœ‹ ã€Š è‚¥ é¾ é æ±Ÿ ã€‹ ï¼Œ å› ç‚º é€™éƒ¨ é›»å½± æ„Ÿè¦º å¥½çœ‹ ã€ å¥½ç¬‘ ã€ å¾ˆ æœ‰ ...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="bert-tokenizer">
<h2>BERT Tokenizer<a class="headerlink" href="#bert-tokenizer" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>You can find more pre-trained models supported by HuggingFace <a class="reference external" href="https://huggingface.co/models?filter=zh">here</a>.</p></li>
<li><p>CKIP has also released their BERT models. Please see <a class="reference external" href="https://huggingface.co/ckiplab">here</a>.</p>
<ul>
<li><p>It seems that CKIP only releases the <code class="docutils literal notranslate"><span class="pre">pytorch</span></code> version of the pre-trained models. They are not using Tensorflow unfortunately.</p></li>
<li><p>But the general Chinese models come with both versions <code class="docutils literal notranslate"><span class="pre">bert-base-chinese</span></code>. So we will use this general one.</p></li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In <code class="docutils literal notranslate"><span class="pre">transformers</span></code>, there are several predefined tensorflow models that use BERT for classification. Please see Hugginface transformersâ€™s <a class="reference external" href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a> documentation.</p>
</div>
<p>dd</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">csv_data</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">50</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">TFBertModel</span><span class="p">,</span> <span class="n">BertConfig</span>
<span class="n">bert_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span>
                                              <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="c1">#                                               max_length=MAX_LEN,</span>
                                              <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "52af120dd3764011b23724c32e0f9e52", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bert_model</span> <span class="o">=</span> <span class="n">TFBertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "d0d87a46f99543ff8b3268536d62a85c", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "5803bf7b74c9496e90c540a7f1ca0299", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of the model checkpoint at bert-base-chinese were not used when initializing TFBertForSequenceClassification: [&#39;nsp___cls&#39;, &#39;mlm___cls&#39;]
- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: [&#39;dropout_37&#39;, &#39;classifier&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sent</span><span class="o">=</span> <span class="s1">&#39;å¤©é˜¿ï¼Œé€™é›»å½±å¯¦åœ¨æ˜¯...ç„¡è¨€å•Šï¼&#39;</span>
<span class="n">tokens</span><span class="o">=</span><span class="n">bert_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;å¤©&#39;, &#39;é˜¿&#39;, &#39;ï¼Œ&#39;, &#39;é€™&#39;, &#39;é›»&#39;, &#39;å½±&#39;, &#39;å¯¦&#39;, &#39;åœ¨&#39;, &#39;æ˜¯&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;ç„¡&#39;, &#39;è¨€&#39;, &#39;å•Š&#39;, &#39;ï¼&#39;]
</pre></div>
</div>
</div>
</div>
<p>Parameters of <code class="docutils literal notranslate"><span class="pre">TFBertForSequenceClassification</span></code> model:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_ids</span></code>: The input ids are often the only required parameters to be passed to the model as input. They are token indices, numerical representations of tokens building the sequences that will be used as input by the model. This can be obtained by the BERT Tokenizer.
input_ids (Numpy array or tf.Tensor of shape (batch_size, sequence_length))
Indices of input sequence tokens in the vocabulary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> : Number of examples or sentences batch
sequence_length : A number of tokens in a sentence.</p></li>
</ul>
<ol class="simple">
<li><p>attention_mask (Numpy array or tf.Tensor of shape (batch_size, sequence_length)) â€“
Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]: 1 for tokens that are not masked, 0 for tokens that are marked (0 if the token is added by padding).
This argument indicates to the model which tokens should be attended to, and which should not.
If we have 2 sentences and the sequence length of one sentence is 8 and another one is 10, then we need to make them of equal length and for that, padding is required. To distinguish between the padded and nonpadded input attention mask is used.</p></li>
<li><p>labels (tf.Tensor of shape (batch_size,), optional) â€“ Labels for computing the sequence classification/regression loss.
Indices should be in [0, â€¦, num_classes- 1]. If num_classes == 1 a regression loss is computed (Mean-Square loss), If num_classes &gt; 1 a classification loss is computed (Cross-Entropy).
These tokens can then be converted into IDs which are understandable by the model. This can be done by directly feeding the sentence to the tokenizer.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized_sequence</span><span class="o">=</span> <span class="n">bert_tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span><span class="n">add_special_tokens</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span> <span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">return_attention_mask</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized_sequence</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;input_ids&#39;: [101, 1921, 7350, 8024, 6857, 7442, 2512, 2179, 1762, 3221, 119, 119, 119, 4192, 6241, 1557, 8013, 102], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bert_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenized_sequence</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;[CLS] å¤© é˜¿ ï¼Œ é€™ é›» å½± å¯¦ åœ¨ æ˜¯... ç„¡ è¨€ å•Š ï¼ [SEP]&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="from-text-to-bert-input">
<h2>From Text to BERT Input<a class="headerlink" href="#from-text-to-bert-input" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_data</span><span class="p">[</span><span class="s1">&#39;label_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">csv_data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;negative&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;positive&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">csv_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>reviewID</th>
      <th>title_CH</th>
      <th>title_EN</th>
      <th>genre</th>
      <th>label</th>
      <th>text</th>
      <th>reviews_sentiword_seg</th>
      <th>label_num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1694</th>
      <td>Review_1695</td>
      <td>è¬è¬æ²’æƒ³åˆ°</td>
      <td>Chhichhore</td>
      <td>åŠ‡æƒ…_å–œåŠ‡</td>
      <td>positive</td>
      <td>çœ‹å®Œé€™éƒ¨ä»¥å¾Œ,æˆ‘äººç”Ÿä¸­æœ€å¥½çœ‹çš„åŠ‡åˆå¢åŠ äº†ä¸€éƒ¨,ä¸Šä¸€éƒ¨æ˜¯ä¸‰å€‹å‚»ç“œ,èª å¿ƒæ¨è–¦</td>
      <td>çœ‹å®Œ é€™éƒ¨ ä»¥å¾Œ , æˆ‘ äººç”Ÿ ä¸­ æœ€ å¥½çœ‹ çš„ åŠ‡ åˆ å¢åŠ  äº† ä¸€éƒ¨ , ä¸Šä¸€éƒ¨ æ˜¯ ä¸‰...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2819</th>
      <td>Review_2820</td>
      <td>è­‰äºº</td>
      <td>Innocent Witness</td>
      <td>åŠ‡æƒ…</td>
      <td>positive</td>
      <td>ä¹‹æ–¼é©šå¥‡éšŠé•·ï¼Œæˆ‘æœƒé¸æ“‡è­‰äººï¼ŒåŠ‡æƒ…å¤ªå¤šå±¤äº†</td>
      <td>ä¹‹æ–¼ é©šå¥‡éšŠé•· ï¼Œ æˆ‘ æœƒ é¸æ“‡ è­‰äºº ï¼Œ åŠ‡æƒ… å¤ªå¤š å±¤ äº†</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2833</th>
      <td>Review_2834</td>
      <td>è¿”æ ¡</td>
      <td>Detention</td>
      <td>æ‡¸ç–‘/é©šæ‚š</td>
      <td>positive</td>
      <td>å¥½çœ‹ ä¸€å †ä¸­åœ‹äººå’ŒéŸ“ç²‰åˆ¥ä¾†äº‚åˆ·è² è©•é˜¿ äº‹å¯¦ä¹Ÿæ˜¯æŠ¹æ»…ä¸äº†é˜¿</td>
      <td>å¥½çœ‹ ä¸€å † ä¸­åœ‹ äºº å’Œ éŸ“ç²‰ åˆ¥ä¾† äº‚ åˆ· è² è©• é˜¿ äº‹å¯¦ ä¹Ÿæ˜¯ æŠ¹æ»… ä¸äº† é˜¿</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2904</th>
      <td>Review_2905</td>
      <td>ä½ çš„æƒ…æ­Œ</td>
      <td>Your love song</td>
      <td>åŠ‡æƒ…</td>
      <td>positive</td>
      <td>æ¼”å“¡æ¼”æŠ€å¯¦åŠ›éƒ½å¾ˆå¥½ï¼ŒåŠ‡æƒ…æ¶æ§‹ä¹Ÿå¾ˆæ£’ï¼</td>
      <td>æ¼”å“¡ æ¼”æŠ€ å¯¦åŠ› éƒ½ å¾ˆ å¥½ ï¼Œ åŠ‡æƒ… æ¶æ§‹ ä¹Ÿ å¾ˆæ£’ ï¼</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2304</th>
      <td>Review_2305</td>
      <td>è‚¥é¾éæ±Ÿ</td>
      <td>Enter The Fat Dragon</td>
      <td>å‹•ä½œ_å–œåŠ‡</td>
      <td>positive</td>
      <td>è¶…æƒ³çœ‹ ã€Šè‚¥é¾éæ±Ÿã€‹ï¼Œå› ç‚ºé€™éƒ¨é›»å½±æ„Ÿè¦ºå¥½çœ‹ã€å¥½ç¬‘ã€å¾ˆæœ‰æ„æ€ï¼Œéçœ‹ä¸å¯ï¼ğŸ™‹</td>
      <td>è¶… æƒ³ çœ‹ ã€Š è‚¥ é¾ é æ±Ÿ ã€‹ ï¼Œ å› ç‚º é€™éƒ¨ é›»å½± æ„Ÿè¦º å¥½çœ‹ ã€ å¥½ç¬‘ ã€ å¾ˆ æœ‰ ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span><span class="o">=</span><span class="n">csv_data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
<span class="n">labels</span><span class="o">=</span><span class="n">csv_data</span><span class="p">[</span><span class="s1">&#39;label_num&#39;</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3200, 3200)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_ids</span><span class="o">=</span><span class="p">[]</span>
<span class="n">attention_masks</span><span class="o">=</span><span class="p">[]</span>
<span class="n">segment_ids</span> <span class="o">=</span><span class="p">[]</span> 

<span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">bert_inp</span><span class="o">=</span><span class="n">bert_tokenizer</span><span class="o">.</span><span class="n">encode_plus</span><span class="p">(</span>
        <span class="n">sent</span><span class="p">,</span><span class="n">add_special_tokens</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">max_length</span> <span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span>
        <span class="n">pad_to_max_length</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
        <span class="n">return_attention_mask</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bert_inp</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span>
    <span class="n">attention_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bert_inp</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])</span>
    <span class="n">segment_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bert_inp</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">])</span>

<span class="c1">## alvin&#39;s note:</span>
<span class="c1">## according to the warning, we should use `padding=&#39;max_length&#39;` and specificay `max_length = 50`</span>
<span class="c1">## to make it work</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_ids</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="n">attention_masks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">attention_masks</span><span class="p">)</span>
<span class="n">segment_ids</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">)</span>
<span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">attention_masks</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3200, 3200, 3200, 3200)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>BERT Tokenizer returns a dictionary from which we can get the input ids and the attention masks.</p></li>
<li><p>Convert all the encoding to NumPy arrays.</p></li>
<li><p>Arguments of BERT Tokenizer:</p>
<ul>
<li><p>text (str, List[str], List[List[str]]) â€“ The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set is_split_into_words=True (to lift the ambiguity with a batch of sequences).</p></li>
<li><p>add_special_tokens (bool, optional, defaults to True) â€“ Whether or not to encode the sequences with the special tokens relative to their model.</p></li>
<li><p>max_length (int, optional) â€” Controls the maximum length to use by one of the truncation/padding parameters. (max_lengthâ‰¤512)</p></li>
<li><p>padding (bool, optional, defaults to True) â€“ Whether or not to pad the sequences to the maximum length.</p></li>
<li><p>return_attention_mask (bool, optional) â€“</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="train-test-split">
<h2>Train-Test Split<a class="headerlink" href="#train-test-split" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn.model_selection</span>
<span class="n">train_inp</span><span class="p">,</span><span class="n">val_inp</span><span class="p">,</span><span class="n">train_label</span><span class="p">,</span><span class="n">val_label</span><span class="p">,</span><span class="n">train_mask</span><span class="p">,</span><span class="n">val_mask</span><span class="p">,</span> <span class="n">train_seg</span><span class="p">,</span> <span class="n">val_seg</span> <span class="o">=</span><span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">attention_masks</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train inp shape </span><span class="si">{}</span><span class="s1"> Val input shape </span><span class="si">{}</span><span class="se">\n</span><span class="s1">Train label shape </span><span class="si">{}</span><span class="s1"> Val label shape </span><span class="si">{}</span><span class="se">\n</span><span class="s1">Train attention mask shape </span><span class="si">{}</span><span class="s1"> Val attention mask shape </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">val_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">train_label</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">val_label</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">train_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">val_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train inp shape (2560, 50) Val input shape (640, 50)
Train label shape (2560,) Val label shape (640,)
Train attention mask shape (2560, 50) Val attention mask shape (640, 50)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-setup">
<h2>Model Setup<a class="headerlink" href="#model-setup" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;./sentiment-analysis-using-bert-keras-chinese/models/&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="c1">## Callbacks</span>
<span class="c1">## The model will automatically create the `log_dir` but not `model_save_path`</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;./sentiment-analysis-using-bert-keras-chinese/tensorboard_data/tb_bert&#39;</span>
<span class="n">model_save_path</span><span class="o">=</span><span class="s1">&#39;./sentiment-analysis-using-bert-keras-chinese/models/bert_model.h5&#39;</span>


<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">model_save_path</span><span class="p">,</span><span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Bert Model&#39;</span><span class="p">,</span><span class="n">bert_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">)</span>

<span class="n">bert_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;tf_bert_for_sequence_classification&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
bert (TFBertMainLayer)       multiple                  102267648 
_________________________________________________________________
dropout_37 (Dropout)         multiple                  0         
_________________________________________________________________
classifier (Dense)           multiple                  1538      
=================================================================
Total params: 102,269,186
Trainable params: 102,269,186
Non-trainable params: 0
_________________________________________________________________

Bert Model None
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-training">
<h2>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span><span class="o">=</span><span class="n">bert_model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">train_inp</span><span class="p">,</span><span class="n">train_mask</span><span class="p">],</span>
                       <span class="n">train_label</span><span class="p">,</span>
                       <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">val_inp</span><span class="p">,</span><span class="n">val_mask</span><span class="p">],</span><span class="n">val_label</span><span class="p">),</span>
                       <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 1/80 [..............................] - ETA: 0s - loss: 0.8381 - accuracy: 0.3750WARNING:tensorflow:From /Users/Alvin/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
80/80 [==============================] - 846s 11s/step - loss: 0.4073 - accuracy: 0.8152 - val_loss: 0.2520 - val_accuracy: 0.8984
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bert_model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">model_save_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-evaluation-using-tensorbaord">
<h2>Model Evaluation Using Tensorbaord<a class="headerlink" href="#model-evaluation-using-tensorbaord" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %load_ext tensorboard</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %tensorboard --logdir {log_dir}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-evaluation-metrics">
<h2>Model Evaluation: Metrics<a class="headerlink" href="#model-evaluation-metrics" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model_save_path=&#39;./sentiment-analysis-using-bert-keras/models/bert_model.h5&#39;</span>


<span class="n">trained_model</span> <span class="o">=</span> <span class="n">TFBertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">,</span><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">trained_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="p">])</span>
<span class="n">trained_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">model_save_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some layers from the model checkpoint at bert-base-chinese were not used when initializing TFBertForSequenceClassification: [&#39;nsp___cls&#39;, &#39;mlm___cls&#39;]
- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: [&#39;classifier&#39;, &#39;dropout_75&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span>
                          <span class="n">target_names</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">,</span>
                          <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    given a sklearn confusion matrix (cm), make a nice plot</span>

<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    cm:           confusion matrix from sklearn.metrics.confusion_matrix</span>

<span class="sd">    target_names: given classification classes such as [0, 1, 2]</span>
<span class="sd">                  the class names, for example: [&#39;high&#39;, &#39;medium&#39;, &#39;low&#39;]</span>

<span class="sd">    title:        the text to display at the top of the matrix</span>

<span class="sd">    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm</span>
<span class="sd">                  see http://matplotlib.org/examples/color/colormaps_reference.html</span>
<span class="sd">                  plt.get_cmap(&#39;jet&#39;) or plt.cm.Blues</span>

<span class="sd">    normalize:    If False, plot the raw numbers</span>
<span class="sd">                  If True, plot the proportions</span>

<span class="sd">    Usage</span>
<span class="sd">    -----</span>
<span class="sd">    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by</span>
<span class="sd">                                                              # sklearn.metrics.confusion_matrix</span>
<span class="sd">                          normalize    = True,                # show proportions</span>
<span class="sd">                          target_names = y_labels_vals,       # list of names of the classes</span>
<span class="sd">                          title        = best_estimator_name) # title of graph</span>

<span class="sd">    Citiation</span>
<span class="sd">    ---------</span>
<span class="sd">    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">itertools</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cm</span><span class="p">))</span>
    <span class="n">misclass</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">accuracy</span>

    <span class="k">if</span> <span class="n">cmap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">target_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">target_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">target_names</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>


    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1.5</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="n">cm</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{:0.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]),</span>
                     <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{:,}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]),</span>
                     <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span>


    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True label&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label</span><span class="se">\n</span><span class="s1">accuracy=</span><span class="si">{:0.4f}</span><span class="s1">; misclass=</span><span class="si">{:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">misclass</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">bert_model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">val_inp</span><span class="p">,</span><span class="n">val_mask</span><span class="p">],</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">pred_labels</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">val_label</span><span class="p">,</span><span class="n">pred_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;F1 score&#39;</span><span class="p">,</span><span class="n">f1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">)</span>

<span class="n">target_names</span><span class="o">=</span><span class="n">csv_data</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">val_label</span><span class="p">,</span><span class="n">pred_labels</span><span class="p">,</span><span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training and saving built model.....&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>F1 score 0.882032667876588
Classification Report
              precision    recall  f1-score   support

    positive       0.86      0.97      0.91       343
    negative       0.96      0.82      0.88       297

    accuracy                           0.90       640
   macro avg       0.91      0.89      0.90       640
weighted avg       0.90      0.90      0.90       640

Training and saving built model.....
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">val_label</span><span class="p">,</span> <span class="n">pred_labels</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span>
                      <span class="n">normalize</span>    <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                      <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ham&#39;</span><span class="p">,</span> <span class="s1">&#39;spam&#39;</span><span class="p">],</span>
                      <span class="n">title</span>        <span class="o">=</span> <span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/sentiment-analysis-using-bert-keras-chinese_49_0.png" src="../_images/sentiment-analysis-using-bert-keras-chinese_49_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">([</span><span class="n">val_inp</span><span class="p">,</span><span class="n">val_mask</span><span class="p">],</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20/20 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.8781
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.0, 0.878125011920929]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="custom-model-with-bert">
<h2>Custom Model with BERT<a class="headerlink" href="#custom-model-with-bert" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFBertModel</span>

<span class="n">bert_custom</span> <span class="o">=</span> <span class="n">TFBertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>
<span class="n">bert_custom</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of the model checkpoint at bert-base-chinese were not used when initializing TFBertModel: [&#39;nsp___cls&#39;, &#39;mlm___cls&#39;]
- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFBertModel were initialized from the model checkpoint at bert-base-chinese.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;tf_bert_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
bert (TFBertMainLayer)       multiple                  102267648 
=================================================================
Total params: 102,267,648
Trainable params: 102,267,648
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="section" id="define-model-structure">
<h3>Define Model Structure<a class="headerlink" href="#define-model-structure" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inp_ids</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="n">MAX_LEN</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_ids&quot;</span><span class="p">)</span>
<span class="n">att_mask</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="n">MAX_LEN</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">)</span>
<span class="n">seg_ids</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="n">MAX_LEN</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">)</span>

<span class="n">inp_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">inp_ids</span><span class="p">,</span>
           <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">att_mask</span><span class="p">,</span>
           <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">seg_ids</span><span class="p">}</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">bert_custom</span><span class="p">(</span><span class="n">inp_dict</span><span class="p">)</span> <span class="c1">## get the pooled output of each input sequence for fine-tuning</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## The output of the each input token includes special token [SEP] and [CLS].</span>
<span class="c1">## The second one is [CLS], which is the pooled output of the entire input sequence</span>
<span class="n">outputs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;tf.Tensor &#39;tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0&#39; shape=(None, 50, 768) dtype=float32&gt;,
 &lt;tf.Tensor &#39;tf_bert_model/bert/pooler/dense/Tanh:0&#39; shape=(None, 768) dtype=float32&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">custom_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp_dict</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">custom_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;functional_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
attention_mask (InputLayer)     [(None, 50)]         0                                            
__________________________________________________________________________________________________
input_ids (InputLayer)          [(None, 50)]         0                                            
__________________________________________________________________________________________________
token_type_ids (InputLayer)     [(None, 50)]         0                                            
__________________________________________________________________________________________________
tf_bert_model (TFBertModel)     ((None, 50, 768), (N 102267648   attention_mask[0][0]             
                                                                 input_ids[0][0]                  
                                                                 token_type_ids[0][0]             
__________________________________________________________________________________________________
dropout_75 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 200)          153800      dropout_75[0][0]                 
__________________________________________________________________________________________________
dropout_76 (Dropout)            (None, 200)          0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            402         dropout_76[0][0]                 
==================================================================================================
Total params: 102,421,850
Trainable params: 102,421,850
Non-trainable params: 0
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Fine tune BERT on IMDB</span>

<span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">train_inp</span><span class="p">,</span>
           <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">train_mask</span><span class="p">,</span>
           <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">train_seg</span><span class="p">}</span>
<span class="n">val_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">val_inp</span><span class="p">,</span>
           <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">val_mask</span><span class="p">,</span>
           <span class="s2">&quot;token_type_ids&quot;</span><span class="p">:</span> <span class="n">val_seg</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bert_custom</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="kc">False</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">## standard learning rate</span>
<span class="n">custom_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="p">])</span>
<span class="n">custom_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;functional_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
attention_mask (InputLayer)     [(None, 50)]         0                                            
__________________________________________________________________________________________________
input_ids (InputLayer)          [(None, 50)]         0                                            
__________________________________________________________________________________________________
token_type_ids (InputLayer)     [(None, 50)]         0                                            
__________________________________________________________________________________________________
tf_bert_model (TFBertModel)     ((None, 50, 768), (N 102267648   attention_mask[0][0]             
                                                                 input_ids[0][0]                  
                                                                 token_type_ids[0][0]             
__________________________________________________________________________________________________
dropout_75 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 200)          153800      dropout_75[0][0]                 
__________________________________________________________________________________________________
dropout_76 (Dropout)            (None, 200)          0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2)            402         dropout_76[0][0]                 
==================================================================================================
Total params: 102,421,850
Trainable params: 154,202
Non-trainable params: 102,267,648
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">custom_history</span> <span class="o">=</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_dict</span><span class="p">,</span><span class="n">val_label</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/3
80/80 [==============================] - 300s 4s/step - loss: 0.6673 - accuracy: 0.5791 - val_loss: 0.6193 - val_accuracy: 0.6016
Epoch 2/3
80/80 [==============================] - 293s 4s/step - loss: 0.5916 - accuracy: 0.6922 - val_loss: 0.4886 - val_accuracy: 0.8234
Epoch 3/3
80/80 [==============================] - 297s 4s/step - loss: 0.5164 - accuracy: 0.7898 - val_loss: 0.4812 - val_accuracy: 0.8313
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://swatimeena989.medium.com/bert-text-classification-using-keras-903671e0207d">BERT Text Classification Using Keras</a></p></li>
<li><p><a class="reference external" href="http://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a></p></li>
<li><p><a class="reference external" href="https://keras.io/examples/nlp/text_extraction_with_bert/#text-extraction-with-bert">Text Extraction with BERT</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./temp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>