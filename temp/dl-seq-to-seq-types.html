
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Attention: Intuition &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sequence Model with Attention for Addition Learning" href="dl-seq-to-seq-attention-addition.html" />
    <link rel="prev" title="3. Word Embeddings" href="text-vec-embedding.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/google-colab.html">
     Google Colab
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   1. Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   2. Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   3. Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-sklearn-classification.html">
   1. Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/topic-modeling-naive.html">
   2. Topic Modeling: A Naive Example
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-neural-network-from-scratch.html">
   1. Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-simple-case.html">
   2. Deep Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sentiment-case.html">
   3. Deep Learning: Sentiment Analysis
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Neural Language Model and Embeddings
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sequence-models-intuition.html">
   1. Sequence Models Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-neural-language-model-primer.html">
   2. Neural Language Model: A Start
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="text-vec-embedding.html">
   3. Word Embeddings
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Seq2Seq, Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-seq-to-seq-attention-addition.html">
   Sequence Model with Attention for Addition Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-transformers-keras.html">
   Text Classification with Transformer
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   Assignment III: Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   Assignment IV: Chinese Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   Assignment V: Text Vectorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/6-machine-learning.html">
   Assignment VI: Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/midterm-exam.html">
   Midterm Exam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/7-topic-modeling.html">
   Assignment VII: Topic Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/8-dl-chinese-name-gender.html">
   Assignment VIII: Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/9-sentiment-analysis-dl.html">
   Assignment IX: Sentiment Analysis Using Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/10-neural-language-model.html">
   Assignment X: Neural Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/11-word2vec.html">
   Assignment XI: Word Embeddings
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/temp/dl-seq-to-seq-types.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/temp/dl-seq-to-seq-types.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/temp/dl-seq-to-seq-types.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-attention">
   Self-Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sequence-model-with-attention">
   Sequence Model with Attention
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vanillar-encoder-decoder-model">
     Vanillar Encoder-Decoder Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#peeky-encoder-decoder-model">
     Peeky Encoder-Decoder Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attention-based-encoder-decoder-model">
     Attention-based Encoder-Decoder Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#usage-of-attention-layer-in-keras">
   Usage of Attention Layer in keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="attention-intuition">
<h1>Attention: Intuition<a class="headerlink" href="#attention-intuition" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>The state-of-the-art NLP features the use of <strong>Attention</strong> or its sophisticated application, <strong>transformers</strong>.</p></li>
<li><p>In this unit, we will provide an intuitive understanding of <strong>Attention</strong> mechanism in deep learning.</p></li>
</ul>
<div class="section" id="self-attention">
<h2>Self-Attention<a class="headerlink" href="#self-attention" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Self-attention operation is fundamental to the SOTA NLP.</p></li>
<li><p>It is a simple sequence-to-sequence operation: a sequence of vectors (<strong>input vectors</strong>) goes in, and a sequence of vectors comes out.</p></li>
<li><p>The self-attention operation builds upon the assumption that among all the input vectors, some are more similar to each other.</p></li>
<li><p>Therefore, the Self-Attention layer may give more weights to those input vectors that are more similar to each other when generating the output vectors.</p></li>
</ul>
<ul class="simple">
<li><p>How do we know which input vectors are more similar or more connected to each ther? The simplest way is to compute the <strong>dot-product</strong> of the two vectors (i.e., similar to Cosine Similarity).</p></li>
<li><p>Therefore, in Self-Attention, each input vector (<strong>Query</strong>) is compared to all the other input vectors (<strong>Keys</strong>) to get the weights or similarity measures.</p></li>
<li><p>And its output vector is a weighted sum over all the input vectors, weighted by the similarity measures (in-between input vectors).</p></li>
</ul>
<p><img alt="" src="../_images/seq2seq-self-atten1.gif" /></p>
<ul class="simple">
<li><p>For instance, in the following example, the word <span class="math notranslate nohighlight">\(walks\)</span> may be more relevant to <em>who</em> is doing the walking, i.e., <span class="math notranslate nohighlight">\(cats\)</span>, or, <em>where</em> the agent is walking, i.e, <span class="math notranslate nohighlight">\(street\)</span>, and less relevant to grammatical words like <span class="math notranslate nohighlight">\(the\)</span>.</p></li>
<li><p>Therefore, an effective Self-Attention layer should create the output vector of <span class="math notranslate nohighlight">\(walks\)</span> (i.e., the weighted sum) by assigning higher weights on these relevant tokens (as indicated by the widths of the arrows) and lower weights on those irrelevant tokens.</p></li>
</ul>
<ul class="simple">
<li><p>To simply put, the Self-Attention layer transforms each input vector into the output vector by taking into consideration how the input vector (Query) is connected to the rest of the input vectors (Keys).</p></li>
</ul>
</div>
<div class="section" id="sequence-model-with-attention">
<h2>Sequence Model with Attention<a class="headerlink" href="#sequence-model-with-attention" title="Permalink to this headline">¶</a></h2>
<div class="section" id="vanillar-encoder-decoder-model">
<h3>Vanillar Encoder-Decoder Model<a class="headerlink" href="#vanillar-encoder-decoder-model" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Attention arises as an effective mechanism for many-to-many sequence-to-sequence model.</p></li>
<li><p>A typical application is machine translation.</p></li>
<li><p>In the vanilla RNN Encoder-Decoder model, after the decoder processes the input sequences in all time steps, the decoder takes the output of the last time step from the encoder as the input for decoding.</p></li>
</ul>
<p><img alt="" src="../_images/seq2seq-vanilla-rnn.jpeg" /></p>
<ul class="simple">
<li><p>Two sequence models need to be trained: encoder and decoder:</p>
<ul>
<li><p>Encoder:</p>
<ul>
<li><p>A vanilla version of the seq-to-seq model takes the <strong>last</strong> return state <span class="math notranslate nohighlight">\(h_t\)</span> of the encoder as the initial and only input for the decoder</p></li>
<li><p>If the encoder uses the LSTM cell, the output of the encoder would be the last return state and the last memory cell, i.e., <span class="math notranslate nohighlight">\(h_t\)</span> and <span class="math notranslate nohighlight">\(c_t\)</span></p></li>
</ul>
</li>
<li><p>Decoder</p>
<ul>
<li><p>During the training stage, the decoder takes the previous return state <span class="math notranslate nohighlight">\(h_{t-1}\)</span> and the current <span class="math notranslate nohighlight">\(Y_t\)</span> as the input for the LSTM (concatenated). This is referred to as <strong>teacher forcing</strong>.</p></li>
<li><p>During the testing stage, the decoder would decode the output one at a time, taking the previous return state <span class="math notranslate nohighlight">\(h_{t-1}\)</span> and the previous return output <span class="math notranslate nohighlight">\(Y_{t-1}\)</span> as the inputs of the LSTM (concatenated). That is, no <strong>teacher-forcing</strong> during the testing stage.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="peeky-encoder-decoder-model">
<h3>Peeky Encoder-Decoder Model<a class="headerlink" href="#peeky-encoder-decoder-model" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="../_images/seq2seq-peeky.jpeg" /></p>
<ul class="simple">
<li><p>In the vanilla encoder-decoder model, decoder can only access the last hidden state from the encoder.</p></li>
<li><p>A variant of the seq-to-seq model is to makes available the last return state <span class="math notranslate nohighlight">\(h_{t}\)</span> from the encoder to every time step in the decoder.</p></li>
<li><p>An intuitive understanding of this <strong>peeky</strong> approach is that during the decoding stage (i.e., translation), the contexts from the source input should be made available to all decoding steps.</p></li>
</ul>
</div>
<div class="section" id="attention-based-encoder-decoder-model">
<h3>Attention-based Encoder-Decoder Model<a class="headerlink" href="#attention-based-encoder-decoder-model" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Compared to Peeky Encoder-Decoder Model, the Attention-based Encoder-Decoder Model goes one step further by allowing the decoder to access not only the hidden state of the last time step from encoder, but all the hidden states from the encoder.</p></li>
<li><p>This is where the Attention mechanism comes in.</p></li>
</ul>
<p><img alt="" src="../_images/seq2seq-enc-dec-attn.gif" /></p>
<ul class="simple">
<li><p>Attention mechansim can be seen as much more sophisticated design of the peeky approach.</p></li>
<li><p>The idea is that during the decoding stage, we need to consider the pairwise relationship (similarity) in-between the decoder state <span class="math notranslate nohighlight">\(h_{t}\)</span> and <strong>ALL</strong> the return states from the encoder.</p></li>
<li><p>An intuitive understanding is as follows. When decoding the translation of <span class="math notranslate nohighlight">\(Y_{1}\)</span>, it is very likely that its translation is more relevant to some of the input words and less relevant to the others.</p></li>
<li><p>Therefore, the Attention mechanism first needs to determine the relative pairwise relationship in-between the decoder <span class="math notranslate nohighlight">\(h_{1}\)</span> and all the encoder hidden states in order to generate the <strong>attention outputs</strong>.</p></li>
</ul>
<p><img alt="" src="../_images/seq2seq-attention-weights.jpeg" /></p>
<ul class="simple">
<li><p>There are many proposals regarding how to compute the attention weights.</p></li>
<li><p>In the current Tensorflow implementation, there are three types of <a class="reference external" href="https://keras.io/api/layers/attention_layers/">Attention layers</a>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Attention</span></code> Layer: Luong’s style attention (i.e., simple dot-product) <a class="reference external" href="https://arxiv.org/pdf/1508.4025.pdf">Luong2015</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">AdditiveAttention</span></code> Layer: Bahdanau’s style attention <a class="reference external" href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau2015</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MultiHeadAttention</span></code> Layer: transformer’s style attention <a class="reference external" href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">“Attention is All you Need” (Vaswani, et al., 2017)</a></p></li>
</ul>
</li>
<li><p>The <strong>Attention</strong> layer then will transform all the hidden states of the encoder into <strong>context vectors</strong>, indicating how the decoding step is relevant to all the input sequences.</p></li>
<li><p>These context vectors (from the Attention layer) can contribute to the decoding process (translation).</p></li>
</ul>
</div>
</div>
<div class="section" id="usage-of-attention-layer-in-keras">
<h2>Usage of Attention Layer in keras<a class="headerlink" href="#usage-of-attention-layer-in-keras" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>When defining the Attention layer, we need to specify the <strong>Query</strong> tensors and the <strong>Key</strong> tensors.</p></li>
<li><p>In Self-Attention layers, the Query is all the input vectors, and the Key is also the input vectors.</p></li>
<li><p>In Attention Layer in sequence-to-sequence model, the Query is the hidden state from the Decoder; the keys are all the input states from the Encoder.</p></li>
</ul>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Please see a very nice review of Lilian Weng’s <a class="reference external" href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">Attention? Attention!</a>.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./temp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="text-vec-embedding.html" title="previous page"><span class="section-number">3. </span>Word Embeddings</a>
    <a class='right-next' id="next-link" href="dl-seq-to-seq-attention-addition.html" title="next page">Sequence Model with Attention for Addition Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>