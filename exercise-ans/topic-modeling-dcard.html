
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Assignment X: Topic Modeling Dcard &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/google-colab.html">
     Google Colab
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   1. Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   2. Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   3. Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-sklearn-classification.html">
   1. Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/topic-modeling-naive.html">
   2. Topic Modeling: A Naive Example
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-network-from-scratch.html">
   Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-simple-case.html">
   Deep Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-sentiment-case.html">
   Deep Learning: Sentiment Analysis
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Embeddings and Language Model
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding.html">
   Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding-keras.html">
   Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-statistical-language-model.html">
   Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-sequence-models-intuition.html">
   Sequence Models Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-language-model-primer.html">
   Neural Language Model: A Start
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Seq2Seq, Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types.html">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-attention-addition.html">
   Seqeunce Model with Attention for Addition Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-keras.html">
   Text Classification with Transformer
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   Assignment III: Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-3-1.html">
     Student Sample 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-3-2.html">
     Student Sample 2
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   Assignment IV: Chinese Language Processing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-4-1.html">
     Student Sample 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-4-2.html">
     Student Sample 2
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   Assignment V: Text Vectorization
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-5-1.html">
     Student Sample 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-5-2.html">
     Student Sample 2
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/6-machine-learning.html">
   Assignment VI: Machine Learning
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/exercise-ans/topic-modeling-dcard.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/exercise-ans/topic-modeling-dcard.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/exercise-ans/topic-modeling-dcard.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-1">
   Question 1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-necessary-dependencies-and-settings">
   Import necessary dependencies and settings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-corpus-of-text-documents">
   Sample corpus of text documents
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bag-of-words-model">
   Bag of Words Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#latent-dirichlet-allocation">
   Latent Dirichlet Allocation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#show-topics-and-their-weights">
   Show topics and their weights
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clustering-documents-using-topic-model-features">
   Clustering documents using topic model features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grid-search-for-topic-number">
   Grid Search for Topic Number
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="assignment-x-topic-modeling-dcard">
<h1>Assignment X: Topic Modeling Dcard<a class="headerlink" href="#assignment-x-topic-modeling-dcard" title="Permalink to this headline">¶</a></h1>
<div class="section" id="question-1">
<h2>Question 1<a class="headerlink" href="#question-1" title="Permalink to this headline">¶</a></h2>
<p>Use the <code class="docutils literal notranslate"><span class="pre">dcard</span></code> dataset and perform topic modeling on the dataset to explore the main topics of this small corpus.
To increase the interpretability of the topic modeling results, please word segment the corpus data using <code class="docutils literal notranslate"><span class="pre">ckip-transformers</span></code> and then include word tokens whose POS are <code class="docutils literal notranslate"><span class="pre">Na</span></code> or <code class="docutils literal notranslate"><span class="pre">Vc</span></code> for topic modeling.</p>
</div>
<div class="section" id="import-necessary-dependencies-and-settings">
<h2>Import necessary dependencies and settings<a class="headerlink" href="#import-necessary-dependencies-and-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">nltk</span><span class="o">,</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">movie_reviews</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>

<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="mi">200</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-corpus-of-text-documents">
<h2>Sample corpus of text documents<a class="headerlink" href="#sample-corpus-of-text-documents" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../../../RepositoryData/data/dcard-top100.csv&#39;</span><span class="p">)</span>
<span class="n">corpus_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>235443715</td>
      <td>三更 21歲這年我差點被活活燒死</td>
      <td>部分回應在B117 \n謝謝各位的留言，我都有看完\n好的不好的，我都接受謝謝大家🙇‍♀️\n\n\n（第三次更新在這邊）\nB258 這邊也有講到怎麼逃生\n很多人好奇我是怎麼踹門的，\n在這邊跟大家說一下，\n因為這台車本來就很老舊，\n加上我文章說的我有停在路邊檢查，\n之前有在練空手道，所以比較知道怎麼施力😥\n謝謝大家的關心，其他比較有問題的我會在留言一一回覆！\n\n後續處理的...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>235442609</td>
      <td>超狂學經歷！195公分帥家教徵學生</td>
      <td>https://i.imgur.com/REIEzSd.jpg\n\n身高195公分的男大生楊承翰在家教社團PO文徵學生的文章被網友推爆了，網友們看到他的學經歷及成績不禁大讚根本就是學霸王，而他不只擁有高顏質，還是籃球系隊成員，超乎常人的學經歷及證書考試成績，瞬間讓網友都跪著朝聖，直呼「天哪好厲害的帥哥」、「這個當家教太可惜了」。\n\n21歲台大學生楊承翰日前在臉書社團「家教補教學校兼全...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>235441998</td>
      <td>我的模特界時間管理大師前男友</td>
      <td>看過這麼多在Dcard、PTT上的感情渣事和創作文\n從沒想過如此荒謬像八點檔的事情居然會發生在自己的身上\n\n本來以為與我交往一年的男友，是因為遠距離的關係分手，但就在我難過發文之後，我的IG私訊被各種匿名爆料塞爆，才發現交往一年的他幾乎是個我完全不認識的人（除了我被無數次劈腿，還有他幻謊症的部分，可能還有妄想症...）\n\n \n接下來的故事全部都是真真切切發生的事情，因為整段故事...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>235441259</td>
      <td>豆皮加爆</td>
      <td>剛剛吃小火鍋，跟店員說不要金針菇（怕卡牙縫），於是店員幫我換其他配料..…\n\n沒想到餐一上桌竟是豆皮加爆~\n\n真是超開心的~有人也跟我一樣喜歡吃豆皮的嗎？\n\nhttps://i.imgur.com/XIma4y2.jpg</td>
    </tr>
    <tr>
      <th>4</th>
      <td>235442693</td>
      <td>這樣女生該追嗎</td>
      <td>已經約好見面，到了當天晚上七點半才回，我是被耍了嗎 \n如下圖\n\n\nhttps://i.imgur.com/81HRQpQ.jpg\nhttps://i.imgur.com/6lmTX1P.jpg\nhttps://i.imgur.com/bV4X0Fz.jpg</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus_df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span>
<span class="c1"># remove url first</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(?:http(s)?:\/\/)?[\w.-]+(?:\.[\w\.-]+)+[\w\-\._~:/?#[\]@!\$&amp;</span><span class="se">\&#39;</span><span class="s1">\(\)\*\+,;=.]+&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">]</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">]</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">65</span><span class="p">,]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ID                                                                                    235443810
title                                                                                 優質cosplay
content    https://megapx-assets.dcard.tw/images/57a22cb7-3880-4e83-97a1-510a691bd1d9/1280.jpeg
Name: 65, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## check each doc integrity, i.e., no empty strings</span>

<span class="n">corpus_line_num</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">]</span>
<span class="n">corpus</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">corpus_line_num</span><span class="p">)]</span>

<span class="n">ind</span> <span class="o">=</span><span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus_line_num</span><span class="p">))</span> <span class="k">if</span> <span class="n">corpus_line_num</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">corpus</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([], dtype=&#39;&lt;U4276&#39;)
</pre></div>
</div>
</div>
</div>
<p>Perform the word segmentation in Google Colab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import ckip_transformers</span>
<span class="c1"># from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger</span>
<span class="c1"># # Initialize drivers</span>
<span class="c1"># ws_driver = CkipWordSegmenter(level=3, device=-1)</span>
<span class="c1"># pos_driver = CkipPosTagger(level=3, device=-1)</span>
<span class="c1"># import re</span>

<span class="c1"># def my_tokenizer(doc):</span>
<span class="c1">#     # `doc`: a list of corpus documents (each element is a document long string)</span>
<span class="c1">#     cur_ws = ws_driver(doc, use_delim = True, delim_set=&#39;\n&#39;)</span>
<span class="c1">#     cur_pos = pos_driver(cur_ws)</span>
<span class="c1">#     doc_seg = [[(x,y) for (x,y) in zip(w,p)]  for (w,p) in zip(cur_ws, cur_pos)]</span>
<span class="c1">#     #cur_words = [(w.strip(),p) for (w,p) in zip(sum(cur_ws,[]), sum(cur_pos,[])) if p not in [&#39;WHITESPACE&#39;]] # if re.match(r&#39;^[nv]&#39;,p[0].lower())]</span>
<span class="c1">#     return doc_seg</span>

<span class="c1"># # def my_tokenizer(doc):</span>
<span class="c1"># #     # `doc`: a list of sentences of a specific doc</span>
<span class="c1"># #     cur_ws = ws_driver(doc, use_delim = True, delim_set=&#39;\n&#39;)</span>
<span class="c1"># #     cur_pos = pos_driver(cur_ws)</span>
<span class="c1"># #     cur_words = [(w.strip(),p) for (w,p) in zip(sum(cur_ws,[]), sum(cur_pos,[])) if p not in [&#39;WHITESPACE&#39;]] # if re.match(r&#39;^[nv]&#39;,p[0].lower())]</span>
<span class="c1"># #     return cur_words</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%time</span>
<span class="c1">## Takes about 22 mins</span>
<span class="c1"># dcard_seg = my_tokenizer(corpus)</span>

<span class="c1"># with open(&#39;dcard_word_tag.pickle&#39;, &#39;wb&#39;) as f:</span>
<span class="c1">#     pickle.dump(dcard_word_tag, f, protocol=pickle.HIGHEST_PROTOCOL)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tokenization: 100%|██████████| 75/75 [00:00&lt;00:00, 27483.21it/s]
Inference: 100%|██████████| 1/1 [00:20&lt;00:00, 20.87s/it]
Tokenization: 100%|██████████| 75/75 [00:00&lt;00:00, 36586.74it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.75s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 10706.13it/s]
Inference: 100%|██████████| 1/1 [00:26&lt;00:00, 26.38s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 15082.00it/s]
Inference: 100%|██████████| 1/1 [00:24&lt;00:00, 24.04s/it]
Tokenization: 100%|██████████| 49/49 [00:00&lt;00:00, 9819.44it/s]
Inference: 100%|██████████| 1/1 [00:38&lt;00:00, 38.41s/it]
Tokenization: 100%|██████████| 49/49 [00:00&lt;00:00, 12557.80it/s]
Inference: 100%|██████████| 1/1 [00:27&lt;00:00, 27.86s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 12192.74it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.84it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 10347.79it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.86it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 7913.78it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.47it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 9532.51it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.42it/s]
Tokenization: 100%|██████████| 66/66 [00:00&lt;00:00, 28883.98it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.74s/it]
Tokenization: 100%|██████████| 66/66 [00:00&lt;00:00, 39478.62it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.07s/it]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 8224.13it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.63it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 3644.05it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.28it/s]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 12587.95it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.82it/s]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 4212.84it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.10it/s]
Tokenization: 100%|██████████| 13/13 [00:00&lt;00:00, 16453.21it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.50s/it]
Tokenization: 100%|██████████| 13/13 [00:00&lt;00:00, 17977.56it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.69s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 7713.66it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.12s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 12520.31it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.88s/it]
Tokenization: 100%|██████████| 82/82 [00:00&lt;00:00, 28851.01it/s]
Inference: 100%|██████████| 1/1 [00:16&lt;00:00, 16.19s/it]
Tokenization: 100%|██████████| 82/82 [00:00&lt;00:00, 36119.82it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.34s/it]
Tokenization: 100%|██████████| 79/79 [00:00&lt;00:00, 17748.68it/s]
Inference: 100%|██████████| 1/1 [00:16&lt;00:00, 16.17s/it]
Tokenization: 100%|██████████| 79/79 [00:00&lt;00:00, 28853.19it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.57s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 29654.30it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.04s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 21368.98it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.07s/it]
Tokenization: 100%|██████████| 14/14 [00:00&lt;00:00, 14509.58it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.80s/it]
Tokenization: 100%|██████████| 14/14 [00:00&lt;00:00, 14628.86it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.12s/it]
Tokenization: 100%|██████████| 44/44 [00:00&lt;00:00, 25301.53it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.41s/it]
Tokenization: 100%|██████████| 44/44 [00:00&lt;00:00, 34112.64it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.63s/it]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 16322.17it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.23s/it]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 24867.42it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.16s/it]
Tokenization: 100%|██████████| 18/18 [00:00&lt;00:00, 27275.10it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.60s/it]
Tokenization: 100%|██████████| 18/18 [00:00&lt;00:00, 28170.70it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.77s/it]
Tokenization: 100%|██████████| 111/111 [00:00&lt;00:00, 38299.42it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.57s/it]
Tokenization: 100%|██████████| 111/111 [00:00&lt;00:00, 47060.32it/s]
Inference: 100%|██████████| 1/1 [00:13&lt;00:00, 13.69s/it]
Tokenization: 100%|██████████| 40/40 [00:00&lt;00:00, 29449.21it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.85s/it]
Tokenization: 100%|██████████| 40/40 [00:00&lt;00:00, 32078.81it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.81s/it]
Tokenization: 100%|██████████| 42/42 [00:00&lt;00:00, 14558.74it/s]
Inference: 100%|██████████| 1/1 [00:14&lt;00:00, 14.15s/it]
Tokenization: 100%|██████████| 42/42 [00:00&lt;00:00, 16103.92it/s]
Inference: 100%|██████████| 1/1 [00:18&lt;00:00, 18.07s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 9700.70it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.80s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 28858.00it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.13s/it]
Tokenization: 100%|██████████| 36/36 [00:00&lt;00:00, 27584.02it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.48s/it]
Tokenization: 100%|██████████| 36/36 [00:00&lt;00:00, 31463.83it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.08s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 23096.39it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.06s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 18086.69it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.18s/it]
Tokenization: 100%|██████████| 27/27 [00:00&lt;00:00, 23831.27it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.34s/it]
Tokenization: 100%|██████████| 27/27 [00:00&lt;00:00, 23543.91it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.28s/it]
Tokenization: 100%|██████████| 37/37 [00:00&lt;00:00, 28883.17it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.80s/it]
Tokenization: 100%|██████████| 37/37 [00:00&lt;00:00, 24120.18it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.56s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 8380.99it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.19s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 19981.53it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.08s/it]
Tokenization: 100%|██████████| 29/29 [00:00&lt;00:00, 33297.24it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.84s/it]
Tokenization: 100%|██████████| 29/29 [00:00&lt;00:00, 34902.39it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.22s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 26284.81it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.86s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 31112.82it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.10s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 8816.86it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.79s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 6195.43it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.80s/it]
Tokenization: 100%|██████████| 50/50 [00:00&lt;00:00, 24862.50it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.32s/it]
Tokenization: 100%|██████████| 50/50 [00:00&lt;00:00, 30227.04it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.20s/it]
Tokenization: 100%|██████████| 38/38 [00:00&lt;00:00, 24156.34it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.51s/it]
Tokenization: 100%|██████████| 38/38 [00:00&lt;00:00, 29730.19it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.60s/it]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 3518.71it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.97it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 780.77it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.12it/s]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 6969.21it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.24s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 7365.97it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.65s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 3172.10it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.86s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 3754.13it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Inference: 100%|██████████| 1/1 [00:18&lt;00:00, 18.11s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 21500.06it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.16s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 18836.69it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.34s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 7182.03it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.33it/s]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 15550.92it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.32it/s]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 15598.01it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.56s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 18910.30it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.32s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 13452.86it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.71s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 14803.43it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.50s/it]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 24221.20it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.10it/s]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 6696.60it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.82it/s]
Tokenization: 100%|██████████| 85/85 [00:00&lt;00:00, 10142.99it/s]
Inference: 100%|██████████| 1/1 [01:31&lt;00:00, 91.49s/it]
Tokenization: 100%|██████████| 85/85 [00:00&lt;00:00, 12179.83it/s]
Inference: 100%|██████████| 2/2 [01:41&lt;00:00, 50.71s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 23354.77it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.76s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 28523.86it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.13s/it]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 4029.11it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.83it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 4877.10it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.53it/s]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 20726.57it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.00it/s]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 23757.64it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.10s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 8351.03it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.65it/s]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 15812.64it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.66it/s]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 27263.69it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.03s/it]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 33682.07it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.12s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 5351.24it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.26it/s]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 15313.27it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.27it/s]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 21549.44it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.55s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 25575.02it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.97s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 17655.77it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.87s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 22258.03it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.03s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 24488.00it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.25s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 29763.72it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.95s/it]
Tokenization: 100%|██████████| 74/74 [00:00&lt;00:00, 10790.14it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.40s/it]
Tokenization: 100%|██████████| 74/74 [00:00&lt;00:00, 49336.91it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.21s/it]
Tokenization: 100%|██████████| 26/26 [00:00&lt;00:00, 35417.96it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.48s/it]
Tokenization: 100%|██████████| 26/26 [00:00&lt;00:00, 31942.56it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.80s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 9868.95it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.88it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 11715.93it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.87it/s]
Tokenization: 100%|██████████| 32/32 [00:00&lt;00:00, 37553.93it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.61s/it]
Tokenization: 100%|██████████| 32/32 [00:00&lt;00:00, 41943.04it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.90s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 13943.83it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.09s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 20651.42it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.48s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 10775.62it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.28s/it]
Tokenization: 100%|██████████| 25/25 [00:00&lt;00:00, 21329.86it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.61s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 4129.01it/s]
Inference: 100%|██████████| 1/1 [00:38&lt;00:00, 38.60s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 4693.26it/s]
Inference: 100%|██████████| 1/1 [00:42&lt;00:00, 42.11s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 26567.25it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.42s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 23967.45it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.01it/s]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 8947.85it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.15it/s]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 9968.64it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.80it/s]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 9765.90it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.10s/it]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 11007.80it/s]
Inference: 100%|██████████| 1/1 [00:11&lt;00:00, 11.36s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 19986.47it/s]
Inference: 100%|██████████| 1/1 [00:19&lt;00:00, 19.11s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 21055.74it/s]
Inference: 100%|██████████| 1/1 [00:19&lt;00:00, 19.85s/it]
Tokenization: 100%|██████████| 57/57 [00:00&lt;00:00, 23760.22it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.93s/it]
Tokenization: 100%|██████████| 57/57 [00:00&lt;00:00, 11052.44it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.48s/it]
Tokenization: 100%|██████████| 34/34 [00:00&lt;00:00, 6206.75it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.36s/it]
Tokenization: 100%|██████████| 34/34 [00:00&lt;00:00, 35342.34it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.75s/it]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 12958.71it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.60s/it]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 12684.39it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.18s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 11366.68it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.50it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 14074.85it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.49it/s]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 26630.50it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.42s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 31163.35it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.45s/it]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 10951.19it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.22s/it]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 23753.14it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.70s/it]
Tokenization: 100%|██████████| 88/88 [00:00&lt;00:00, 49186.93it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.99s/it]
Tokenization: 100%|██████████| 88/88 [00:00&lt;00:00, 57554.77it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.71s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 18008.33it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.76s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 6766.00it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.65s/it]
Tokenization: 100%|██████████| 49/49 [00:00&lt;00:00, 27160.16it/s]
Inference: 100%|██████████| 1/1 [00:12&lt;00:00, 12.51s/it]
Tokenization: 100%|██████████| 49/49 [00:00&lt;00:00, 32032.56it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.29s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 23967.45it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.02it/s]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 11941.08it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.01it/s]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 20175.70it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.13it/s]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 19259.56it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.00it/s]
Tokenization: 100%|██████████| 50/50 [00:00&lt;00:00, 17630.53it/s]
Inference: 100%|██████████| 1/1 [00:24&lt;00:00, 24.08s/it]
Tokenization: 100%|██████████| 50/50 [00:00&lt;00:00, 25010.76it/s]
Inference: 100%|██████████| 1/1 [00:22&lt;00:00, 22.07s/it]
Tokenization: 100%|██████████| 41/41 [00:00&lt;00:00, 27889.47it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.88s/it]
Tokenization: 100%|██████████| 41/41 [00:00&lt;00:00, 36863.12it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.73s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 42581.77it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.90it/s]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 4779.15it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.98it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 3447.85it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.59it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 1966.39it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.40it/s]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 7672.51it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.12s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 2629.29it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.13s/it]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 17175.69it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.06it/s]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 12365.28it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.18it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 9425.40it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  7.38it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 1650.65it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  7.50it/s]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 7041.85it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.87s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 9310.33it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.02s/it]
Tokenization: 100%|██████████| 63/63 [00:00&lt;00:00, 24853.38it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.42s/it]
Tokenization: 100%|██████████| 63/63 [00:00&lt;00:00, 27356.99it/s]
Inference: 100%|██████████| 1/1 [00:11&lt;00:00, 11.09s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 21383.92it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.53s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 11939.86it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.64s/it]
Tokenization: 100%|██████████| 58/58 [00:00&lt;00:00, 28224.81it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.16s/it]
Tokenization: 100%|██████████| 58/58 [00:00&lt;00:00, 39723.98it/s]
Inference: 100%|██████████| 1/1 [00:15&lt;00:00, 15.94s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 5041.23it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.47s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 6919.87it/s]
Inference: 100%|██████████| 1/1 [00:13&lt;00:00, 13.97s/it]
Tokenization: 100%|██████████| 17/17 [00:00&lt;00:00, 17467.70it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.22s/it]
Tokenization: 100%|██████████| 17/17 [00:00&lt;00:00, 16667.41it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.17s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 10040.23it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.40s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 8989.40it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.34s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 27016.45it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.39s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 28032.11it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.60s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 12608.13it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.47it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 816.07it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.62it/s]
Tokenization: 100%|██████████| 17/17 [00:00&lt;00:00, 8956.56it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.34s/it]
Tokenization: 100%|██████████| 17/17 [00:00&lt;00:00, 21070.68it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.93s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 23373.83it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.14s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 20983.18it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.04s/it]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 16256.99it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.15it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 3992.67it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  4.28it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 1751.52it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.66it/s]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 7077.00it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.50it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 1582.76it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.26it/s]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 5683.34it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  3.17it/s]
Tokenization: 100%|██████████| 27/27 [00:00&lt;00:00, 19381.52it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.23s/it]
Tokenization: 100%|██████████| 27/27 [00:00&lt;00:00, 12140.46it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.54s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 3953.16it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.41s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 2131.25it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.08s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 17559.89it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.25s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 10902.39it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.07s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 12121.10it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.02s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 18961.59it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.71s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 15559.16it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.37s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 8139.76it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.03it/s]
Tokenization: 100%|██████████| 31/31 [00:00&lt;00:00, 7794.70it/s]
Inference: 100%|██████████| 1/1 [00:19&lt;00:00, 19.74s/it]
Tokenization: 100%|██████████| 31/31 [00:00&lt;00:00, 11859.12it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.43s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 5031.15it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.72s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 9418.35it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.74s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 21min 4s, sys: 20.9 s, total: 21min 25s
Wall time: 22min
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;dcard_seg.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">dcard_seg</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## From each document, keep only words tagged as N*</span>
<span class="n">norm_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Na&#39;</span><span class="p">,</span><span class="s1">&#39;VC&#39;</span><span class="p">]])</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">dcard_seg</span><span class="p">]</span><span class="c1"># if len(doc)&gt;0]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dcard_seg</span><span class="p">[</span><span class="mi">65</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;\n&#39;, &#39;WHITESPACE&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check any zero documents</span>
<span class="p">[(</span><span class="n">i</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(65, &#39;&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">norm_corpus</span><span class="p">[</span><span class="mi">65</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">65</span><span class="p">,]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ID                                                                                    235443810
title                                                                                 優質cosplay
content    https://megapx-assets.dcard.tw/images/57a22cb7-3880-4e83-97a1-510a691bd1d9/1280.jpeg
Name: 65, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df2</span> <span class="o">=</span> <span class="n">corpus_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">65</span><span class="p">])</span>
<span class="k">del</span> <span class="n">norm_corpus</span><span class="p">[</span><span class="mi">65</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>235443715</td>
      <td>三更 21歲這年我差點被活活燒死</td>
      <td>部分回應在B117 \n謝謝各位的留言，我都有看完\n好的不好的，我都接受謝謝大家🙇‍♀️\n\n\n（第三次更新在這邊）\nB258 這邊也有講到怎麼逃生\n很多人好奇我是怎麼踹門的，\n在這邊跟大家說一下，\n因為這台車本來就很老舊，\n加上我文章說的我有停在路邊檢查，\n之前有在練空手道，所以比較知道怎麼施力😥\n謝謝大家的關心，其他比較有問題的我會在留言一一回覆！\n\n後續處理的...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>235442609</td>
      <td>超狂學經歷！195公分帥家教徵學生</td>
      <td>https://i.imgur.com/REIEzSd.jpg\n\n身高195公分的男大生楊承翰在家教社團PO文徵學生的文章被網友推爆了，網友們看到他的學經歷及成績不禁大讚根本就是學霸王，而他不只擁有高顏質，還是籃球系隊成員，超乎常人的學經歷及證書考試成績，瞬間讓網友都跪著朝聖，直呼「天哪好厲害的帥哥」、「這個當家教太可惜了」。\n\n21歲台大學生楊承翰日前在臉書社團「家教補教學校兼全...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>235441998</td>
      <td>我的模特界時間管理大師前男友</td>
      <td>看過這麼多在Dcard、PTT上的感情渣事和創作文\n從沒想過如此荒謬像八點檔的事情居然會發生在自己的身上\n\n本來以為與我交往一年的男友，是因為遠距離的關係分手，但就在我難過發文之後，我的IG私訊被各種匿名爆料塞爆，才發現交往一年的他幾乎是個我完全不認識的人（除了我被無數次劈腿，還有他幻謊症的部分，可能還有妄想症...）\n\n \n接下來的故事全部都是真真切切發生的事情，因為整段故事...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>235441259</td>
      <td>豆皮加爆</td>
      <td>剛剛吃小火鍋，跟店員說不要金針菇（怕卡牙縫），於是店員幫我換其他配料..…\n\n沒想到餐一上桌竟是豆皮加爆~\n\n真是超開心的~有人也跟我一樣喜歡吃豆皮的嗎？\n\nhttps://i.imgur.com/XIma4y2.jpg</td>
    </tr>
    <tr>
      <th>4</th>
      <td>235442693</td>
      <td>這樣女生該追嗎</td>
      <td>已經約好見面，到了當天晚上七點半才回，我是被耍了嗎 \n如下圖\n\n\nhttps://i.imgur.com/81HRQpQ.jpg\nhttps://i.imgur.com/6lmTX1P.jpg\nhttps://i.imgur.com/bV4X0Fz.jpg</td>
    </tr>
    <tr>
      <th>5</th>
      <td>235441122</td>
      <td>深夜被約砲哥開導4小時哭了</td>
      <td>嗨！巨砲哥 答應你的文來了😆\n這是一段與約砲小哥哥談心的奇幻旅程\n\n可憐的我情人節當天被前男友提分手\n原本說好228連假要一起出去玩直接泡湯\n昨天晚上一整個很鬱卒 \n但又不想一直丟負能量給身邊朋友\n所以就上wootalk找人聊聊\n結果就遇到這個傳說中的暖男(?)巨砲哥\nhttps://i.imgur.com/nlzrqS3.jpg\n\n劈頭就問胸部多大⋯\n本來想按離開...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>235442321</td>
      <td>這樣真很暴露？？？</td>
      <td>https://i.imgur.com/HCTwyAH.jpg\n（圖片非本人）\n今天逛街買了一件此類型的白色，但他有點透，所以裡面有配一件白色小可愛，但男友說還是太暴露！？想問各位男性朋友 可以接受女友穿這件衣服嗎？🤔</td>
    </tr>
    <tr>
      <th>7</th>
      <td>235442924</td>
      <td>泳衣+裙會很怪嗎</td>
      <td>https://i.imgur.com/RWJLK2v.jpg\n\n因為馬鞍很寬\n想請問女孩們會覺得加這種裙式沙龍好嗎？\n怕會不會很奇怪\n看模特兒穿又覺得蠻好看的\n怕實際穿出去會怪怪的</td>
    </tr>
    <tr>
      <th>8</th>
      <td>235441419</td>
      <td>關於一個860的訂製蛋糕：）</td>
      <td>手機排版請見諒😖🙏🏻（圖多）\n先說這不是我第一次訂購訂製蛋糕\n也了解訂製蛋糕不可能跟圖上一樣完美\n看到這間的ig上照片都很漂亮才選擇這間的\n\nhttps://i.imgur.com/fETTnah.jpg\n這張是訂購時給的參考圖\n\nhttps://i.imgur.com/XsBjPYR.jpg\n這張是我拿到後打開的樣子\n\n以下附上對話記錄\nhttps://i.img...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>235440762</td>
      <td>有女生提醒我男友吃早餐</td>
      <td>https://i.imgur.com/6Yk9etg.jpg\n想在這裡問大家有沒有接到這種電話⋯\n我男友前幾個月有接到一次，電話內容就只有女生用嗲嗲的聲音提醒我男友吃早餐這樣而已。電話掛了之後男友也有跟我說是他不認識的。\n\n但因為自己心裡存有懷疑，隔天在上班的時候有叫男同事用我手機打過去問（男友有給我她的手機號碼截圖\n\n男同事一開始就問她是不是那位提醒自己吃早餐的那個女生，後...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">corpus_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corpus_df2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 3)
(99, 3)
99
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_df2</span><span class="p">[</span><span class="s1">&#39;Normalized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm_corpus</span>
<span class="n">corpus_df2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>title</th>
      <th>content</th>
      <th>Normalized</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>235443715</td>
      <td>三更 21歲這年我差點被活活燒死</td>
      <td>部分回應在B117 \n謝謝各位的留言，我都有看完\n好的不好的，我都接受謝謝大家🙇‍♀️\n\n\n（第三次更新在這邊）\nB258 這邊也有講到怎麼逃生\n很多人好奇我是怎麼踹門的，\n在這邊跟大家說一下，\n因為這台車本來就很老舊，\n加上我文章說的我有停在路邊檢查，\n之前有在練空手道，所以比較知道怎麼施力😥\n謝謝大家的關心，其他比較有問題的我會在留言一一回覆！\n\n後續處理的...</td>
      <td>回應 留言 看完 接受 更新 人 踹 門 車 文章 路 練 空手道 問題 留言 車 車 地方 平台 訂 車 平台 家人 平台 聯繫 開 事故 會議 平台 律師 態度 錢 談話 燒壞 東西 浩劫 接受 人命 平台 律師 上訴 車子 鑑定 鑑定完 正文 朋友們 吃 燒烤 車 高鐵 開 車 人 車 平台 車 服務 車 資料 取 車 時候 老闆 派錯 人手 搭 計程車 牽 車 按 計程車 證明聯 ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>235442609</td>
      <td>超狂學經歷！195公分帥家教徵學生</td>
      <td>https://i.imgur.com/REIEzSd.jpg\n\n身高195公分的男大生楊承翰在家教社團PO文徵學生的文章被網友推爆了，網友們看到他的學經歷及成績不禁大讚根本就是學霸王，而他不只擁有高顏質，還是籃球系隊成員，超乎常人的學經歷及證書考試成績，瞬間讓網友都跪著朝聖，直呼「天哪好厲害的帥哥」、「這個當家教太可惜了」。\n\n21歲台大學生楊承翰日前在臉書社團「家教補教學校兼全...</td>
      <td>身高 男 大生 家教 社團 徵 學生 文章 網友 推爆 網友 們 學經歷 成績 學霸王 顏質 籃球 系隊 成員 常人 學經歷 證書 考試 成績 網友 天 帥哥 家教 學生 臉書 社團 家教 補教 師訓 時薪 找 家教 學生 內容 英文 數學 理化 程式 語言 範圍 接受 貼文 學經歷 學歷 大三 主修 資工 數學 實驗 醫學 研究生 新冠 專案 訪問生 中英文 經驗 對 家教 經驗 學生 ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>235441998</td>
      <td>我的模特界時間管理大師前男友</td>
      <td>看過這麼多在Dcard、PTT上的感情渣事和創作文\n從沒想過如此荒謬像八點檔的事情居然會發生在自己的身上\n\n本來以為與我交往一年的男友，是因為遠距離的關係分手，但就在我難過發文之後，我的IG私訊被各種匿名爆料塞爆，才發現交往一年的他幾乎是個我完全不認識的人（除了我被無數次劈腿，還有他幻謊症的部分，可能還有妄想症...）\n\n \n接下來的故事全部都是真真切切發生的事情，因為整段故事...</td>
      <td>看過 感情 渣事 創作 文 八點檔 事情 身 男友 距離 關係 私訊 塞爆 人 幻謊症 故事 事情 故事 牽扯 人 故事 講起 故事 時間 管理 大師 男友 女 主角 加我 背景 距離 期間 疫情 時間 距離 時間 整體 形象 外表 紳士 拍 廣告 機票 廠商 包 邀請 找 攝影師 大哥 房 訂 牽 手 關係 心理 建設 鼓起 勇氣 附 手機 照片 時間 地點 月 疫情 月 時間 態度 月...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>235441259</td>
      <td>豆皮加爆</td>
      <td>剛剛吃小火鍋，跟店員說不要金針菇（怕卡牙縫），於是店員幫我換其他配料..…\n\n沒想到餐一上桌竟是豆皮加爆~\n\n真是超開心的~有人也跟我一樣喜歡吃豆皮的嗎？\n\nhttps://i.imgur.com/XIma4y2.jpg</td>
      <td>吃 火鍋 店員 要 金針菇 卡 店員 換 配料 餐 豆皮 加 人 吃 豆皮</td>
    </tr>
    <tr>
      <th>4</th>
      <td>235442693</td>
      <td>這樣女生該追嗎</td>
      <td>已經約好見面，到了當天晚上七點半才回，我是被耍了嗎 \n如下圖\n\n\nhttps://i.imgur.com/81HRQpQ.jpg\nhttps://i.imgur.com/6lmTX1P.jpg\nhttps://i.imgur.com/bV4X0Fz.jpg</td>
      <td>耍</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>235444562</td>
      <td>主題：💟愛情塔羅💟 他要的感情關係vs 我要的感情關係為何？兩個人的近期發展（曖昧/交往中/斷聯/復合）</td>
      <td>🤗感謝我們之間的連結帶領你來到這裡！ \n\n主題：💟愛情塔羅💟 他要的感情關係vs 我要的感情關係為何？兩個人的近期發展（曖昧/交往中/斷聯/復合）\n\n本次的大眾占卜適合處在曖昧、交往中、剛斷聯、分手、期待的你，有時候一份感情的重要核心正是在於雙方要的是不是一樣的東西，不見得得要完全相同，但至少如果理解彼此的感情需求，在相處上也能夠更融洽嘍！\n\n⭐️請閉上眼睛，深呼吸，腦子專心裡...</td>
      <td>連結 主題 愛情 要 感情 關係 要 感情 關係 人 發展 感情 核心 要 東西 感情 需求 閉上 眼睛 腦子 要 感情 關係 要 樣子 人 點滴 張開 眼睛 牌卡 選出 連結 選 牌卡 天使 看 連結 天使 天使 天使 天使 天使 選 感覺 牌 找到 文字 解答 影片 解答 參考 影片 視頻 時間軸 選 牌 天使 天使 天使 天使 天使 文字 解答 祝福</td>
    </tr>
    <tr>
      <th>96</th>
      <td>235441027</td>
      <td>#分享 老花古董包 LV 方盒子｜Celine 化妝箱</td>
      <td>近期購入的兩款古董包 可能因為是新歡 所以都讓我愛不釋手(๑•̀ •́)و✧\n不過正是古董包的緣故 包況總有些不盡理想的狀況 帶有小瑕疵的部分 我自己都可以接受\n為了比較包包的容量 文內有帶到一小部分的what’s in my bag 也有實揹照的部分*ˊᵕˋ\n\n\n\n𓎘𓎘𓎘 Louis Vuitton monogram 開口笑方盒子\n（名字是參考小紅書介紹）\n\n購入價格：...</td>
      <td>購入 古董包 新歡 古董包 緣故 包況 狀況 瑕疵 接受 比較 包包 容量 文 帶到 實 揹照 笑 方盒子 名字 參考 書 購入 價格 購入 方式 尺寸 容量 暗層 單肩包 媽媽 生日 禮物 藏 看 購入 媽媽 留 用 容量 物品 帶 保溫瓶 放入 保溫瓶 放入 小說 照片 拍 照片 參考 個子 身形 暗層 放 面紙 放 口紅 護唇膏 拉鍊 夾層 放 悠遊卡 化妝箱 購入 價格 購入 方式...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>235447320</td>
      <td>在公車上遇到的超尷尬事件</td>
      <td>剛剛在公車上有一個阿伯下車前跟我說：妹妹你很有愛心欸 讓位置給別人 不像有些人都在裝睡\n講完這句話還瞄了一眼旁邊的女生\n我當下就笑笑的\n可是阿伯\n那個女生\n-\n-\n-\n是我朋友(^_^;)\n幸好阿伯講完就下車了⋯\nhttps://i.imgur.com/htuMwVw.jpg</td>
      <td>公車 阿伯 妹妹 愛心 位置 人 講完 話 瞄 女生 阿伯 女生 朋友 阿伯 講完</td>
    </tr>
    <tr>
      <th>98</th>
      <td>235440749</td>
      <td>#大眾占卜 🥺。他現在對我的想法是?他的下一步是什麼?我能為這段關係做什麼樣的努力❣</td>
      <td>大家好這裡是金魚🙏\n這次的占卜適合斷聯、曖昧、復合的族群\n\n再上圖之前先置入我的IG\nhttps://www.instagram.com/goldenfishtarot\n\n【大眾占卜集合多人能量請選擇有感應的部分聆聽即可】\n喜歡有聲版請點連結\n喜歡文字下面附上文案\nhttps://youtu.be/xkJHmyl_M7g\n\nhttps://i.imgur.com/Ux...</td>
      <td>金魚 族群 圖 置入 人 能量 選擇 感應 聆聽 點 連結 文字 附上 文案 對象 感情 騙 錢 關 遇見 心房 打開 過程 愛 感情 家庭 熱情 感染力 感情 方式 樣子 帶來 副作用 圍繞 生活 面對 事 心 關卡 捲進 麻煩 感情 選 資本 做 距離 個性 面對 生活 關卡 打出 安全牌 冒 風險 突破 現實 條件 做 切斷 後路 做出 抉擇 理性 配合 內心 想法 做出 行動 關係...</td>
    </tr>
    <tr>
      <th>99</th>
      <td>235442177</td>
      <td>所以，你要當我女朋友嗎？</td>
      <td>「所以，你要當我女朋友嗎？」我看進她的眼睛，隱約反射出自己的倒影。躺在床上的我們呼吸有些紊亂，午後的陽光肆無忌憚的灑在身上，有點溫暖。\n\n我們的故事，從英國開始。\n\n\n大學畢業後我跑到英國念碩士，人生地不熟的地方，一個認識的人也沒有，頭幾週的生活常常是一個人吃飯、逛街、看劇度過，再加上那時還沒走出前女友劈腿的陰影，那段時間說實在還滿煎熬的。\n\n幸好後來認識了跟我住在同個宿舍的...</td>
      <td>女朋友 眼睛 反射出 倒影 床 呼吸 陽光 灑 身 故事 念 碩士 地方 人 生活 人 看劇 加上 女友 陰影 時間 煎熬 台灣人 朋友 人脈 所有人 台灣人 福 交到 朋友 女孩 人 開 火鍋趴 參加 籃球 校隊 比賽 時間 延長賽 手機 訊息 傳來 通知 比賽 煮 人 等 露出 眼睛 掃 恩 人 等 煮 氣氛 熱氣 火鍋 生面孔 加上 愧疚感 印象 頭髮 眼睛 印象 大王 飯 交換 聯...</td>
    </tr>
  </tbody>
</table>
<p>99 rows × 4 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## check `norm_corpus`</span>
<span class="nb">len</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">norm_corpus</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;日系 妝容 剪 頭髮 換 髮型 頭髮 打 日系 感覺 妝容 剪 頭髮 興趣 妝 附上 素顏 封面 妝容 剪完 髮 私心 大愛 橘色 妝容 整體 眼線筆 睫毛膏 選擇 顏色 附上 彩妝品 眼妝 眼影 打底色 膏體 腮紅 做 腮紅 眼睛 手 上 眼影 發色 微飛粉 沾取 量 艾杜紗 眼線筆 眼線 膠筆 鉛 丹橘 芯 畫 手 感覺 妝 更新 持久性 艾杜紗 睫毛 底膏 粉色 擦 感覺 作用 上 睫毛膏 艾杜紗 艾 潤唇蜜 嘴 自然感 橘 裸色 畫 唇型 疊加 眼妝 眼影 塗 眼窩 塗 雙眼皮 折 疊擦 眼 疊擦 眼影 塗滿 眼下 疊加 亮橘 眼妝 完成 紫粉色 基底 整體 人 附上 彩妝品 眼妝 眼影 組合 攜帶型 眼影 排 眼影 單色 眼影 閃片 擦 拿來 打亮 眼頭 金 混 白色 珠光 金色 亮片 推 新手 買 塗 打 底色 手 眼皮 妝感 眼線 阻力 經典 眼線 眼線液 眼線筆 用 拿 畫 眼線 眼妝 秘密 棕色 眼 黑色 咖啡 腮紅 小花 腮紅 紫羅蘭 小花 腮紅 發色 用 口紅 細白管 玫瑰色 粉顏 色調 眼妝 眼影 塗 眼窩 塗 雙眼皮 折中 刷子 沾取 打 眼下 加強 眼皮 閃度 疊 眼影 塗 地方 疊擦 眼妝 刷子 完成 日系 妝容 問題 留言 觀看 妝容 實拍 影片 髮型&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bag-of-words-model">
<h2>Bag of Words Model<a class="headerlink" href="#bag-of-words-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Bag-of-words model is the simplest way to vectorize texts into numeric representations.</p></li>
<li><p>In short, it is a method to represent a text using its word frequency list.</p></li>
<li><p>The sequential order of words in the text is therefore naively ignored.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="c1"># get bag of words features in sparse format</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">token_pattern</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;[^\s0-9]+&#39;</span><span class="p">)</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;99x718 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 2789 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view dense representation </span>
<span class="c1"># warning might give a memory error if data is too big</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">cv_matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 1],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 1, 0],
       [0, 0, 0, ..., 0, 0, 0]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get all unique words in the corpus</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="c1"># show document feature vectors</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>上</th>
      <th>上衣</th>
      <th>上身</th>
      <th>下</th>
      <th>下午茶</th>
      <th>下載</th>
      <th>丟</th>
      <th>中文</th>
      <th>中餐</th>
      <th>主人</th>
      <th>...</th>
      <th>騙</th>
      <th>體重</th>
      <th>魅力</th>
      <th>魚</th>
      <th>鳥</th>
      <th>黃色</th>
      <th>黑</th>
      <th>黑色</th>
      <th>點</th>
      <th>鼓起</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>99 rows × 718 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="latent-dirichlet-allocation">
<h2>Latent Dirichlet Allocation<a class="headerlink" href="#latent-dirichlet-allocation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_of_topic</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>


<span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_of_topic</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                               <span class="n">max_doc_update_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;online&#39;</span><span class="p">,</span>
                               <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">learning_offset</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dt_matrix</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span> <span class="c1"># document matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 10.7 s, sys: 918 ms, total: 11.6 s
Wall time: 24.2 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dt_matrix</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_of_topic</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>T1</th>
      <th>T2</th>
      <th>T3</th>
      <th>T4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.43273</td>
      <td>0.00284</td>
      <td>0.00282</td>
      <td>0.56162</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.15363</td>
      <td>0.00484</td>
      <td>0.00455</td>
      <td>0.83698</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00134</td>
      <td>0.00133</td>
      <td>0.00133</td>
      <td>0.99600</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.02217</td>
      <td>0.02104</td>
      <td>0.02272</td>
      <td>0.93407</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.25000</td>
      <td>0.25000</td>
      <td>0.25000</td>
      <td>0.25000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>0.00469</td>
      <td>0.00481</td>
      <td>0.00463</td>
      <td>0.98587</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0.98663</td>
      <td>0.00441</td>
      <td>0.00445</td>
      <td>0.00451</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0.02550</td>
      <td>0.02528</td>
      <td>0.02518</td>
      <td>0.92404</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0.00208</td>
      <td>0.00212</td>
      <td>0.00208</td>
      <td>0.99372</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0.00489</td>
      <td>0.00484</td>
      <td>0.00499</td>
      <td>0.98528</td>
    </tr>
  </tbody>
</table>
<p>99 rows × 4 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="show-topics-and-their-weights">
<h2>Show topics and their weights<a class="headerlink" href="#show-topics-and-their-weights" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tt_matrix = lda.components_ # topic matrix</span>
<span class="c1"># for topic_weights in tt_matrix:</span>
<span class="c1">#     topic = [(token, weight) for token, weight in zip(vocab, topic_weights)]</span>
<span class="c1">#     topic = sorted(topic, key=lambda x: -x[1])</span>
<span class="c1">#     topic = [item for item in topic if item[1] &gt; 0.6]</span>
<span class="c1">#     print(topic)</span>
<span class="c1">#     print()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topic_terms</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">components_</span>
<span class="n">top_terms</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">topic_keywords_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">topic_terms</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,:</span><span class="n">top_terms</span><span class="p">]</span>
<span class="n">topic_keywords</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">topic_keywords_idxs</span><span class="p">]</span>
<span class="n">topics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">topic_keywords</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">topics_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">topics</span><span class="p">,</span>
                        <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Keywords per Topic&#39;</span><span class="p">],</span>
                        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Topic&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_of_topic</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topics_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Keywords per Topic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Topic1</th>
      <td>買, 穿, 穿搭, 衣服, 包包, 放, 洋裝, 吃, 看, 搭, 時候, 鞋子, 白色, 背心, 用, 東西, 搭配, 購入, 黑色, 車</td>
    </tr>
    <tr>
      <th>Topic2</th>
      <td>舞台, 人, 影片, 們, 歌, 看, 粉絲, 文章, 節目, 主打, 附上, 寶寶, 推, 看看, 時候, 孩子, 朋友, 微博, 歌曲, 推特</td>
    </tr>
    <tr>
      <th>Topic3</th>
      <td>眼影, 用, 人, 顏色, 腮紅, 唇膏, 粉底液, 妝容, 眼妝, 感覺, 畫, 粉底, 擦, 底妝, 唇釉, 質地, 妝感, 塗, 手, 頭髮</td>
    </tr>
    <tr>
      <th>Topic4</th>
      <td>人, 時候, 看, 吃, 男友, 朋友, 感情, 時間, 事, 蛋糕, 關係, 電話, 做, 月, 故事, 找, 工作, 女生, 事情, 問題</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:,.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>


<span class="n">dt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dt_matrix</span><span class="p">,</span>
                    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Topic&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_of_topic</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>

<span class="n">max_contrib_topics</span> <span class="o">=</span> <span class="n">dt_df</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dominant_topics</span> <span class="o">=</span> <span class="n">max_contrib_topics</span><span class="o">.</span><span class="n">index</span>
<span class="n">contrib_perc</span> <span class="o">=</span> <span class="n">max_contrib_topics</span><span class="o">.</span><span class="n">values</span>
<span class="n">document_numbers</span> <span class="o">=</span> <span class="p">[</span><span class="n">dt_df</span><span class="p">[</span><span class="n">dt_df</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">==</span><span class="n">max_contrib_topics</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">dominant_topics</span><span class="p">]</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">norm_corpus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">document_numbers</span><span class="p">]</span>

<span class="n">documents_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Dominant Topic&#39;</span><span class="p">:</span> <span class="n">dominant_topics</span><span class="p">,</span>
                            <span class="s1">&#39;Contribution%&#39;</span><span class="p">:</span> <span class="n">contrib_perc</span><span class="p">,</span>
                            <span class="s1">&#39;DOCID&#39;</span><span class="p">:</span> <span class="n">document_numbers</span><span class="p">,</span>
                            <span class="s1">&#39;Topic&#39;</span><span class="p">:</span> <span class="n">topics_df</span><span class="p">[</span><span class="s1">&#39;Keywords per Topic&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;Text&#39;</span><span class="p">:</span> <span class="n">documents</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">documents_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dominant Topic</th>
      <th>Contribution%</th>
      <th>DOCID</th>
      <th>Topic</th>
      <th>Text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Topic1</th>
      <td>Topic1</td>
      <td>0.99348</td>
      <td>71</td>
      <td>買, 穿, 穿搭, 衣服, 包包, 放, 洋裝, 吃, 看, 搭, 時候, 鞋子, 白色, 背心, 用, 東西, 搭配, 購入, 黑色, 車</td>
      <td>穿搭 放 主題 穿搭 問題 建議 留言 大地 色系 路線 洋裝 搭配 腰帶 比例 帽子 包包 選用 奶茶色 提高 整體 色彩 一致性 配 咖啡色 馬丁鞋 完成 買 洋裝 故事 話 古著 洋裝 衣服 小姐 店家 看 看 拿起 洋裝 試穿 帶回 錢包 領 友人 友人 打開 錢包 店員 姊姊 帶走 吃 大餐 現金 留 衣服 穿搭 資訊 帽子 洋裝 包包 鞋子 女孩 路線 整體 色系 暗色 黑色 ...</td>
    </tr>
    <tr>
      <th>Topic2</th>
      <td>Topic2</td>
      <td>0.97997</td>
      <td>84</td>
      <td>舞台, 人, 影片, 們, 歌, 看, 粉絲, 文章, 節目, 主打, 附上, 寶寶, 推, 看看, 時候, 孩子, 朋友, 微博, 歌曲, 推特</td>
      <td>歌 團體 挑出 非 主打 粉絲 發 文章 女團 推 推 歌 麒麟 椰澀 場面 歌 治癒 人心 粉墨 主打 孩子 們 歌 聲音 偏題 推薦 非 主打 孩子 們 孩子 們 特色 女友 歌 商演 唱 歌 音響 高音 主唱 歌 印象 歌曲 夢想 補 文 神仙 主打 主打 光 頂跨 打 歌舞台 看 到</td>
    </tr>
    <tr>
      <th>Topic3</th>
      <td>Topic3</td>
      <td>0.99350</td>
      <td>10</td>
      <td>眼影, 用, 人, 顏色, 腮紅, 唇膏, 粉底液, 妝容, 眼妝, 感覺, 畫, 粉底, 擦, 底妝, 唇釉, 質地, 妝感, 塗, 手, 頭髮</td>
      <td>日系 妝容 剪 頭髮 換 髮型 頭髮 打 日系 感覺 妝容 剪 頭髮 興趣 妝 附上 素顏 封面 妝容 剪完 髮 私心 大愛 橘色 妝容 整體 眼線筆 睫毛膏 選擇 顏色 附上 彩妝品 眼妝 眼影 打底色 膏體 腮紅 做 腮紅 眼睛 手 上 眼影 發色 微飛粉 沾取 量 艾杜紗 眼線筆 眼線 膠筆 鉛 丹橘 芯 畫 手 感覺 妝 更新 持久性 艾杜紗 睫毛 底膏 粉色 擦 感覺 作用 上 ...</td>
    </tr>
    <tr>
      <th>Topic4</th>
      <td>Topic4</td>
      <td>0.99731</td>
      <td>39</td>
      <td>人, 時候, 看, 吃, 男友, 朋友, 感情, 時間, 事, 蛋糕, 關係, 電話, 做, 月, 故事, 找, 工作, 女生, 事情, 問題</td>
      <td>故事 發文 版 規則 刪除 戀情 遇上 情緒 男子 感情 解脫 時候 放 鞭炮 心情 新 時代 女性 地方 生活 挑戰 待 遊子 們 人 時候 情緒 放大 吃到 台牌 泡麵 時候 戀情 放 長假 社會 異性 機會 時間 異性 打開 軟體 對話 男子 互換 讀 研究生 經營 頻道 追蹤 人數 人 朋友 心態 看 菜 對話 簽證 月 約 釋出 意思 網路 吃 晚餐 中文 程 中文 過程 離開 ...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyLDAvis</span>
<span class="kn">import</span> <span class="nn">pyLDAvis.sklearn</span>
<span class="kn">import</span> <span class="nn">dill</span>
<span class="c1">#import warnings</span>

<span class="c1">#warnings.filterwanrings(&#39;ignore&#39;)</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">enable_notebook</span><span class="p">()</span>
<span class="n">cv_matrix2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">cv_matrix2</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">mds</span><span class="o">=</span><span class="s2">&quot;mmds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css">


<div id="ldavis_el680751404088344607924370080306"></div>
<script type="text/javascript">

var ldavis_el680751404088344607924370080306_data = {"mdsDat": {"x": [0.08489639099217597, 0.15058542075902423, -0.12177784017802251, -0.1137039715731777], "y": [-0.15407038800318965, 0.12287987781895612, 0.12466313188666993, -0.09347262170243639], "topics": [1, 2, 3, 4], "cluster": [1, 1, 1, 1], "Freq": [61.1742290142291, 19.94002358738104, 12.128302915382603, 6.75744448300727]}, "tinfo": {"Term": ["\u4eba", "\u8cb7", "\u5f71\u7247", "\u5011", "\u7a7f", "\u7a7f\u642d", "\u8863\u670d", "\u5305\u5305", "\u770b", "\u7528", "\u821e\u53f0", "\u773c\u5f71", "\u984f\u8272", "\u611f\u89ba", "\u9644\u4e0a", "\u6587\u7ae0", "\u6d0b\u88dd", "\u816e\u7d05", "\u6b4c", "\u5507\u818f", "\u7c89\u7d72", "\u653e", "\u7c89\u5e95\u6db2", "\u599d\u5bb9", "\u773c\u599d", "\u756b", "\u642d", "\u6642\u5019", "\u610f\u601d", "\u5b69\u5b50", "\u611f\u60c5", "\u86cb\u7cd5", "\u95dc\u4fc2", "\u96fb\u8a71", "\u627e", "\u5de5\u4f5c", "\u8c93", "\u5c0d\u8c61", "\u7537", "\u8349\u8393", "\u8001\u5e2b", "\u8a0a\u606f", "\u6210\u54e1", "\u966a", "\u9a19", "\u614b\u5ea6", "\u958b", "\u5b78\u59b9", "\u8981", "\u751f\u6d3b", "\u990a", "\u9322", "\u540c\u4e8b", "\u5bb6\u4eba", "\u624b\u6a5f", "\u5c0f\u5b69", "\u5e8a", "\u5abd", "\u96e2\u958b", "\u6ab8\u6aac", "\u7537\u53cb", "\u6708", "\u4e8b", "\u5973\u751f", "\u6545\u4e8b", "\u4e8b\u60c5", "\u4eba", "\u5973\u53cb", "\u6642\u9593", "\u9047\u5230", "\u6642\u5019", "\u505a", "\u5403", "\u59ca\u59ca", "\u670b\u53cb", "\u7b49", "\u770b", "\u554f\u984c", "\u5abd\u5abd", "\u7167\u7247", "\u7a7f\u642d", "\u8863\u670d", "\u5305\u5305", "\u6d0b\u88dd", "\u978b\u5b50", "\u80cc\u5fc3", "\u4e0a\u8863", "\u7a7f", "\u5916\u5957", "\u9577\u88d9", "\u50f9\u683c", "\u9078\u7528", "\u9732", "\u5496\u5561\u8272", "\u5c3a\u5bf8", "\u817f", "\u88d9\u5b50", "\u725b\u4ed4\u8932", "\u5929\u71c8", "\u670d\u52d9", "\u9ed1\u8272", "\u8cfc\u5165", "\u8766\u76ae", "\u6bdb\u8863", "\u85cd\u8272", "\u725b\u4ed4", "\u914d", "\u8089", "\u897f\u88dd", "\u8eab\u6750", "\u767d\u8272", "\u642d\u914d", "\u8cb7", "\u642d", "\u896f\u886b", "\u6574\u9ad4", "\u6771\u897f", "\u653e", "\u5473\u9053", "\u8eca", "\u7528", "\u5403", "\u770b", "\u984f\u8272", "\u8eab", "\u6642\u5019", "\u62cd", "\u670b\u53cb", "\u773c\u5f71", "\u816e\u7d05", "\u7c89\u5e95\u6db2", "\u599d\u5bb9", "\u773c\u599d", "\u7c89\u5e95", "\u5e95\u599d", "\u5507\u91c9", "\u8cea\u5730", "\u599d\u611f", "\u5857", "\u6253\u4eae", "\u773c\u7dda", "\u906e\u7455\u5ea6", "\u5507", "\u53e3\u7f69", "\u9727\u9762", "\u65b0\u4eba", "\u64e6", "\u5507\u8272", "\u5fc3\u5f97", "\u8272\u865f", "\u7f8e\u599d\u86cb", "\u773c\u7aa9", "\u5507\u818f", "\u62cd\u958b", "\u756b\u6cd5", "\u906e\u7455\u818f", "\u6ffe\u93e1", "\u6c23\u8272", "\u756b", "\u982d\u9aee", "\u65e5\u7cfb", "\u599d", "\u71d2\u5230", "\u773c", "\u984f\u8272", "\u7528", "\u611f\u89ba", "\u4eba", "\u624b", "\u9644\u4e0a", "\u5e36", "\u81c9", "\u821e\u53f0", "\u7bc0\u76ee", "\u5fae\u535a", "\u63a8\u7279", "\u6b4c\u66f2", "\u6b4c", "\u4e3b\u6301\u4eba", "\u6b4c\u8072", "\u7c89\u7d72", "\u5bf6\u5bf6", "\u50be\u5411", "\u6284", "\u85dd\u4eba", "\u5c55\u73fe", "\u4e3b\u6253", "\u7279\u8272", "\u773c\u795e", "\u5531", "\u88dc", "\u63a8", "\u6253\u7834", "\u8ffd", "\u71d2", "\u8868\u6f14", "\u5b69\u5b50", "\u770b\u770b", "\u59d0\u59d0", "\u5f71\u7247", "\u5237\u982d", "\u6548\u679c", "\u9700\u6c42", "\u5305\u88dd", "\u6587\u7ae0", "\u5011", "\u9023\u7d50", "\u610f\u601d", "\u9644\u4e0a", "\u4eba", "\u770b", "\u5507\u818f", "\u6642\u5019", "\u670b\u53cb", "\u984f\u8272", "\u5beb"], "Freq": [120.0, 34.0, 16.0, 21.0, 19.0, 18.0, 17.0, 16.0, 60.0, 20.0, 8.0, 10.0, 18.0, 18.0, 16.0, 12.0, 13.0, 9.0, 7.0, 10.0, 7.0, 24.0, 8.0, 8.0, 8.0, 9.0, 14.0, 64.0, 8.0, 6.0, 31.050660290130253, 27.715009645527726, 26.37019828723182, 25.952430743915663, 23.361617291909663, 22.462653236643927, 17.707371552827446, 15.237682517250471, 15.074769426702542, 14.953830306591415, 13.359037158384517, 13.282941284553177, 14.731826014061902, 12.255305134310532, 12.187606298604525, 12.121357506521228, 13.013534087018993, 11.480439302965395, 12.236281088362222, 11.364388134004923, 11.317900702041937, 11.336857850385226, 11.243780562336466, 12.151195472355765, 11.280475305770322, 10.517838701594222, 10.494703508220123, 10.448185257254227, 10.42505235694339, 10.401849875651811, 37.03108921721046, 25.04071185690822, 29.798995539580442, 22.379753936839137, 23.825932114733437, 21.39618054789447, 98.77816456625274, 14.470248709923274, 30.74774851284842, 15.118861823197337, 50.74803551123506, 25.633355310447552, 38.62181895492823, 15.522210681969645, 32.95240960354585, 14.246062925805957, 40.528199240260584, 19.158777840961427, 16.61387465710106, 14.302786726441207, 17.791819081348, 16.78961189390425, 16.166697491023786, 12.815548997184457, 9.459903797200107, 9.338277621575394, 6.829304125078879, 18.326983087118034, 6.068137189344684, 5.965197235159611, 6.00191039582235, 5.267796433977162, 5.267785402920049, 5.267251538503702, 5.246947056217948, 5.198684185745719, 4.424526920596058, 4.362004754129301, 4.334821906750395, 4.371862755447812, 8.620695609875273, 8.644523390199605, 3.5812567626122274, 3.5812429666320393, 3.5604109347619004, 3.5604109347699353, 3.5599355669392354, 3.497895335189129, 3.514926822169241, 3.5328267030812563, 9.345444254520316, 9.145683558084249, 24.806663480595507, 10.705054916813879, 6.644598206684884, 8.41077732734905, 9.23042156738363, 13.560956511016716, 7.947662123633091, 8.55389686274653, 9.28123127882666, 12.157541301368711, 11.775050581695815, 7.489134967139375, 6.70120407354406, 9.717357902115968, 5.696981180055984, 6.567933888347663, 10.01845584007416, 8.531352891538411, 7.797475993713325, 7.778394813551888, 7.778388976576648, 6.329463937046645, 5.557392346965428, 5.554175727161284, 5.536218243744072, 5.481076853064393, 5.4800506228577035, 4.032205743910978, 3.974970575527245, 3.9749676482693044, 3.221911182990902, 3.221910503755728, 3.2370729878066267, 3.196971010550621, 6.281073677694515, 2.5069824633662003, 2.4879259234155047, 2.4878099609990576, 2.5008403397223997, 2.4688615542428467, 7.888303153010126, 1.7348789389068078, 1.7158053485695746, 1.7158048714585235, 1.7157993833327951, 1.7157804047849925, 6.995563448144437, 4.754767149704742, 3.197319561194739, 3.218452665863396, 3.120598507090759, 4.0146271349424465, 8.831233490999848, 9.355679026434697, 7.201519586166216, 9.243357742025715, 5.03670847801704, 4.502893512812362, 3.8008140443609246, 3.2219132755307203, 7.999423380611666, 4.073089552077708, 2.785839645959338, 2.7702606986682388, 2.7759952928038225, 5.445602096056426, 2.1194985049233503, 2.118092575186889, 5.126841315828583, 3.508923546061761, 1.4680487131322753, 1.4680466811011115, 1.4678738960097903, 1.4657635116918983, 3.9282035222731904, 1.3524076035385086, 1.327733897950266, 1.7577939205378539, 2.126230319186681, 3.449569729850671, 1.4692005282470122, 1.4759771037826241, 1.3843041893926462, 2.120643087709726, 3.1734739577559243, 3.3190932634808483, 1.3247860346674878, 6.983701935684277, 0.8329472424151888, 0.8328765397941794, 1.4696836361072778, 2.1714021527744625, 4.344551964790099, 6.2484732464217, 2.5569682663065443, 2.7482564878395586, 3.792840151495993, 7.016667066207861, 5.196472408185805, 2.1673805798498775, 3.285212530115387, 2.8968851777330675, 2.136349464903204, 1.8674750589549292], "Total": [120.0, 34.0, 16.0, 21.0, 19.0, 18.0, 17.0, 16.0, 60.0, 20.0, 8.0, 10.0, 18.0, 18.0, 16.0, 12.0, 13.0, 9.0, 7.0, 10.0, 7.0, 24.0, 8.0, 8.0, 8.0, 9.0, 14.0, 64.0, 8.0, 6.0, 31.625889352388597, 28.278780521926606, 26.933969497565922, 26.516199659197664, 23.9484373449606, 23.03632231682237, 18.27123085133804, 15.801454101686357, 15.638941167817734, 15.522389300482027, 13.92282178881885, 13.851324725619033, 15.407911990301649, 12.820844883504948, 12.75140785879498, 12.702963439730123, 13.645534693944548, 12.044200054359527, 12.839727180053108, 11.928151654862784, 11.881718195198166, 11.904486955691102, 11.811634875235704, 12.77436488735496, 11.877545834155827, 11.081659793736694, 11.058466175078031, 11.012025618690576, 10.988832579791396, 10.96562497322376, 39.32114949996892, 26.589662925891055, 31.871295755239046, 23.806536895091153, 25.444372773566666, 22.83886719985628, 120.4780847947189, 15.482062316580816, 35.314316995706704, 16.438123995501915, 64.78055589256589, 31.380540541596936, 51.88482439225936, 17.266028274163684, 45.555759627888484, 15.58721010960036, 60.654624325343995, 26.79729358100188, 21.691506302906216, 20.049941717155598, 18.379283547676625, 17.39146971783108, 16.75537694689176, 13.403011647472953, 10.051154371457795, 9.925750216481156, 7.416777680484493, 19.98806485057226, 6.656993720481783, 6.5526716457828815, 6.5948996032182, 5.855258250165309, 5.8552567820293975, 5.85531811123892, 5.83442016477785, 5.793496407177869, 5.011988689087028, 4.949477910388506, 4.929364464189737, 4.971558048862392, 9.960609195156119, 10.000775720326349, 4.168719030102093, 4.168717098873904, 4.147881506055276, 4.147881506075596, 4.147931385629495, 4.085371590654324, 4.106642409597904, 4.12781005705258, 11.686924925377648, 11.573322103818006, 34.790060855292054, 14.350603347028194, 8.4235442238808, 11.630233752221459, 13.671237534532214, 24.10690909087823, 12.338591607496763, 17.274291591214244, 20.935312569799407, 51.88482439225936, 60.654624325343995, 18.690437920453803, 13.09045337573478, 64.78055589256589, 11.372617282698783, 45.555759627888484, 10.623511623463386, 9.136496576697775, 8.402499660332802, 8.383420984115547, 8.383420757373411, 6.934557160664016, 6.162415212678527, 6.162710650365722, 6.143529111157646, 6.086100735227038, 6.086195485776286, 4.6372279102505285, 4.579992135877883, 4.579991969660965, 3.8269375874051943, 3.8269375021500363, 3.8463768145483614, 3.809107458155919, 7.791391801199874, 3.1120390655474304, 3.0929614149298095, 3.0929889520607525, 3.1112157783277756, 3.073883384565617, 10.502985315007514, 2.339907369013926, 2.320828950799932, 2.320828890841085, 2.3208287355120367, 2.3208278890046206, 9.48940365200259, 7.112474103871345, 4.631509377246239, 4.766997271282036, 4.679538094112865, 6.439249474237587, 18.690437920453803, 20.935312569799407, 18.654078860839835, 120.4780847947189, 22.42145384338455, 16.765501622565342, 14.574633043271017, 12.561346769474097, 8.63118696746607, 4.705499499497637, 3.4191398328201106, 3.4022579795726475, 3.4231391851703528, 7.05901908886874, 2.7503724471069018, 2.750943382614593, 7.095534267061711, 4.957459479417341, 2.0987657876293686, 2.0987662527316377, 2.098836963126892, 2.099693852010912, 5.633792433599538, 2.1689267581775487, 2.1783909103592225, 2.920438487903636, 3.709990274993343, 6.3869034626758605, 3.0144009407756283, 3.058062732720564, 2.9451402371361812, 4.582116018031387, 6.995800319452163, 7.671872837015938, 3.0730338346384403, 16.985660415753053, 2.2167741061293826, 2.235863615444619, 3.976723004728828, 5.9339039099126065, 12.54370856904766, 21.72088541785555, 7.245979735924807, 8.06078462959874, 16.765501622565342, 120.4780847947189, 60.654624325343995, 10.502985315007514, 64.78055589256589, 45.555759627888484, 18.690437920453803, 10.773678255329958], "Category": ["Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4"], "logprob": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.4698, -4.5834, -4.6332, -4.6491, -4.7543, -4.7935, -5.0314, -5.1816, -5.1924, -5.2004, -5.3132, -5.3189, -5.2154, -5.3994, -5.405, -5.4104, -5.3394, -5.4647, -5.401, -5.4749, -5.479, -5.4773, -5.4856, -5.408, -5.4823, -5.5523, -5.5545, -5.559, -5.5612, -5.5634, -4.2936, -4.6849, -4.5109, -4.7972, -4.7346, -4.8422, -3.3125, -5.2333, -4.4796, -5.1894, -3.9785, -4.6615, -4.2516, -5.1631, -4.4103, -5.2489, -4.2034, -4.9526, -5.0951, -5.2449, -3.9057, -3.9636, -4.0014, -4.2337, -4.5373, -4.5503, -4.8632, -3.876, -4.9813, -4.9984, -4.9923, -5.1228, -5.1228, -5.1229, -5.1267, -5.136, -5.2972, -5.3115, -5.3177, -5.3092, -4.6302, -4.6275, -5.5087, -5.5087, -5.5145, -5.5145, -5.5146, -5.5322, -5.5274, -5.5223, -4.5495, -4.5711, -3.5733, -4.4137, -4.8906, -4.6549, -4.5619, -4.1772, -4.7115, -4.638, -4.5564, -4.2864, -4.3184, -4.7709, -4.8821, -4.5105, -5.0445, -4.9022, -3.9828, -4.1435, -4.2334, -4.2359, -4.2359, -4.442, -4.5721, -4.5727, -4.5759, -4.5859, -4.5861, -4.8929, -4.9072, -4.9072, -5.1172, -5.1172, -5.1125, -5.125, -4.4497, -5.3681, -5.3758, -5.3758, -5.3706, -5.3834, -4.2218, -5.7363, -5.7473, -5.7473, -5.7473, -5.7473, -4.3419, -4.7281, -5.1249, -5.1183, -5.1492, -4.8973, -4.1089, -4.0512, -4.3129, -4.0633, -4.6705, -4.7825, -4.952, -5.1172, -3.6229, -4.2979, -4.6778, -4.6834, -4.6813, -4.0075, -4.9511, -4.9518, -4.0678, -4.447, -5.3184, -5.3184, -5.3185, -5.3199, -4.3341, -5.4004, -5.4188, -5.1382, -4.948, -4.4641, -5.3176, -5.313, -5.3771, -4.9506, -4.5475, -4.5026, -5.4211, -3.7587, -5.8851, -5.8852, -5.3173, -4.9269, -4.2334, -3.87, -4.7635, -4.6913, -4.3692, -3.754, -4.0543, -4.9288, -4.5129, -4.6387, -4.9432, -5.0777], "loglift": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4731, 0.4713, 0.4703, 0.47, 0.4666, 0.4662, 0.4601, 0.4551, 0.4547, 0.4541, 0.4501, 0.4495, 0.4466, 0.4463, 0.4462, 0.4446, 0.444, 0.4435, 0.4433, 0.443, 0.4428, 0.4426, 0.4422, 0.4414, 0.4399, 0.4392, 0.4391, 0.4389, 0.4388, 0.4387, 0.4314, 0.4314, 0.4242, 0.4296, 0.4257, 0.4262, 0.2929, 0.4239, 0.353, 0.4078, 0.2473, 0.2892, 0.1962, 0.385, 0.1676, 0.4015, 0.0882, 0.1559, 0.2248, 0.1537, 1.58, 1.5772, 1.5767, 1.5676, 1.5518, 1.5514, 1.5299, 1.5257, 1.5198, 1.5185, 1.5182, 1.5067, 1.5067, 1.5066, 1.5063, 1.5041, 1.4878, 1.4861, 1.4839, 1.4839, 1.468, 1.4667, 1.4605, 1.4605, 1.4597, 1.4597, 1.4596, 1.4572, 1.4569, 1.4568, 1.3889, 1.377, 1.2742, 1.3194, 1.3752, 1.2883, 1.2197, 1.0371, 1.1726, 0.9096, 0.799, 0.1614, -0.0268, 0.6979, 0.9428, -0.2847, 0.9212, -0.3243, 2.051, 2.0411, 2.0349, 2.0347, 2.0347, 2.0183, 2.0063, 2.0057, 2.0055, 2.0049, 2.0047, 1.9698, 1.9679, 1.9679, 1.9375, 1.9375, 1.9372, 1.9344, 1.8941, 1.8934, 1.8919, 1.8919, 1.8912, 1.8904, 1.8233, 1.8105, 1.8076, 1.8076, 1.8076, 1.8076, 1.8047, 1.7069, 1.7391, 1.7168, 1.7045, 1.6372, 1.3599, 1.3042, 1.1579, -0.4579, 0.6164, 0.795, 0.7656, 0.749, 2.6185, 2.5502, 2.4897, 2.489, 2.485, 2.435, 2.434, 2.4331, 2.3695, 2.3489, 2.3371, 2.3371, 2.337, 2.3351, 2.3339, 2.2222, 2.1994, 2.1869, 2.1378, 2.0785, 1.9758, 1.9661, 1.9396, 1.9241, 1.904, 1.8567, 1.8531, 1.8057, 1.7157, 1.707, 1.6991, 1.6892, 1.6342, 1.4486, 1.6529, 1.6185, 1.2083, -0.1487, 0.2373, 1.1164, -0.287, -0.0608, 0.5256, 0.942]}, "token.table": {"Topic": [2, 1, 3, 4, 4, 1, 3, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 2, 3, 4, 2, 2, 3, 4, 3, 1, 2, 3, 1, 1, 2, 3, 2, 3, 3, 4, 3, 3, 1, 4, 1, 2, 3, 3, 2, 2, 1, 4, 1, 2, 1, 3, 3, 3, 1, 2, 1, 4, 1, 1, 2, 1, 4, 1, 1, 1, 3, 4, 2, 4, 1, 1, 2, 4, 1, 1, 2, 3, 1, 3, 1, 3, 4, 4, 3, 1, 4, 1, 1, 3, 1, 1, 1, 2, 3, 1, 3, 1, 4, 1, 4, 1, 2, 3, 3, 4, 4, 1, 2, 1, 2, 4, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 3, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 2, 3, 4, 2, 1, 2, 1, 1, 4, 4, 4, 2, 3, 2, 3, 1, 2, 3, 4, 3, 4, 2, 3, 2, 2, 4, 1, 1, 2, 3, 1, 1, 2, 3, 1, 3, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 1, 3, 3, 3, 4, 3, 3, 1, 2, 2, 1, 3, 4, 3, 3, 1, 4, 3, 1, 2, 2, 3, 2, 1, 2, 3, 4, 3, 1, 2, 4, 1, 2, 2, 1, 4, 2, 1, 4, 1, 2, 2, 1, 1, 1, 1, 2, 3, 3, 2, 3, 1, 2, 2, 1, 2, 1, 4, 1, 4, 1, 3, 3, 3, 2, 2, 1, 2, 1, 1, 1, 2, 3, 4, 1, 1, 1, 1, 4, 3, 2, 2, 1, 2, 3, 2, 3, 4, 1, 1, 2, 3], "Freq": [0.9438060976829404, 0.17750032713950747, 0.17750032713950747, 0.7100013085580299, 0.7271742422026466, 0.9412858589242817, 0.06275239059495212, 0.919485183579164, 0.04378500874186495, 0.8217262099466875, 0.04150132373468119, 0.07470238272242614, 0.058101853228553664, 0.5064250277273459, 0.1841545555372167, 0.04603863888430418, 0.27623183330582507, 0.828538946470196, 0.063733765113092, 0.063733765113092, 0.031866882556546, 0.4764705075212494, 0.9097939864121816, 0.45110595492567285, 0.45110595492567285, 0.9549173409057867, 0.16852311988562818, 0.33704623977125636, 0.33704623977125636, 0.7839166430898207, 0.7516648742058452, 0.23128149975564466, 0.01927345831297039, 0.9312851367478875, 0.08104652717352387, 0.648372217388191, 0.2431395815205716, 0.8539245699397289, 0.7839166256260038, 0.7616882019790081, 0.19042205049475203, 0.9639981815177754, 0.9735975515326091, 0.34241433406043936, 0.6848286681208787, 0.7090268255101021, 0.22390320805582173, 0.07463440268527391, 0.8215312852972314, 0.901307745197297, 0.8114636337115517, 0.904272293556552, 0.06459087811118229, 0.9241159307188583, 0.042005269578129924, 0.2097756602514396, 0.6293269807543188, 0.9542643766975281, 0.8215440751842038, 0.9266751881752605, 0.05791719926095378, 0.3254113211277596, 0.3254113211277596, 0.9080981416377313, 0.7837168964942904, 0.23050496955714425, 0.4288287062251268, 0.4288287062251268, 0.9133026643823001, 0.93938133956691, 0.6497316732599618, 0.18563762093141767, 0.18563762093141767, 0.20171622262407915, 0.8068648904963166, 0.9492797247311041, 0.992631086384474, 0.8569831892095792, 0.4762599076252394, 0.9550135519650377, 0.5488988968880785, 0.13722472422201962, 0.27444944844403923, 0.9042845401595161, 0.97364422761641, 0.47098551390916427, 0.11774637847729107, 0.4121123246705187, 0.8774136615306536, 0.6466294698491696, 0.6202870104778989, 0.37217220628673936, 0.9802095888778121, 0.5896833653411908, 0.37525305067166687, 0.9446614608421594, 0.9735258099502123, 0.5798018313533959, 0.22300070436669073, 0.22300070436669073, 0.9261172428708042, 0.862584301961535, 0.331740873111157, 0.331740873111157, 0.9603966918050219, 0.47647040193182805, 0.43965253342399235, 0.5275830401087909, 0.8547346901355466, 0.31314079063316214, 0.4697111859497432, 0.8817673492169531, 0.20905044390494268, 0.7665182943181231, 0.08640561379261213, 0.7776505241335092, 0.08640561379261213, 0.12834677365936084, 0.770080641956165, 0.3733369535709368, 0.5807463722214573, 0.04148188373010409, 0.9432340979115359, 0.039301420746314, 0.44725447164680576, 0.44725447164680576, 0.08598279461141464, 0.6878623568913171, 0.17196558922282928, 0.3188849595780817, 0.3188849595780817, 0.3188849595780817, 0.7875860770418833, 0.2159123340897932, 0.6477370022693796, 0.7872732689200754, 0.15436730763138734, 0.015436730763138734, 0.0463101922894162, 0.8778309376270477, 0.05663425404045468, 0.05663425404045468, 0.940215002712834, 0.03760860010851336, 0.7243869989119431, 0.15365784825404855, 0.06585336353744937, 0.06585336353744937, 0.8045767465020935, 0.2925850706562877, 0.6583164089766473, 0.9119407260797578, 0.14166274200573914, 0.7083137100286956, 0.8763885538153204, 0.7270233232132643, 0.9595278127845425, 0.8617614470574894, 0.9699312618631546, 0.8617611327355211, 0.6982563938338531, 0.14962637010725424, 0.09975091340483616, 0.04987545670241808, 0.3395424052785982, 0.3395424052785982, 0.21369630503875137, 0.6410889151162541, 0.9643477023490217, 0.8081660474944968, 0.4610575236022515, 0.9221881409862523, 0.09553236873497338, 0.42989565930738016, 0.42989565930738016, 0.9591442182075238, 0.9409694393605977, 0.025431606469205344, 0.025431606469205344, 0.2107614001200098, 0.7376649004200343, 0.8617610527956616, 0.085565707522305, 0.770091367700745, 0.085565707522305, 0.6759583536463932, 0.19784146935991997, 0.049460367339979994, 0.08243394556663332, 0.260692537857278, 0.260692537857278, 0.39103880678591696, 0.3105952033698464, 0.6211904067396928, 0.9542644025070335, 0.9413083314102767, 0.4590544310686172, 0.6506427700030097, 0.8733639450307241, 0.050029855690175526, 0.9005374024231594, 0.9793635292315531, 0.8981722772426878, 0.06415516266019199, 0.8500691585297254, 0.8652318902257735, 0.952097628491084, 0.28186742882551225, 0.7046685720637806, 0.9642532738801061, 0.9337187674441146, 0.7343273270080952, 0.9067324689529263, 0.9850602935652706, 0.8630366964248455, 0.3184371925565006, 0.39804649069562575, 0.23882789441737545, 0.9268713596582682, 0.6466237128546705, 0.9663460766013771, 0.9643477023537458, 0.4764543495127791, 0.9901417063684749, 0.9595273682673786, 0.9774907052605385, 0.4364795636185701, 0.4364795636185701, 0.7980863980618101, 0.2695424855262712, 0.5390849710525424, 0.11871487504808176, 0.8310041253365723, 0.9740317273915394, 0.9345992972998952, 0.938538389469388, 0.9851553048864151, 0.22995073314978373, 0.7185960410930742, 0.05748768328744593, 0.9766373515025796, 0.8999301905858867, 0.09999224339843187, 0.4583492891943641, 0.5347408373934247, 0.96903683665526, 0.46311595226682545, 0.5210054463001786, 0.3270044101123994, 0.3270044101123994, 0.5520302492937457, 0.4140226869703092, 0.9125128879733819, 0.06083419253155879, 0.8733639767268198, 0.8617610750593447, 0.8539333000143652, 0.9643361059100439, 0.9240213409399639, 0.9156570517098067, 0.9526926054256404, 0.9653237337463263, 0.41752404178461483, 0.05964629168351641, 0.29823145841758203, 0.23858516673406563, 0.9359757573729769, 0.9100147743073389, 0.9805326681111103, 0.5029266553445504, 0.2514633276722752, 0.7799547846308078, 0.8539335141279712, 0.8954195376361195, 0.1405980514509988, 0.1405980514509988, 0.702990257254994, 0.37452305985509193, 0.4815296483851182, 0.10700658853002627, 0.9257920293418085, 0.9410725570763769, 0.9035591923811983, 0.10039546582013315], "Term": ["\u4e0a\u8863", "\u4e3b\u6253", "\u4e3b\u6253", "\u4e3b\u6253", "\u4e3b\u6301\u4eba", "\u4e8b", "\u4e8b", "\u4e8b\u60c5", "\u4e8b\u60c5", "\u4eba", "\u4eba", "\u4eba", "\u4eba", "\u5011", "\u5011", "\u5011", "\u5011", "\u505a", "\u505a", "\u505a", "\u505a", "\u50be\u5411", "\u50f9\u683c", "\u5237\u982d", "\u5237\u982d", "\u5305\u5305", "\u5305\u88dd", "\u5305\u88dd", "\u5305\u88dd", "\u53e3\u7f69", "\u5403", "\u5403", "\u5403", "\u540c\u4e8b", "\u5473\u9053", "\u5473\u9053", "\u5473\u9053", "\u5496\u5561\u8272", "\u5507", "\u5507\u818f", "\u5507\u818f", "\u5507\u8272", "\u5507\u91c9", "\u5531", "\u5531", "\u554f\u984c", "\u554f\u984c", "\u554f\u984c", "\u5857", "\u5916\u5957", "\u5929\u71c8", "\u5973\u53cb", "\u5973\u53cb", "\u5973\u751f", "\u5973\u751f", "\u599d", "\u599d", "\u599d\u5bb9", "\u599d\u611f", "\u59ca\u59ca", "\u59ca\u59ca", "\u59d0\u59d0", "\u59d0\u59d0", "\u5abd", "\u5abd\u5abd", "\u5abd\u5abd", "\u5b69\u5b50", "\u5b69\u5b50", "\u5b78\u59b9", "\u5bb6\u4eba", "\u5beb", "\u5beb", "\u5beb", "\u5bf6\u5bf6", "\u5bf6\u5bf6", "\u5c0d\u8c61", "\u5c0f\u5b69", "\u5c3a\u5bf8", "\u5c55\u73fe", "\u5de5\u4f5c", "\u5e36", "\u5e36", "\u5e36", "\u5e8a", "\u5e95\u599d", "\u5f71\u7247", "\u5f71\u7247", "\u5f71\u7247", "\u5fae\u535a", "\u5fc3\u5f97", "\u610f\u601d", "\u610f\u601d", "\u611f\u60c5", "\u611f\u89ba", "\u611f\u89ba", "\u614b\u5ea6", "\u6210\u54e1", "\u624b", "\u624b", "\u624b", "\u624b\u6a5f", "\u6253\u4eae", "\u6253\u7834", "\u6253\u7834", "\u627e", "\u6284", "\u62cd", "\u62cd", "\u62cd\u958b", "\u63a8", "\u63a8", "\u63a8\u7279", "\u642d", "\u642d", "\u642d\u914d", "\u642d\u914d", "\u642d\u914d", "\u64e6", "\u64e6", "\u653e", "\u653e", "\u653e", "\u6545\u4e8b", "\u6545\u4e8b", "\u6548\u679c", "\u6548\u679c", "\u6574\u9ad4", "\u6574\u9ad4", "\u6574\u9ad4", "\u6587\u7ae0", "\u6587\u7ae0", "\u6587\u7ae0", "\u65b0\u4eba", "\u65e5\u7cfb", "\u65e5\u7cfb", "\u6642\u5019", "\u6642\u5019", "\u6642\u5019", "\u6642\u5019", "\u6642\u9593", "\u6642\u9593", "\u6642\u9593", "\u6708", "\u6708", "\u670b\u53cb", "\u670b\u53cb", "\u670b\u53cb", "\u670b\u53cb", "\u670d\u52d9", "\u6771\u897f", "\u6771\u897f", "\u6ab8\u6aac", "\u6b4c", "\u6b4c", "\u6b4c\u66f2", "\u6b4c\u8072", "\u6bdb\u8863", "\u6c23\u8272", "\u6d0b\u88dd", "\u6ffe\u93e1", "\u7167\u7247", "\u7167\u7247", "\u7167\u7247", "\u7167\u7247", "\u71d2", "\u71d2", "\u71d2\u5230", "\u71d2\u5230", "\u725b\u4ed4", "\u725b\u4ed4\u8932", "\u7279\u8272", "\u751f\u6d3b", "\u7528", "\u7528", "\u7528", "\u7537", "\u7537\u53cb", "\u7537\u53cb", "\u7537\u53cb", "\u756b", "\u756b", "\u756b\u6cd5", "\u767d\u8272", "\u767d\u8272", "\u767d\u8272", "\u770b", "\u770b", "\u770b", "\u770b", "\u770b\u770b", "\u770b\u770b", "\u770b\u770b", "\u773c", "\u773c", "\u773c\u599d", "\u773c\u5f71", "\u773c\u795e", "\u773c\u7aa9", "\u773c\u7dda", "\u7a7f", "\u7a7f", "\u7a7f\u642d", "\u7b49", "\u7b49", "\u7bc0\u76ee", "\u7c89\u5e95", "\u7c89\u5e95\u6db2", "\u7c89\u7d72", "\u7c89\u7d72", "\u7f8e\u599d\u86cb", "\u8001\u5e2b", "\u8089", "\u80cc\u5fc3", "\u816e\u7d05", "\u817f", "\u81c9", "\u81c9", "\u81c9", "\u821e\u53f0", "\u8272\u865f", "\u8349\u8393", "\u85cd\u8272", "\u85dd\u4eba", "\u86cb\u7cd5", "\u8766\u76ae", "\u8863\u670d", "\u8868\u6f14", "\u8868\u6f14", "\u88d9\u5b50", "\u88dc", "\u88dc", "\u896f\u886b", "\u896f\u886b", "\u897f\u88dd", "\u8981", "\u8a0a\u606f", "\u8c93", "\u8cb7", "\u8cb7", "\u8cb7", "\u8cea\u5730", "\u8cfc\u5165", "\u8cfc\u5165", "\u8eab", "\u8eab", "\u8eab\u6750", "\u8eca", "\u8eca", "\u8ffd", "\u8ffd", "\u9023\u7d50", "\u9023\u7d50", "\u9047\u5230", "\u9047\u5230", "\u906e\u7455\u5ea6", "\u906e\u7455\u818f", "\u9078\u7528", "\u914d", "\u9322", "\u9577\u88d9", "\u958b", "\u95dc\u4fc2", "\u9644\u4e0a", "\u9644\u4e0a", "\u9644\u4e0a", "\u9644\u4e0a", "\u966a", "\u96e2\u958b", "\u96fb\u8a71", "\u9700\u6c42", "\u9700\u6c42", "\u9727\u9762", "\u9732", "\u978b\u5b50", "\u982d\u9aee", "\u982d\u9aee", "\u982d\u9aee", "\u984f\u8272", "\u984f\u8272", "\u984f\u8272", "\u990a", "\u9a19", "\u9ed1\u8272", "\u9ed1\u8272"]}, "R": 30, "lambda.step": 0.01, "plot.opts": {"xlab": "PC1", "ylab": "PC2"}, "topic.order": [4, 1, 3, 2]};

function LDAvis_load_lib(url, callback){
  var s = document.createElement('script');
  s.src = url;
  s.async = true;
  s.onreadystatechange = s.onload = callback;
  s.onerror = function(){console.warn("failed to load library " + url);};
  document.getElementsByTagName("head")[0].appendChild(s);
}

if(typeof(LDAvis) !== "undefined"){
   // already loaded: just create the visualization
   !function(LDAvis){
       new LDAvis("#" + "ldavis_el680751404088344607924370080306", ldavis_el680751404088344607924370080306_data);
   }(LDAvis);
}else if(typeof define === "function" && define.amd){
   // require.js is available: use it to load d3/LDAvis
   require.config({paths: {d3: "https://d3js.org/d3.v5"}});
   require(["d3"], function(d3){
      window.d3 = d3;
      LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js", function(){
        new LDAvis("#" + "ldavis_el680751404088344607924370080306", ldavis_el680751404088344607924370080306_data);
      });
    });
}else{
    // require.js not available: dynamically load d3 & LDAvis
    LDAvis_load_lib("https://d3js.org/d3.v5.js", function(){
         LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js", function(){
                 new LDAvis("#" + "ldavis_el680751404088344607924370080306", ldavis_el680751404088344607924370080306_data);
            })
         });
}
</script></div></div>
</div>
</div>
<div class="section" id="clustering-documents-using-topic-model-features">
<h2>Clustering documents using topic model features<a class="headerlink" href="#clustering-documents-using-topic-model-features" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">num_of_topic</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">km</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">corpus_df2</span><span class="p">[</span><span class="s1">&#39;ClusterLabels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span>
<span class="n">corpus_df2</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>title</th>
      <th>content</th>
      <th>Normalized</th>
      <th>ClusterLabels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>90</th>
      <td>235444293</td>
      <td>球場上端火鍋</td>
      <td>https://www.dcard.tw/v2/vivid/videos/7d1d1171-e0c7-4225-9e07-517ee6b898ab?r=0.7625\n幹真的不是套好的嗎XDDD\n笑到瘋</td>
      <td>套好</td>
      <td>1</td>
    </tr>
    <tr>
      <th>91</th>
      <td>235442238</td>
      <td>#問 特殊形狀美妝蛋</td>
      <td>https://i.imgur.com/PxSaXkZ.jpg\nhttps://i.imgur.com/Tq1GPx8.jpg\n小紅書上好多好可愛的美妝蛋\n被燒到不行\n想請問各位水水有用過嗎？</td>
      <td>書 美妝蛋 燒 用</td>
      <td>1</td>
    </tr>
    <tr>
      <th>92</th>
      <td>235446475</td>
      <td>問這個很漂亮的人是誰</td>
      <td>最近的合作舞台，剛好三團都沒什麼在追，想問板上的各位這位是誰🙏\nhttps://i.imgur.com/gPVxus5.jpg</td>
      <td>舞台 追 板</td>
      <td>3</td>
    </tr>
    <tr>
      <th>93</th>
      <td>235443651</td>
      <td>更）市北這樣是偷偷放榜嗎⋯⋯</td>
      <td>我有一一看完大家的回覆了\n謝謝很多戰友或是其他朋友的加油\n也看到有通過市北初試的留言\n真的很恭喜\n希望你可以唸到自己想唸的事物\n唸輔導諮商向來是自己的夢想\n我從指考填志願時與這個領域錯過之後也還是很努力的想擠身進去\n我覺得我已經盡我所能\n若結果還是不如預期\n那真的就是真的不適合吧\n期許自己能遇到自己喜歡以及適合自己的地方\n不管是研究所或工作都是\n——————————...</td>
      <td>看完 戰友 朋友 通過 初試 留言 唸 事物 唸 輔導 夢想 指考 填 志願 領域 擠 身 結果 預期 遇到 地方 工作 正文 手賤 系統 複試 名單 意思 死刑 名字 等 煎熬 阻止 找 工作</td>
      <td>0</td>
    </tr>
    <tr>
      <th>94</th>
      <td>235445249</td>
      <td>女友有罪惡感（微西斯）</td>
      <td>前幾天跟女友做了  做完之後他哭了  我趕緊安撫他的情緒  並詢問說是不是我弄痛你了  他跟我說是因為怕如果父母知道的話會對他失望所以他有罪惡感（女友父母有跟他說要等結婚之後才可以做  不可以隨便給別人）我跟他說每個人本來就都有慾望  你不要太自責\n\n我跟女友都是對方的第一任  我們已經交往了快三年直到前一陣子才做  但這次並不是第一次  上個月的時侯我就有戴在外面磨一磨然後不小心滑進...</td>
      <td>女友 做 做完 情緒 弄痛 父母 罪惡感 女友 父母 等 做 人 慾望 女友 做 月 時侯 戴 磨 磨 弄 弄 罪惡感 罪惡感 原因 碰 頻率 弄 慾望 處理好 吃 女友 接受 吃</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>235444562</td>
      <td>主題：💟愛情塔羅💟 他要的感情關係vs 我要的感情關係為何？兩個人的近期發展（曖昧/交往中/斷聯/復合）</td>
      <td>🤗感謝我們之間的連結帶領你來到這裡！ \n\n主題：💟愛情塔羅💟 他要的感情關係vs 我要的感情關係為何？兩個人的近期發展（曖昧/交往中/斷聯/復合）\n\n本次的大眾占卜適合處在曖昧、交往中、剛斷聯、分手、期待的你，有時候一份感情的重要核心正是在於雙方要的是不是一樣的東西，不見得得要完全相同，但至少如果理解彼此的感情需求，在相處上也能夠更融洽嘍！\n\n⭐️請閉上眼睛，深呼吸，腦子專心裡...</td>
      <td>連結 主題 愛情 要 感情 關係 要 感情 關係 人 發展 感情 核心 要 東西 感情 需求 閉上 眼睛 腦子 要 感情 關係 要 樣子 人 點滴 張開 眼睛 牌卡 選出 連結 選 牌卡 天使 看 連結 天使 天使 天使 天使 天使 選 感覺 牌 找到 文字 解答 影片 解答 參考 影片 視頻 時間軸 選 牌 天使 天使 天使 天使 天使 文字 解答 祝福</td>
      <td>0</td>
    </tr>
    <tr>
      <th>96</th>
      <td>235441027</td>
      <td>#分享 老花古董包 LV 方盒子｜Celine 化妝箱</td>
      <td>近期購入的兩款古董包 可能因為是新歡 所以都讓我愛不釋手(๑•̀ •́)و✧\n不過正是古董包的緣故 包況總有些不盡理想的狀況 帶有小瑕疵的部分 我自己都可以接受\n為了比較包包的容量 文內有帶到一小部分的what’s in my bag 也有實揹照的部分*ˊᵕˋ\n\n\n\n𓎘𓎘𓎘 Louis Vuitton monogram 開口笑方盒子\n（名字是參考小紅書介紹）\n\n購入價格：...</td>
      <td>購入 古董包 新歡 古董包 緣故 包況 狀況 瑕疵 接受 比較 包包 容量 文 帶到 實 揹照 笑 方盒子 名字 參考 書 購入 價格 購入 方式 尺寸 容量 暗層 單肩包 媽媽 生日 禮物 藏 看 購入 媽媽 留 用 容量 物品 帶 保溫瓶 放入 保溫瓶 放入 小說 照片 拍 照片 參考 個子 身形 暗層 放 面紙 放 口紅 護唇膏 拉鍊 夾層 放 悠遊卡 化妝箱 購入 價格 購入 方式...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>97</th>
      <td>235447320</td>
      <td>在公車上遇到的超尷尬事件</td>
      <td>剛剛在公車上有一個阿伯下車前跟我說：妹妹你很有愛心欸 讓位置給別人 不像有些人都在裝睡\n講完這句話還瞄了一眼旁邊的女生\n我當下就笑笑的\n可是阿伯\n那個女生\n-\n-\n-\n是我朋友(^_^;)\n幸好阿伯講完就下車了⋯\nhttps://i.imgur.com/htuMwVw.jpg</td>
      <td>公車 阿伯 妹妹 愛心 位置 人 講完 話 瞄 女生 阿伯 女生 朋友 阿伯 講完</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>235440749</td>
      <td>#大眾占卜 🥺。他現在對我的想法是?他的下一步是什麼?我能為這段關係做什麼樣的努力❣</td>
      <td>大家好這裡是金魚🙏\n這次的占卜適合斷聯、曖昧、復合的族群\n\n再上圖之前先置入我的IG\nhttps://www.instagram.com/goldenfishtarot\n\n【大眾占卜集合多人能量請選擇有感應的部分聆聽即可】\n喜歡有聲版請點連結\n喜歡文字下面附上文案\nhttps://youtu.be/xkJHmyl_M7g\n\nhttps://i.imgur.com/Ux...</td>
      <td>金魚 族群 圖 置入 人 能量 選擇 感應 聆聽 點 連結 文字 附上 文案 對象 感情 騙 錢 關 遇見 心房 打開 過程 愛 感情 家庭 熱情 感染力 感情 方式 樣子 帶來 副作用 圍繞 生活 面對 事 心 關卡 捲進 麻煩 感情 選 資本 做 距離 個性 面對 生活 關卡 打出 安全牌 冒 風險 突破 現實 條件 做 切斷 後路 做出 抉擇 理性 配合 內心 想法 做出 行動 關係...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>99</th>
      <td>235442177</td>
      <td>所以，你要當我女朋友嗎？</td>
      <td>「所以，你要當我女朋友嗎？」我看進她的眼睛，隱約反射出自己的倒影。躺在床上的我們呼吸有些紊亂，午後的陽光肆無忌憚的灑在身上，有點溫暖。\n\n我們的故事，從英國開始。\n\n\n大學畢業後我跑到英國念碩士，人生地不熟的地方，一個認識的人也沒有，頭幾週的生活常常是一個人吃飯、逛街、看劇度過，再加上那時還沒走出前女友劈腿的陰影，那段時間說實在還滿煎熬的。\n\n幸好後來認識了跟我住在同個宿舍的...</td>
      <td>女朋友 眼睛 反射出 倒影 床 呼吸 陽光 灑 身 故事 念 碩士 地方 人 生活 人 看劇 加上 女友 陰影 時間 煎熬 台灣人 朋友 人脈 所有人 台灣人 福 交到 朋友 女孩 人 開 火鍋趴 參加 籃球 校隊 比賽 時間 延長賽 手機 訊息 傳來 通知 比賽 煮 人 等 露出 眼睛 掃 恩 人 等 煮 氣氛 熱氣 火鍋 生面孔 加上 愧疚感 印象 頭髮 眼睛 印象 大王 飯 交換 聯...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_labels</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ClusterLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>94</th>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>2</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>99 rows × 1 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="grid-search-for-topic-number">
<h2>Grid Search for Topic Number<a class="headerlink" href="#grid-search-for-topic-number" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Options to try with our LDA</span>
<span class="c1"># Beware it will try *all* of the combinations, so it&#39;ll take ages</span>
<span class="n">search_params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
  <span class="s1">&#39;learning_decay&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Set up LDA with the options we&#39;ll keep static</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;online&#39;</span><span class="p">)</span>

<span class="c1"># Try all of the options</span>
<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">search_params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>

<span class="c1"># What did we find?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Model&#39;s Params: &quot;</span><span class="p">,</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Log Likelihood Score: &quot;</span><span class="p">,</span> <span class="n">gridsearch</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 6 candidates, totalling 30 fits
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    5.6s finished
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best Model&#39;s Params:  {&#39;learning_decay&#39;: 0.7, &#39;n_components&#39;: 3}
Best Log Likelihood Score:  -7141.615202193745
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>

<span class="c1"># Use LDA to look for 5 topics</span>
<span class="n">n_topics</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;online&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">n_topics</span><span class="p">,</span> <span class="n">learning_decay</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">dt_matrix</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>

<span class="c1"># Print the top 10 words per topic</span>
<span class="n">n_words</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

<span class="n">topic_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">top_n</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">topic</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>
             <span class="p">[</span><span class="o">-</span><span class="n">n_words</span><span class="p">:]][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">top_features</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">top_n</span><span class="p">)</span>
    <span class="n">topic_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;topic_</span><span class="si">{</span><span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">top_n</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic </span><span class="si">{</span><span class="n">topic_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">top_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic 0: 人 時候 看 朋友 吃 時間 男友 故事 月 事
Topic 1: 蛋糕 人 吃 用 男友 買 唇膏 味道 者 看
Topic 2: 穿搭 人 感情 洋裝 草莓 包包 老師 買 穿 鞋子
CPU times: user 630 ms, sys: 4.09 ms, total: 634 ms
Wall time: 641 ms
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set it up as a dataframe</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dt_matrix</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_topics</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_axis</span> <span class="o">=</span> <span class="n">corpus_df2</span><span class="o">.</span><span class="n">index</span>
<span class="n">y_axis</span> <span class="o">=</span> <span class="n">features</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot a stackplot - https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/stackplot_demo.html</span>
<span class="n">ax</span><span class="o">.</span><span class="n">stackplot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">y_axis</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="s1">&#39;wiggle&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_axis</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Move the legend off of the chart</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7fb36b086080&gt;
</pre></div>
</div>
<img alt="../_images/topic-modeling-dcard_47_1.png" src="../_images/topic-modeling-dcard_47_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tmtoolkit.topicmod.evaluate</span> <span class="kn">import</span> <span class="n">metric_coherence_gensim</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">components_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.99622656, 4.43427231, 2.12298073, ..., 2.10537896, 4.59528939,
        1.20741198],
       [2.18366783, 0.65372205, 0.46146093, ..., 0.60133333, 2.12917148,
        1.24868343],
       [1.22940268, 2.75627593, 2.02141124, ..., 7.50715219, 1.86656863,
        0.50491256]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># lda_model - LatentDirichletAllocation()</span>
<span class="c1"># vect - CountVectorizer()</span>
<span class="c1"># texts - the list of tokenized words</span>
<span class="n">norm_corpus</span>
<span class="n">norm_corpus_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_corpus</span><span class="p">]</span>


<span class="n">metric_coherence_gensim</span><span class="p">(</span><span class="n">measure</span><span class="o">=</span><span class="s1">&#39;c_v&#39;</span><span class="p">,</span> 
                        <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                        <span class="n">topic_word_distrib</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> 
                        <span class="n">dtm</span><span class="o">=</span><span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">),</span> 
                        <span class="n">vocab</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()),</span> 
                        <span class="n">texts</span><span class="o">=</span><span class="n">norm_corpus_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.514889678590938, 0.21459892616206094, 0.24997943126350197]
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./exercise-ans"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>