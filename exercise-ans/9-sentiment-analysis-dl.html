
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Assignment IV: Sentiment Analysis Using Deep Learning &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/google-colab.html">
     Google Colab
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   1. Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   2. Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   3. Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-sklearn-classification.html">
   1. Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/topic-modeling-naive.html">
   2. Topic Modeling: A Naive Example
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-neural-network-from-scratch.html">
   1. Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-simple-case.html">
   2. Deep Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sentiment-case.html">
   3. Deep Learning: Sentiment Analysis
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Neural Language Model and Embeddings
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/dl-sequence-models-intuition.html">
   1. Sequence Models Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding.html">
   2. Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding-keras.html">
   3. Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-statistical-language-model.html">
   4. Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-language-model-primer.html">
   5. Neural Language Model: A Start
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Seq2Seq, Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types.html">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-attention-addition.html">
   Seqeunce Model with Attention for Addition Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-keras.html">
   Text Classification with Transformer
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   Assignment III: Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   Assignment IV: Chinese Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   Assignment V: Text Vectorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/6-machine-learning.html">
   Assignment VI: Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/midterm-exam.html">
   Midterm Exam
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/7-topic-modeling.html">
   Assignment VII: Topic Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/8-dl-chinese-name-gender.html">
   Assignment VIII: Deep Learning
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/exercise-ans/9-sentiment-analysis-dl.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/exercise-ans/9-sentiment-analysis-dl.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/exercise-ans/9-sentiment-analysis-dl.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-1">
   Question 1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#not-used">
     Not Used
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-word-embeddings">
   Training Word Embeddings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-pre-trained-word-embeddings">
   Loading Pre-trained Word Embeddings
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-model">
   Building Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-visualization">
   Model Visualization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-fitting">
   Model Fitting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-using-self-trained-word-embeddings">
     Fitting using self-trained word embeddings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-using-pre-trained-word-embedding-model">
     Fitting using pre-trained word embedding model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="assignment-iv-sentiment-analysis-using-deep-learning">
<h1>Assignment IV: Sentiment Analysis Using Deep Learning<a class="headerlink" href="#assignment-iv-sentiment-analysis-using-deep-learning" title="Permalink to this headline">¶</a></h1>
<div class="section" id="question-1">
<h2>Question 1<a class="headerlink" href="#question-1" title="Permalink to this headline">¶</a></h2>
<p>Build a movie review classifier using the dataset in <code class="docutils literal notranslate"><span class="pre">demo_data/movie_reviews.csv</span></code>. The objective of the classifier is to automatically classify a movie review into either positive or negative category.</p>
<p>The dataset is the famous IMBd moview reviews dataset. You can take a look at the SOTA classification performance on this dataset <a class="reference external" href="https://paperswithcode.com/sota/sentiment-analysis-on-imdb">here</a>.</p>
<p>In your experiments, please include the following strategies in your considerations:</p>
<ul class="simple">
<li><p>Please use sequence models for this task.</p></li>
<li><p>For embedding layers, please try both self-trained embedding layer along with the sentiment classifier, as well as pre-trained embeddings provided in <code class="docutils literal notranslate"><span class="pre">spacy</span></code>.</p></li>
<li><p>Please include dropout and regularization layers to avoid overfitting.</p></li>
</ul>
<ul class="simple">
<li><p>This tutorial uses Sarkar’s book example.</p></li>
<li><p>Simple Multilayer Deep Neural Network on Sentiment Classification</p></li>
<li><p>Use the average text embeddings based on word embeddings</p></li>
<li><p>Use both self-trained word embeddings and spacy embeddings.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="c1">## loading packages</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">keras.layers.normalization</span> <span class="kn">import</span> <span class="n">BatchNormalization</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1.17 ms, sys: 2.15 ms, total: 3.32 ms
Wall time: 83.8 ms
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="c1">## Loading the raw data and look at the structure of the data quickly</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../../../RepositoryData/data/movie_reviews.csv&#39;</span><span class="p">)</span>

<span class="c1"># take a peek at the data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1">## split reviews and sentiments</span>
<span class="n">reviews</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">])</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span> <span class="k">if</span> <span class="n">l</span><span class="o">==</span><span class="s2">&quot;negative&quot;</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;sentiment&#39;</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">reviews</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentiments</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># build train and test datasets</span>
<span class="n">train_reviews</span> <span class="o">=</span> <span class="n">reviews</span><span class="p">[:</span><span class="mi">35000</span><span class="p">]</span>
<span class="n">train_sentiments</span> <span class="o">=</span> <span class="n">sentiments</span><span class="p">[:</span><span class="mi">35000</span><span class="p">]</span>
<span class="n">test_reviews</span> <span class="o">=</span> <span class="n">reviews</span><span class="p">[</span><span class="mi">35000</span><span class="p">:]</span>
<span class="n">test_sentiments</span> <span class="o">=</span> <span class="n">sentiments</span><span class="p">[</span><span class="mi">35000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.4.1
                                              review sentiment
0  One of the other reviewers has mentioned that ...  positive
1  A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...  positive
2  I thought this was a wonderful way to spend ti...  positive
3  Basically there&#39;s a family where a little boy ...  negative
4  Petter Mattei&#39;s &quot;Love in the Time of Money&quot; is...  positive
(50000,)
(50000,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">TAWP</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">TAWP.contractions</span> <span class="kn">import</span> <span class="n">CONTRACTION_MAP</span>

<span class="k">def</span> <span class="nf">expand_contractions</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">contraction_mapping</span><span class="o">=</span><span class="n">CONTRACTION_MAP</span><span class="p">):</span>
    <span class="c1">## create a regex pattern of all contracted forms</span>
    <span class="n">contractions_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;(</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">contraction_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">())),</span>
                                      <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">expand_match</span><span class="p">(</span><span class="n">contraction</span><span class="p">):</span>
        <span class="n">match</span> <span class="o">=</span> <span class="n">contraction</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># the whole matched contraction</span>

        <span class="c1"># if the matched contraction (=keys) exists in the dict,</span>
        <span class="c1"># get its corresponding uncontracted form (=values)</span>
        <span class="n">expanded_contraction</span> <span class="o">=</span> <span class="n">contraction_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">match</span><span class="p">)</span>\
                                <span class="k">if</span> <span class="n">contraction_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">match</span><span class="p">)</span>\
                                <span class="k">else</span> <span class="n">contraction_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">match</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">expanded_contraction</span>

    <span class="c1"># find each contraction in the pattern,</span>
    <span class="c1"># find it from text,</span>
    <span class="c1"># and replace it using the output of</span>
    <span class="c1"># expand_match</span>
    <span class="n">expanded_text</span> <span class="o">=</span> <span class="n">contractions_pattern</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">expand_match</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">expanded_text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">expanded_text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expanded_text</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">expand_contractions</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&lt;.+?&gt;&#39;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
    
<span class="n">normalize_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_reviews</span><span class="p">[</span><span class="mi">101</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Okay, last night, August 18th, 2004, I had the distinct displeasure of meeting Mr. Van Bebble at a showing of the film The Manson Family at the Three Penny in Chicago as part of the Chicago Underground Film Festival. Here&#39;s what I have to say about it. First of all, the film is an obvious rip off of every Kenneth Anger, Roman Polanski, Oliver Stone and Terry Gilliam movie I&#39;ve ever seen. Second of all, in a short Q &amp; A session after the show Mr. Van Bebble immediately stated that he never made any contact with the actual Manson Family members or Charlie himself, calling them liars and saying he wanted nothing to do with them, that the film was based on his (Van Bebble&#39;s) take on the trial having seen it all from his living room on TV and in the news (and I&#39;m assuming from the Autobiography and the book Helter Skelter which were directly mimicked through the narrative). So I had second dibs on questions, I asked if he was trying to present the outsider, Mtv, sex drugs and rock &#39;n roll version and not necessarily the true story. This question obviously pissed off the by now sloshed director who started shouting &quot;f*** you, shut the f*** up, this is the truth! All those other movies are bullsh**!&quot;&lt;br /&gt;&lt;br /&gt;Well anyway, I didn&#39;t even think about how ridiculous this was until the next day when I read the tagline for the film, &quot;You&#39;ve heard the laws side of the story...now hear the story as it is told by the Manson Family.&quot; Excuse me, if this guy has never even spoken to the family and considers them to be liars that he doesn&#39;t want to have anything to do with, how in God&#39;s name can he tell the story for them!? This is the most ridiculous statement I have ever heard! The film was obviously catered to the sex drugs and rock &#39;n roll audience that it had no trouble in attracting to the small, dimly lit theatre, and was even more obviously spawned by the sex drugs and rock &#39;n roll mind of a man who couldn&#39;t even watch his own film without getting up every ten minutes to go get more beer or to shout some sort of Rocky Horroresque call line to the actors on screen. This film accomplishes little more than warping the public&#39;s image of actual events (which helped shape the state of America and much of the world today) into some sort of Slasher/Comic Book/Porno/Rape fantasy dreamed up by an obviously shallow individual.&lt;br /&gt;&lt;br /&gt;The film was definitely very impressive to look at. The soundtrack was refreshing as it contained actual samples of Charlie&#39;s work with the Family off of his Lie album. The editing was nice and choppy to simulate the nauseating uncertainty of most modern music videos. All in all this film would have made a much better addition to the catalogues at Mtv than to the Underground Film Festival or for that matter the minds of any intellectual observers. I felt like I was at a midnight Rocky Horror viewing the way the audience was dressed and behaving (probably the best part of the experience). The cast was very good with the exception of Charlie who resembled some sort of stoned Dungeons and Dragons enthusiast more than the actual role he was portraying. The descriptions the film gave of him as full of energy, throwing ten things at you and being very physical about it all the while did not match at all the slow, lethargic, and chubby representation that was actually presented.&lt;br /&gt;&lt;br /&gt;All in all the film basically explains itself as Sadie (or maybe it was Linda) declares at the end, &quot;You can write a bunch of bullsh** books or make a bunch of bullsh** movies...etc. etc.&quot; Case in point. Even the disclaimer &quot;Based on a True Story&quot; is a dead giveaway, signalling that somewhere beneath this psychedelic garbage heap lay the foundation of an actual story with content that will make and has made a difference in the world. All you have to do is a little bit of alchemy to separate the truth from the the crap, or actually, maybe you could just avoid it all together and go read a book instead.&lt;br /&gt;&lt;br /&gt;All I can say is this, when the film ended I got a free beer so I&#39;m glad I went, but not so glad I spent fifteen dollars on my ticket to be told to shut the f*** up for asking the director a question. Peace.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">normalize_corpus</span><span class="p">(</span><span class="n">train_reviews</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only &quot;has got all the polari&quot; but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great masters of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional dream techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwells murals decorating every surface) are terribly well done.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1">## Processing is ignored</span>
<span class="n">norm_train_reviews</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">train_reviews</span><span class="p">)</span>
<span class="n">norm_test_reviews</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">test_reviews</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 46s, sys: 979 ms, total: 1min 47s
Wall time: 1min 49s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NUM_WORDS</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">tokenizer</span><span class="o">=</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">NUM_WORDS</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">train_reviews</span><span class="p">)</span>

<span class="c1"># vocab_size = len(tokenizer.word_index) + 1</span>
<span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vocabulary Size: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vocabulary Size: 10001
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;the&#39;, 1),
 (&#39;and&#39;, 2),
 (&#39;a&#39;, 3),
 (&#39;of&#39;, 4),
 (&#39;to&#39;, 5),
 (&#39;is&#39;, 6),
 (&#39;br&#39;, 7),
 (&#39;in&#39;, 8),
 (&#39;it&#39;, 9),
 (&#39;i&#39;, 10)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reviews_to_sequences</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">200</span><span class="p">):</span>
    <span class="n">reviews_int</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">reviews</span><span class="p">)</span>
    <span class="n">reviews_pad</span> <span class="o">=</span> <span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">reviews_int</span><span class="p">,</span>
                           <span class="n">maxlen</span> <span class="o">=</span> <span class="n">MAX_LEN</span><span class="p">,</span> 
                           <span class="n">truncating</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> 
                           <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reviews_pad</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>


<span class="n">X_train</span> <span class="o">=</span> <span class="n">reviews_to_sequences</span><span class="p">(</span><span class="n">train_reviews</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">reviews_to_sequences</span><span class="p">(</span><span class="n">test_reviews</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">train_sentiments</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="c1">## sequences to one-hot</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">test_sentiments</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="c1">## sequences to one-hot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(35000, 200)
[[0. 1.]
 [0. 1.]
 [0. 1.]
 [1. 0.]
 [0. 1.]
 [0. 1.]
 [0. 1.]
 [1. 0.]
 [1. 0.]
 [0. 1.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># Plotting results</span>
<span class="k">def</span> <span class="nf">plot1</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>

    <span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1">## Accuracy plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="c1">## Loss plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    
<span class="k">def</span> <span class="nf">plot2</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1">#plt.gca().set_ylim(0,1)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_model_lstm</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="c1">#     model.add(Input(shape=(MAX_LEN,)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SpatialDropout1D</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">LSTM_DIM</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
<span class="k">def</span> <span class="nf">build_model_lstm_pretrained_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="c1">#     model.add(Input(shape=(MAX_LEN,)))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="n">train_emb</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SpatialDropout1D</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">LSTM_DIM</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">build_model_bilstm_pretrain_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">,</span> <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                       <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="n">train_emb</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">LSTM_DIM</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">LSTM_DIM</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Using Spacy embeddings</span>

<span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en_core_web_lg&#39;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;parser&#39;</span><span class="p">,</span> <span class="s1">&#39;tag&#39;</span><span class="p">,</span><span class="s1">&#39;entity&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w2id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>
<span class="n">id2w</span> <span class="o">=</span> <span class="p">{</span><span class="nb">id</span><span class="p">:</span><span class="n">w</span> <span class="k">for</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="nb">id</span><span class="p">)</span> <span class="ow">in</span> <span class="n">w2id</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## initialize word embedding matrix</span>
<span class="n">EMBED_DIM</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">))</span>
<span class="n">embedding_matrix</span><span class="o">.</span><span class="n">shape</span>
<span class="n">unk_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">unk_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">w2id</span><span class="p">)</span>
<span class="n">spacy_w2v</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">spacy_w2v</span> <span class="o">=</span> <span class="p">{</span><span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="n">wid</span><span class="p">]:</span><span class="n">wvec</span> <span class="k">for</span> <span class="p">(</span><span class="n">wid</span><span class="p">,</span> <span class="n">wvec</span><span class="p">)</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spacy_w2v</span><span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.27, -0.06, -0.19,  0.02, -0.02,  0.01, -0.14,  0.18,  0.18,  2.59],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;the&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">vector</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.27, -0.06, -0.19,  0.02, -0.02,  0.01, -0.14,  0.18,  0.18,  2.59],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">unk_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">unk_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">w2id</span><span class="o">.</span><span class="n">keys</span><span class="p">())[:</span><span class="mi">10000</span><span class="p">]:</span>
    <span class="n">cur_word_vec</span> <span class="o">=</span> <span class="n">spacy_w2v</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">cur_word_vec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cur_word_id</span> <span class="o">=</span> <span class="n">w2id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">cur_word_id</span><span class="p">]</span><span class="o">=</span><span class="n">cur_word_vec</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">unk_cnt</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="n">unk_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Unkown Words in IMDB:&quot;</span><span class="p">,</span> <span class="n">unk_cnt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Unkown Words in IMDB: 195
CPU times: user 30.2 ms, sys: 8.25 ms, total: 38.4 ms
Wall time: 37.4 ms
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Using GloVe Embeddings</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">glove_file</span> <span class="o">=</span> <span class="s2">&quot;../../../RepositoryData/data/glove/glove.6B/glove.6B.50d.txt&quot;</span>
<span class="n">glove_w2v</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">glove_file</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">vector</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="mi">50</span><span class="p">:</span>
            <span class="n">glove_w2v</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There was an issue with &quot;</span> <span class="o">+</span> <span class="n">word</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">glove_w2v</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>400000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1">## initialize word embedding matrix</span>
<span class="n">EMBED_DIM</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">embedding_matrix_glove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">))</span>
<span class="n">embedding_matrix_glove</span><span class="o">.</span><span class="n">shape</span>
<span class="n">unk_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">unk_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">w2id</span><span class="o">.</span><span class="n">keys</span><span class="p">())[:</span><span class="mi">10000</span><span class="p">]:</span>
    <span class="n">cur_word_vec</span> <span class="o">=</span> <span class="n">glove_w2v</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">cur_word_vec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cur_word_id</span> <span class="o">=</span> <span class="n">w2id</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">embedding_matrix_glove</span><span class="p">[</span><span class="n">cur_word_id</span><span class="p">]</span><span class="o">=</span><span class="n">cur_word_vec</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">unk_cnt</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="n">unk_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Unkown Words in IMDB (GloVe):&quot;</span><span class="p">,</span> <span class="n">unk_cnt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Unkown Words in IMDB (GloVe): 184
CPU times: user 22.1 ms, sys: 2.23 ms, total: 24.3 ms
Wall time: 22.4 ms
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Model Building</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">SpatialDropout1D</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">LSTM</span>

<span class="n">LSTM_DIM</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># total LSTM units</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">build_model_lstm</span><span class="p">()</span>
<span class="n">model2_1</span> <span class="o">=</span> <span class="n">build_model_lstm_pretrained_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model2_2</span> <span class="o">=</span> <span class="n">build_model_lstm_pretrained_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model3_1</span> <span class="o">=</span> <span class="n">build_model_bilstm_pretrain_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model3_2</span> <span class="o">=</span> <span class="n">build_model_bilstm_pretrain_emb</span><span class="p">(</span><span class="n">train_emb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">])</span>
<span class="n">model2_1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">])</span>
<span class="n">model2_2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">])</span>
<span class="n">model3_1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">])</span>
<span class="n">model3_2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EPOCH</span><span class="o">=</span> <span class="mi">10</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(35000, 200)
(35000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Model fitting</span>
<span class="n">history1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCH</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
110/110 [==============================] - 108s 950ms/step - loss: 0.5505 - accuracy: 0.6854 - precision: 0.6854 - recall: 0.6854 - val_loss: 0.2941 - val_accuracy: 0.8789 - val_precision: 0.8789 - val_recall: 0.8789
Epoch 2/10
110/110 [==============================] - 94s 856ms/step - loss: 0.2328 - accuracy: 0.9103 - precision: 0.9103 - recall: 0.9103 - val_loss: 0.2995 - val_accuracy: 0.8806 - val_precision: 0.8806 - val_recall: 0.8806
Epoch 3/10
110/110 [==============================] - 93s 847ms/step - loss: 0.1613 - accuracy: 0.9425 - precision: 0.9425 - recall: 0.9425 - val_loss: 0.3269 - val_accuracy: 0.8761 - val_precision: 0.8761 - val_recall: 0.8761
Epoch 4/10
110/110 [==============================] - 97s 879ms/step - loss: 0.1191 - accuracy: 0.9585 - precision: 0.9585 - recall: 0.9585 - val_loss: 0.3472 - val_accuracy: 0.8687 - val_precision: 0.8687 - val_recall: 0.8687
Epoch 5/10
110/110 [==============================] - 100s 906ms/step - loss: 0.0961 - accuracy: 0.9676 - precision: 0.9676 - recall: 0.9676 - val_loss: 0.4318 - val_accuracy: 0.8696 - val_precision: 0.8696 - val_recall: 0.8696
Epoch 6/10
110/110 [==============================] - 95s 864ms/step - loss: 0.0718 - accuracy: 0.9776 - precision: 0.9776 - recall: 0.9776 - val_loss: 0.5271 - val_accuracy: 0.8674 - val_precision: 0.8674 - val_recall: 0.8674
Epoch 7/10
110/110 [==============================] - 95s 863ms/step - loss: 0.0491 - accuracy: 0.9843 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.6444 - val_accuracy: 0.8630 - val_precision: 0.8630 - val_recall: 0.8630
Epoch 8/10
110/110 [==============================] - 96s 870ms/step - loss: 0.0571 - accuracy: 0.9828 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.6434 - val_accuracy: 0.8631 - val_precision: 0.8631 - val_recall: 0.8631
Epoch 9/10
110/110 [==============================] - 95s 862ms/step - loss: 0.0586 - accuracy: 0.9796 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.6003 - val_accuracy: 0.8641 - val_precision: 0.8641 - val_recall: 0.8641
Epoch 10/10
110/110 [==============================] - 96s 869ms/step - loss: 0.0401 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.6364 - val_accuracy: 0.8614 - val_precision: 0.8614 - val_recall: 0.8614
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Model fitting</span>
<span class="n">history2_1</span> <span class="o">=</span> <span class="n">model2_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCH</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">## Model fitting</span>
<span class="n">history2_2</span> <span class="o">=</span> <span class="n">model2_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCH</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">## Model fitting</span>
<span class="n">history3_1</span> <span class="o">=</span> <span class="n">model3_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCH</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1">## Model fitting</span>
<span class="n">history3_2</span> <span class="o">=</span> <span class="n">model3_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                   <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCH</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
                   <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
110/110 [==============================] - 72s 631ms/step - loss: 0.5914 - accuracy: 0.6749 - precision: 0.6749 - recall: 0.6749 - val_loss: 0.4497 - val_accuracy: 0.8114 - val_precision: 0.8114 - val_recall: 0.8114
Epoch 2/10
110/110 [==============================] - 69s 624ms/step - loss: 0.4381 - accuracy: 0.8005 - precision: 0.8005 - recall: 0.8005 - val_loss: 0.3674 - val_accuracy: 0.8436 - val_precision: 0.8436 - val_recall: 0.8436
Epoch 3/10
110/110 [==============================] - 67s 605ms/step - loss: 0.4047 - accuracy: 0.8185 - precision: 0.8185 - recall: 0.8185 - val_loss: 0.4159 - val_accuracy: 0.8387 - val_precision: 0.8387 - val_recall: 0.8387
Epoch 4/10
110/110 [==============================] - 67s 613ms/step - loss: 0.3609 - accuracy: 0.8424 - precision: 0.8424 - recall: 0.8424 - val_loss: 0.3186 - val_accuracy: 0.8666 - val_precision: 0.8666 - val_recall: 0.8666
Epoch 5/10
110/110 [==============================] - 70s 633ms/step - loss: 0.3333 - accuracy: 0.8537 - precision: 0.8537 - recall: 0.8537 - val_loss: 0.3276 - val_accuracy: 0.8671 - val_precision: 0.8671 - val_recall: 0.8671
Epoch 6/10
110/110 [==============================] - 70s 633ms/step - loss: 0.3136 - accuracy: 0.8661 - precision: 0.8661 - recall: 0.8661 - val_loss: 0.3086 - val_accuracy: 0.8704 - val_precision: 0.8704 - val_recall: 0.8704
Epoch 7/10
110/110 [==============================] - 69s 631ms/step - loss: 0.3100 - accuracy: 0.8701 - precision: 0.8701 - recall: 0.8701 - val_loss: 0.2856 - val_accuracy: 0.8823 - val_precision: 0.8823 - val_recall: 0.8823
Epoch 8/10
110/110 [==============================] - 69s 628ms/step - loss: 0.2950 - accuracy: 0.8782 - precision: 0.8782 - recall: 0.8782 - val_loss: 0.2882 - val_accuracy: 0.8821 - val_precision: 0.8821 - val_recall: 0.8821
Epoch 9/10
110/110 [==============================] - 70s 633ms/step - loss: 0.2751 - accuracy: 0.8845 - precision: 0.8845 - recall: 0.8845 - val_loss: 0.2682 - val_accuracy: 0.8874 - val_precision: 0.8874 - val_recall: 0.8874
Epoch 10/10
110/110 [==============================] - 69s 631ms/step - loss: 0.2803 - accuracy: 0.8826 - precision: 0.8826 - recall: 0.8826 - val_loss: 0.2666 - val_accuracy: 0.8920 - val_precision: 0.8920 - val_recall: 0.8920
Epoch 1/10
110/110 [==============================] - 95s 839ms/step - loss: 0.5951 - accuracy: 0.6600 - precision: 0.6600 - recall: 0.6600 - val_loss: 0.3901 - val_accuracy: 0.8399 - val_precision: 0.8399 - val_recall: 0.8399
Epoch 2/10
110/110 [==============================] - 96s 870ms/step - loss: 0.3689 - accuracy: 0.8423 - precision: 0.8423 - recall: 0.8423 - val_loss: 0.3005 - val_accuracy: 0.8759 - val_precision: 0.8759 - val_recall: 0.8759
Epoch 3/10
110/110 [==============================] - 90s 814ms/step - loss: 0.2839 - accuracy: 0.8844 - precision: 0.8844 - recall: 0.8844 - val_loss: 0.2827 - val_accuracy: 0.8826 - val_precision: 0.8826 - val_recall: 0.8826
Epoch 4/10
110/110 [==============================] - 89s 809ms/step - loss: 0.2422 - accuracy: 0.9041 - precision: 0.9041 - recall: 0.9041 - val_loss: 0.2937 - val_accuracy: 0.8849 - val_precision: 0.8849 - val_recall: 0.8849
Epoch 5/10
110/110 [==============================] - 88s 797ms/step - loss: 0.2032 - accuracy: 0.9195 - precision: 0.9195 - recall: 0.9195 - val_loss: 0.2842 - val_accuracy: 0.8919 - val_precision: 0.8919 - val_recall: 0.8919
Epoch 6/10
110/110 [==============================] - 88s 802ms/step - loss: 0.1677 - accuracy: 0.9367 - precision: 0.9367 - recall: 0.9367 - val_loss: 0.2786 - val_accuracy: 0.8931 - val_precision: 0.8931 - val_recall: 0.8931
Epoch 7/10
110/110 [==============================] - 92s 836ms/step - loss: 0.1488 - accuracy: 0.9445 - precision: 0.9445 - recall: 0.9445 - val_loss: 0.2931 - val_accuracy: 0.8913 - val_precision: 0.8913 - val_recall: 0.8913
Epoch 8/10
110/110 [==============================] - 89s 808ms/step - loss: 0.1286 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - val_loss: 0.3373 - val_accuracy: 0.8914 - val_precision: 0.8914 - val_recall: 0.8914
Epoch 9/10
110/110 [==============================] - 89s 812ms/step - loss: 0.1097 - accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - val_loss: 0.3927 - val_accuracy: 0.8863 - val_precision: 0.8863 - val_recall: 0.8863
Epoch 10/10
110/110 [==============================] - 89s 814ms/step - loss: 0.0859 - accuracy: 0.9696 - precision: 0.9696 - recall: 0.9696 - val_loss: 0.3883 - val_accuracy: 0.8891 - val_precision: 0.8891 - val_recall: 0.8891
Epoch 1/10
110/110 [==============================] - 180s 2s/step - loss: 0.5632 - accuracy: 0.6877 - precision: 0.6877 - recall: 0.6877 - val_loss: 0.4038 - val_accuracy: 0.8300 - val_precision: 0.8300 - val_recall: 0.8300
Epoch 2/10
110/110 [==============================] - 161s 1s/step - loss: 0.3872 - accuracy: 0.8305 - precision: 0.8305 - recall: 0.8305 - val_loss: 0.3760 - val_accuracy: 0.8443 - val_precision: 0.8443 - val_recall: 0.8443
Epoch 3/10
110/110 [==============================] - 161s 1s/step - loss: 0.3583 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - val_loss: 0.3281 - val_accuracy: 0.8653 - val_precision: 0.8653 - val_recall: 0.8653
Epoch 4/10
110/110 [==============================] - 160s 1s/step - loss: 0.3193 - accuracy: 0.8642 - precision: 0.8642 - recall: 0.8642 - val_loss: 0.2916 - val_accuracy: 0.8764 - val_precision: 0.8764 - val_recall: 0.8764
Epoch 5/10
110/110 [==============================] - 160s 1s/step - loss: 0.3055 - accuracy: 0.8700 - precision: 0.8700 - recall: 0.8700 - val_loss: 0.2846 - val_accuracy: 0.8786 - val_precision: 0.8786 - val_recall: 0.8786
Epoch 6/10
110/110 [==============================] - 159s 1s/step - loss: 0.2948 - accuracy: 0.8748 - precision: 0.8748 - recall: 0.8748 - val_loss: 0.2854 - val_accuracy: 0.8831 - val_precision: 0.8831 - val_recall: 0.8831
Epoch 7/10
110/110 [==============================] - 160s 1s/step - loss: 0.2793 - accuracy: 0.8835 - precision: 0.8835 - recall: 0.8835 - val_loss: 0.2908 - val_accuracy: 0.8756 - val_precision: 0.8756 - val_recall: 0.8756
Epoch 8/10
110/110 [==============================] - 160s 1s/step - loss: 0.2680 - accuracy: 0.8898 - precision: 0.8898 - recall: 0.8898 - val_loss: 0.3139 - val_accuracy: 0.8746 - val_precision: 0.8746 - val_recall: 0.8746
Epoch 9/10
110/110 [==============================] - 159s 1s/step - loss: 0.2602 - accuracy: 0.8926 - precision: 0.8926 - recall: 0.8926 - val_loss: 0.2968 - val_accuracy: 0.8739 - val_precision: 0.8739 - val_recall: 0.8739
Epoch 10/10
110/110 [==============================] - 161s 1s/step - loss: 0.2485 - accuracy: 0.8964 - precision: 0.8964 - recall: 0.8964 - val_loss: 0.3286 - val_accuracy: 0.8629 - val_precision: 0.8629 - val_recall: 0.8629
Epoch 1/10
110/110 [==============================] - 209s 2s/step - loss: 0.5685 - accuracy: 0.6718 - precision: 0.6718 - recall: 0.6718 - val_loss: 0.3602 - val_accuracy: 0.8637 - val_precision: 0.8637 - val_recall: 0.8637
Epoch 2/10
110/110 [==============================] - 192s 2s/step - loss: 0.3002 - accuracy: 0.8747 - precision: 0.8747 - recall: 0.8747 - val_loss: 0.3376 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814
Epoch 3/10
110/110 [==============================] - 192s 2s/step - loss: 0.2432 - accuracy: 0.9032 - precision: 0.9032 - recall: 0.9032 - val_loss: 0.3058 - val_accuracy: 0.8927 - val_precision: 0.8927 - val_recall: 0.8927
Epoch 4/10
110/110 [==============================] - 191s 2s/step - loss: 0.2138 - accuracy: 0.9174 - precision: 0.9174 - recall: 0.9174 - val_loss: 0.3465 - val_accuracy: 0.8860 - val_precision: 0.8860 - val_recall: 0.8860
Epoch 5/10
110/110 [==============================] - 191s 2s/step - loss: 0.1879 - accuracy: 0.9290 - precision: 0.9290 - recall: 0.9290 - val_loss: 0.3440 - val_accuracy: 0.8830 - val_precision: 0.8830 - val_recall: 0.8830
Epoch 6/10
110/110 [==============================] - 191s 2s/step - loss: 0.1704 - accuracy: 0.9338 - precision: 0.9338 - recall: 0.9338 - val_loss: 0.3493 - val_accuracy: 0.8900 - val_precision: 0.8900 - val_recall: 0.8900
Epoch 7/10
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>110/110 [==============================] - 191s 2s/step - loss: 0.1355 - accuracy: 0.9492 - precision: 0.9492 - recall: 0.9492 - val_loss: 0.3669 - val_accuracy: 0.8934 - val_precision: 0.8934 - val_recall: 0.8934
Epoch 8/10
110/110 [==============================] - 192s 2s/step - loss: 0.1209 - accuracy: 0.9582 - precision: 0.9582 - recall: 0.9582 - val_loss: 0.3839 - val_accuracy: 0.8936 - val_precision: 0.8936 - val_recall: 0.8936
Epoch 9/10
110/110 [==============================] - 193s 2s/step - loss: 0.1027 - accuracy: 0.9629 - precision: 0.9629 - recall: 0.9629 - val_loss: 0.3863 - val_accuracy: 0.8921 - val_precision: 0.8921 - val_recall: 0.8921
Epoch 10/10
110/110 [==============================] - 191s 2s/step - loss: 0.0878 - accuracy: 0.9685 - precision: 0.9685 - recall: 0.9685 - val_loss: 0.4229 - val_accuracy: 0.8911 - val_precision: 0.8911 - val_recall: 0.8911
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot1</span><span class="p">(</span><span class="n">history1</span><span class="p">)</span>
<span class="n">plot1</span><span class="p">(</span><span class="n">history2_1</span><span class="p">)</span>
<span class="n">plot1</span><span class="p">(</span><span class="n">history3_1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9-sentiment-analysis-dl_30_0.png" src="../_images/9-sentiment-analysis-dl_30_0.png" />
<img alt="../_images/9-sentiment-analysis-dl_30_1.png" src="../_images/9-sentiment-analysis-dl_30_1.png" />
<img alt="../_images/9-sentiment-analysis-dl_30_2.png" src="../_images/9-sentiment-analysis-dl_30_2.png" />
<img alt="../_images/9-sentiment-analysis-dl_30_3.png" src="../_images/9-sentiment-analysis-dl_30_3.png" />
<img alt="../_images/9-sentiment-analysis-dl_30_4.png" src="../_images/9-sentiment-analysis-dl_30_4.png" />
<img alt="../_images/9-sentiment-analysis-dl_30_5.png" src="../_images/9-sentiment-analysis-dl_30_5.png" />
</div>
</div>
<div class="section" id="not-used">
<h3>Not Used<a class="headerlink" href="#not-used" title="Permalink to this headline">¶</a></h3>
<p>The following codes are from Sarkar’s book. I am not going to use the following codes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from nltk.tokenize.toktok import ToktokTokenizer</span>

<span class="c1"># tokenizer = ToktokTokenizer()</span>

<span class="c1"># # tokenize train reviews &amp; encode train labels</span>
<span class="c1"># tokenized_train = [tokenizer.tokenize(text)</span>
<span class="c1">#                    for text in norm_train_reviews]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Convert sentiments into one-hot encodings</span>
<span class="c1">## labels to integers to one-hot</span>
<span class="c1">#le = LabelEncoder() ## label to sequences</span>
<span class="c1">#num_classes=2 </span>
<span class="c1">#y_tr = le.fit_transform(train_sentiments)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">train_sentiments</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="c1">## sequences to one-hot</span>

<span class="c1">#print(y_tr[:5])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0. 1.]
 [0. 1.]
 [0. 1.]
 [1. 0.]
 [0. 1.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tokenize test reviews &amp; encode test labels</span>
<span class="n">tokenized_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
                   <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">norm_test_reviews</span><span class="p">]</span>

<span class="c1">#y_ts = le.fit_transform(test_sentiments)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">test_sentiments</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>



<span class="c1"># print class label encoding map and encoded labels</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentiment class label map:&#39;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">le</span><span class="o">.</span><span class="n">classes_</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample test label transformation:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">+</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">35</span><span class="p">,</span>
      <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Actual Labels:&#39;</span><span class="p">,</span> <span class="n">test_sentiments</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Encoded Labels:&#39;</span><span class="p">,</span> <span class="n">y_ts</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> 
      <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">One hot encoded Labels:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sentiment class label map: {&#39;negative&#39;: 0, &#39;positive&#39;: 1}
Sample test label transformation:
----------------------------------- 
Actual Labels: [0 1 0] 
Encoded Labels: [0 1 0] 
One hot encoded Labels:
 [[1. 0.]
 [0. 1.]
 [1. 0.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized_train_len</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">tokenized_train</span><span class="p">]</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">tokenized_train_len</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x7ff630a27e80&gt;
</pre></div>
</div>
<img alt="../_images/9-sentiment-analysis-dl_40_1.png" src="../_images/9-sentiment-analysis-dl_40_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## min and max text lengths in training set</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">tokenized_train_len</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">tokenized_train_len</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
2594
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="training-word-embeddings">
<h2>Training Word Embeddings<a class="headerlink" href="#training-word-embeddings" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Training the word embeddings using skip-gram on the training set</p></li>
<li><p>Compute the average of embeddings for each document in the training and testing set</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># build word2vec model</span>
<span class="n">embed_dim</span> <span class="o">=</span> <span class="mi">96</span>
<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">tokenized_train</span><span class="p">,</span>
                                   <span class="n">size</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
                                   <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                   <span class="n">max_vocab_size</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span>
                                   <span class="n">min_count</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                   <span class="n">sample</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                                   <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                   <span class="n">sg</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># `sg=0` for BOW; `sg=1` for skipgram</span>

<span class="c1">## takes 5mins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 50.1 s, sys: 408 ms, total: 50.5 s
Wall time: 16.9 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## This model uses the document word vector averaging scheme</span>
<span class="c1">## Use the average word vector representations to represent one document (movie reivew)</span>

<span class="k">def</span> <span class="nf">averaged_word2vec_vectorizer</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
    <span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">index2word</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">average_word_vectors</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
        <span class="n">nwords</span> <span class="o">=</span> <span class="mf">0.</span>
        
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span> 
                <span class="n">nwords</span> <span class="o">=</span> <span class="n">nwords</span> <span class="o">+</span> <span class="mf">1.</span>
                <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">feature_vector</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">nwords</span><span class="p">:</span>
            <span class="n">feature_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">feature_vector</span><span class="p">,</span> <span class="n">nwords</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">feature_vector</span>
    
    <span class="c1"># For each text in the corpus</span>
    <span class="c1"># Find the embeddings of each word in the corpus</span>
    <span class="c1"># and add all word vectors together and take the average</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">average_word_vectors</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">tokenized_sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># generate averaged word vector features from word2vec model</span>
<span class="n">avg_wv_train_features</span> <span class="o">=</span> <span class="n">averaged_word2vec_vectorizer</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">tokenized_train</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">w2v_model</span><span class="p">,</span>
                                                     <span class="n">num_features</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">)</span>
<span class="n">avg_wv_test_features</span> <span class="o">=</span> <span class="n">averaged_word2vec_vectorizer</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">tokenized_test</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">w2v_model</span><span class="p">,</span>
                                                    <span class="n">num_features</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 54.7 s, sys: 605 ms, total: 55.3 s
Wall time: 55.4 s
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="loading-pre-trained-word-embeddings">
<h2>Loading Pre-trained Word Embeddings<a class="headerlink" href="#loading-pre-trained-word-embeddings" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Load the GloVe embeddings from <code class="docutils literal notranslate"><span class="pre">spacy</span></code>. (The embedding dimension size of the small language model is 96).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">spacy</span></code> computes the average embeddings for each document.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># Use the N-dimensional word vectors trained on the Common Crawl using the GloVe model</span>
<span class="c1"># Provided by spaCy</span>

<span class="kn">import</span> <span class="nn">spacy</span>
<span class="c1">#nlp = spacy.load(&#39;en&#39;, parse=False, tag=False, entity=False)</span>
<span class="n">nlp_vec</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en_core_web_sm&#39;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;parser&#39;</span><span class="p">,</span> <span class="s1">&#39;tag&#39;</span><span class="p">,</span><span class="s1">&#39;entity&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1.87 s, sys: 428 ms, total: 2.3 s
Wall time: 28.6 s
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>spacy will automatically compute the average embeddings for the document.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span><span class="n">nlp_vec</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">norm_train_reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">doc</span><span class="o">.</span><span class="n">vector</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.18,  0.04,  0.03, -0.11,  0.1 ,  0.11, -0.09,  0.09,  0.19, -0.28,
       -0.04, -0.  , -0.18, -0.08,  0.01,  0.04,  0.09, -0.17,  0.15,  0.  ,
       -0.12,  0.16,  0.08,  0.09, -0.3 , -0.02, -0.08,  0.22,  0.05,  0.25,
       -0.17,  0.01,  0.06, -0.27,  0.24, -0.06,  0.23, -0.07,  0.04,  0.17,
        0.01, -0.06, -0.01, -0.03, -0.02, -0.12,  0.1 ,  0.03, -0.07, -0.03,
        0.26,  0.02, -0.22, -0.17,  0.03,  0.15,  0.13,  0.04,  0.16,  0.14,
       -0.04, -0.2 , -0.06, -0.06,  0.1 , -0.09, -0.07, -0.19,  0.05,  0.15,
        0.19, -0.06,  0.04, -0.17, -0.17, -0.03, -0.15, -0.19, -0.09, -0.02,
       -0.03,  0.22,  0.16,  0.06, -0.07, -0.16, -0.14, -0.25, -0.15, -0.25,
       -0.16,  0.12,  0.18,  0.07,  0.14, -0.1 ], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">train_docs</span> <span class="o">=</span> <span class="n">nlp_vec</span><span class="o">.</span><span class="n">pipe</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">norm_train_reviews</span><span class="p">],</span> <span class="n">n_process</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">train_glove_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">vector</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">train_docs</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 57s, sys: 29 s, total: 2min 26s
Wall time: 5min 34s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">test_docs</span> <span class="o">=</span> <span class="n">nlp_vec</span><span class="o">.</span><span class="n">pipe</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">norm_test_reviews</span><span class="p">],</span> <span class="n">n_process</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">test_glove_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">vector</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_docs</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 48.7 s, sys: 17.6 s, total: 1min 6s
Wall time: 2min 28s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Word2Vec model:&gt; Train features shape:&#39;</span><span class="p">,</span> <span class="n">avg_wv_train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39; Test features shape:&#39;</span><span class="p">,</span> <span class="n">avg_wv_test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;GloVe model:&gt; Train features shape:&#39;</span><span class="p">,</span> <span class="n">train_glove_features</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39; Test features shape:&#39;</span><span class="p">,</span> <span class="n">test_glove_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Word2Vec model:&gt; Train features shape: (35000, 96)  Test features shape: (15000, 96)
GloVe model:&gt; Train features shape: (35000, 96)  Test features shape: (15000, 96)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="building-model">
<h2>Building Model<a class="headerlink" href="#building-model" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>A simple fully-connected 4 layer deep neural network</p>
<ul>
<li><p>input layer (not counted as one layer), i.e., the word embedding layer</p></li>
<li><p>three dense hidden layers (with 512 neurons)</p></li>
<li><p>one output layer (with 2 neurons for classification)</p></li>
</ul>
</li>
<li><p>(aka. multi-layered perceptron or deep ANN)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># Plotting results</span>
<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>

    <span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1">## Accuracy plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation acc&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="c1">## Loss plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    
<span class="k">def</span> <span class="nf">plot2</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1">#plt.gca().set_ylim(0,1)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">construct_deepnn_architecture</span><span class="p">(</span><span class="n">num_input_features</span><span class="p">):</span>
    <span class="n">dnn_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_input_features</span><span class="p">,),</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span> <span class="c1"># improve  stability of the network.</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span> <span class="c1"># relu better than sigmoid, to present vanishing gradient problem</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span> <span class="c1"># prevents overfitting</span>
    
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">dnn_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

    <span class="n">dnn_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>                 
                      <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">dnn_model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w2v_dnn</span> <span class="o">=</span> <span class="n">construct_deepnn_architecture</span><span class="p">(</span><span class="n">num_input_features</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-visualization">
<h2>Model Visualization<a class="headerlink" href="#model-visualization" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>To make this work, install <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">pydot</span></code></p></li>
<li><p>and also install <code class="docutils literal notranslate"><span class="pre">!brew</span> <span class="pre">install</span> <span class="pre">graphviz</span></code> in terminal for mac</p>
<ul>
<li><p>that is, install <a class="reference external" href="https://graphviz.gitlab.io/download/">graphvis</a></p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">w2v_dnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9-sentiment-analysis-dl_61_0.png" src="../_images/9-sentiment-analysis-dl_61_0.png" />
</div>
</div>
</div>
<div class="section" id="model-fitting">
<h2>Model Fitting<a class="headerlink" href="#model-fitting" title="Permalink to this headline">¶</a></h2>
<div class="section" id="fitting-using-self-trained-word-embeddings">
<h3>Fitting using self-trained word embeddings<a class="headerlink" href="#fitting-using-self-trained-word-embeddings" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">history</span> <span class="o">=</span><span class="n">w2v_dnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">avg_wv_train_features</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
247/247 [==============================] - 10s 17ms/step - loss: 0.5071 - accuracy: 0.7677 - val_loss: 0.4319 - val_accuracy: 0.8289
Epoch 2/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3934 - accuracy: 0.8242 - val_loss: 0.3856 - val_accuracy: 0.8240
Epoch 3/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3675 - accuracy: 0.8375 - val_loss: 0.3663 - val_accuracy: 0.8400
Epoch 4/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3616 - accuracy: 0.8386 - val_loss: 0.3763 - val_accuracy: 0.8369
Epoch 5/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3531 - accuracy: 0.8485 - val_loss: 0.3745 - val_accuracy: 0.8294
Epoch 6/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3502 - accuracy: 0.8476 - val_loss: 0.4002 - val_accuracy: 0.8157
Epoch 7/10
247/247 [==============================] - 3s 10ms/step - loss: 0.3498 - accuracy: 0.8477 - val_loss: 0.3826 - val_accuracy: 0.8254
Epoch 8/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3359 - accuracy: 0.8519 - val_loss: 0.4307 - val_accuracy: 0.8000
Epoch 9/10
247/247 [==============================] - 2s 10ms/step - loss: 0.3318 - accuracy: 0.8556 - val_loss: 0.4055 - val_accuracy: 0.8120
Epoch 10/10
247/247 [==============================] - 3s 10ms/step - loss: 0.3338 - accuracy: 0.8530 - val_loss: 0.3838 - val_accuracy: 0.8246
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot2</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9-sentiment-analysis-dl_65_0.png" src="../_images/9-sentiment-analysis-dl_65_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">w2v_dnn</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">avg_wv_test_features</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Alvin/opt/anaconda3/envs/python-notes/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&quot;int32&quot;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># functions from Text Analytics with Python book</span>
<span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">):</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> 
                                               <span class="n">predicted_labels</span><span class="p">),</span>
                        <span class="mi">4</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> 
                                               <span class="n">predicted_labels</span><span class="p">,</span>
                                               <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
                        <span class="mi">4</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Recall:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> 
                                               <span class="n">predicted_labels</span><span class="p">,</span>
                                               <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
                        <span class="mi">4</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;F1 Score:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> 
                                               <span class="n">predicted_labels</span><span class="p">,</span>
                                               <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
                        <span class="mi">4</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">display_confusion_matrix</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]):</span>
    
    <span class="n">total_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
    <span class="n">level_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">total_classes</span><span class="o">*</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">total_classes</span><span class="p">))]</span>

    <span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">predicted_labels</span><span class="p">,</span> 
                                  <span class="n">labels</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="n">cm_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> 
                            <span class="n">columns</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="p">(</span><span class="n">levels</span><span class="o">=</span><span class="p">[[</span><span class="s1">&#39;Predicted:&#39;</span><span class="p">],</span> <span class="n">classes</span><span class="p">],</span> 
                                                  <span class="n">codes</span><span class="o">=</span><span class="n">level_labels</span><span class="p">),</span> 
                            <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="p">(</span><span class="n">levels</span><span class="o">=</span><span class="p">[[</span><span class="s1">&#39;Actual:&#39;</span><span class="p">],</span> <span class="n">classes</span><span class="p">],</span> 
                                                <span class="n">codes</span><span class="o">=</span><span class="n">level_labels</span><span class="p">))</span> 
    <span class="nb">print</span><span class="p">(</span><span class="n">cm_frame</span><span class="p">)</span> 
<span class="k">def</span> <span class="nf">display_classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]):</span>

    <span class="n">report</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">true_labels</span><span class="p">,</span> 
                                           <span class="n">y_pred</span><span class="o">=</span><span class="n">predicted_labels</span><span class="p">,</span> 
                                           <span class="n">labels</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
    
    
    
<span class="k">def</span> <span class="nf">display_model_performance_metrics</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Performance metrics:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">get_metrics</span><span class="p">(</span><span class="n">true_labels</span><span class="o">=</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="o">=</span><span class="n">predicted_labels</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Model Classification report:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">display_classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="o">=</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="o">=</span><span class="n">predicted_labels</span><span class="p">,</span> 
                                  <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction Confusion Matrix:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">display_confusion_matrix</span><span class="p">(</span><span class="n">true_labels</span><span class="o">=</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="o">=</span><span class="n">predicted_labels</span><span class="p">,</span> 
                             <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_model_performance_metrics</span><span class="p">(</span><span class="n">true_labels</span><span class="o">=</span><span class="n">test_sentiments</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> 
                                      <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">])</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model Performance metrics:
------------------------------
Accuracy: 0.8216
Precision: 0.8253
Recall: 0.8216
F1 Score: 0.8211

Model Classification report:
------------------------------
              precision    recall  f1-score   support

    negative       0.79      0.87      0.83      7490
    positive       0.86      0.77      0.81      7510

    accuracy                           0.82     15000
   macro avg       0.83      0.82      0.82     15000
weighted avg       0.83      0.82      0.82     15000


Prediction Confusion Matrix:
------------------------------
                 Predicted:         
                   negative positive
Actual: negative       6548      942
        positive       1734     5776
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="fitting-using-pre-trained-word-embedding-model">
<h3>Fitting using pre-trained word embedding model<a class="headerlink" href="#fitting-using-pre-trained-word-embedding-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">glove_dnn</span> <span class="o">=</span> <span class="n">construct_deepnn_architecture</span><span class="p">(</span><span class="n">num_input_features</span><span class="o">=</span><span class="mi">96</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">history2</span><span class="o">=</span><span class="n">glove_dnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_glove_features</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
247/247 [==============================] - 4s 11ms/step - loss: 0.7172 - accuracy: 0.6316 - val_loss: 0.6476 - val_accuracy: 0.6120
Epoch 2/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5890 - accuracy: 0.6921 - val_loss: 0.6032 - val_accuracy: 0.6734
Epoch 3/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5716 - accuracy: 0.7039 - val_loss: 0.5850 - val_accuracy: 0.6883
Epoch 4/10
247/247 [==============================] - 3s 11ms/step - loss: 0.5606 - accuracy: 0.7137 - val_loss: 0.6039 - val_accuracy: 0.6743
Epoch 5/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5480 - accuracy: 0.7221 - val_loss: 0.6082 - val_accuracy: 0.6817
Epoch 6/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5381 - accuracy: 0.7284 - val_loss: 0.5864 - val_accuracy: 0.6897
Epoch 7/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5367 - accuracy: 0.7302 - val_loss: 0.5882 - val_accuracy: 0.6957
Epoch 8/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5330 - accuracy: 0.7346 - val_loss: 0.6167 - val_accuracy: 0.6869
Epoch 9/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5178 - accuracy: 0.7461 - val_loss: 0.6080 - val_accuracy: 0.6766
Epoch 10/10
247/247 [==============================] - 2s 10ms/step - loss: 0.5100 - accuracy: 0.7491 - val_loss: 0.5948 - val_accuracy: 0.6894
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot2</span><span class="p">(</span><span class="n">history2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9-sentiment-analysis-dl_72_0.png" src="../_images/9-sentiment-analysis-dl_72_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">glove_dnn</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">test_glove_features</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/Alvin/opt/anaconda3/envs/python-notes/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&quot;int32&quot;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_model_performance_metrics</span><span class="p">(</span><span class="n">true_labels</span><span class="o">=</span><span class="n">test_sentiments</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> 
                                      <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">])</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model Performance metrics:
------------------------------
Accuracy: 0.7011
Precision: 0.7012
Recall: 0.7011
F1 Score: 0.701

Model Classification report:
------------------------------
              precision    recall  f1-score   support

    negative       0.71      0.69      0.70      7490
    positive       0.70      0.72      0.71      7510

    accuracy                           0.70     15000
   macro avg       0.70      0.70      0.70     15000
weighted avg       0.70      0.70      0.70     15000


Prediction Confusion Matrix:
------------------------------
                 Predicted:         
                   negative positive
Actual: negative       5134     2356
        positive       2128     5382
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://paperswithcode.com/sota/sentiment-analysis-on-imdb">State of Arts on this dataset</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./exercise-ans"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>