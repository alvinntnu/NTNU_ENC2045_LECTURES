
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chinese Language Processing &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-nlp-case.html">
   Machine Learning: NLP Tasks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/ml-sklearn-classification.html">
   Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-classification-ml-newsgroups.html">
   Text Classification Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/topic-modeling-naive.html">
   Topic Modeling: A Naive Example
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-network-from-scratch.html">
   Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding.html">
   Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding-keras.html">
   Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-statistical-language-model.html">
   Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-sequence-models-intuition.html">
   Sequence Models Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-language-model-primer.html">
   Neural Language Model: A Start
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-language-model-eng.html">
   Neural Language Model of English
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  More Sequence Models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-classification-dl.html">
   Text Classification based on Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-dl.html">
   Sentiment Analysis based on Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-machine-translation.html">
   Machine Translation (Sequence-to-Sequence)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-attention-addition.html">
   Seqeunce Model with Attention for Addition Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-using-bert.html">
   Sentiment Analysis Using BERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/gpt2.html">
   Transformer-based Language Model - GPT2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/ktrain-tutorial-explaining-predictions.html">
   Explainable AI
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   1. Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   2. Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   3. Assignment III: Preprocessing
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Under-Construction Notebooks
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-machine-translation-attention.html">
   Machine Translation with Attention (Thushan)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types.html">
   Intutions for Types of Sequence-to-Sequence Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types-date.html">
   Types of Sequence Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-language-model-zh-char.html">
   Neural Language Model of Chinese
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/word2vec-chinese.html">
   Word Embeddings with Chinese Texts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-lstm-v1.html">
   Sentiment Analysis with LSTM (imdb)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-lstm-v2.html">
   Sentiment Analysis Using LSTM 2 (csv)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-marc.html">
   Sentiment Analysis Chinese Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-svm-hyperparameter-marc.html">
   Sentiment Analysis of Yahoo! Movie reviews
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/sentiment-analysis-using-bert-chinese.html">
   Sentiment Analysis Using BERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-classification-ml_Sarkar.html">
   Text Classification based on Bag-of-Words (Sarkar Version)
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/exercise-ans/4-chinese-nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/exercise-ans/4-chinese-nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/exercise-ans/4-chinese-nlp.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-1">
   Question 1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-2">
   Question 2
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="chinese-language-processing">
<h1>Chinese Language Processing<a class="headerlink" href="#chinese-language-processing" title="Permalink to this headline">¶</a></h1>
<div class="section" id="question-1">
<h2>Question 1<a class="headerlink" href="#question-1" title="Permalink to this headline">¶</a></h2>
<p>The csv file <code class="docutils literal notranslate"><span class="pre">songs.csv</span></code> includes 100 posts from Dcard, a on-line discussion forum for students in Taiwan.</p>
<p>Please preprocess the data by:</p>
<ul class="simple">
<li><p>removing symbols, punctuations, emoticons or other non-linguistic symbols</p></li>
<li><p>performing word segmentation on the corpus using <code class="docutils literal notranslate"><span class="pre">ckip-transformer</span></code></p></li>
<li><p>creating a word frequency list of this tiny corpus</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please note that the preprocessing steps are important. Removal of characters from texts may have a lot to do with the word segmentation performance.</p>
</div>
<div class="cell tag_remove-input tag_remove-output docutils container">
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">ckip_transformers</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>
<span class="kn">from</span> <span class="nn">ckip_transformers.nlp</span> <span class="kn">import</span> <span class="n">CkipWordSegmenter</span><span class="c1">#, CkipPosTagger, CkipNerChunker</span>


<span class="c1">#nlp = spacy.load(&#39;zh-core-web-sm&#39;, parse=True, tag=True, entity=True)</span>


<span class="c1"># Initialize drivers</span>
<span class="n">ws_driver</span>  <span class="o">=</span> <span class="n">CkipWordSegmenter</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">()</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../../RepositoryData/data/stopwords/tomlinNTUB-chinese-stopwords.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">stopword_list</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">word_seg</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># texts is a full article</span>
    <span class="c1"># CKIPtagger works on a list, so we split the texts into paragraphs first</span>
    <span class="n">text_lines</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\n+&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text_lines_seg</span> <span class="o">=</span> <span class="n">ws_driver</span><span class="p">(</span><span class="n">text_lines</span><span class="p">,</span> <span class="n">use_delim</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="c1"># sents-splits for word-seg</span>
    <span class="n">text_lines</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">line_tokens</span><span class="p">)</span> <span class="k">for</span> <span class="n">line_tokens</span> <span class="ow">in</span> <span class="n">text_lines_seg</span><span class="p">]</span>
    <span class="n">text_seg</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_lines</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text_seg</span>
    
    

<span class="k">def</span> <span class="nf">strip_html_tags</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">()):</span>
        <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">soup</span><span class="p">([</span><span class="s1">&#39;iframe&#39;</span><span class="p">,</span> <span class="s1">&#39;script&#39;</span><span class="p">])]</span>
        <span class="n">stripped_text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
        <span class="n">stripped_text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[\r|\n|\r\n]+&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">stripped_text</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stripped_text</span> <span class="o">=</span> <span class="n">text</span>
    <span class="k">return</span> <span class="n">stripped_text</span>



<span class="c1"># def lemmatize_text(text):</span>
<span class="c1">#     text = nlp(text)</span>
<span class="c1">#     text = &#39; &#39;.join([word.lemma_ if word.lemma_ != &#39;-PRON-&#39; else word.text for word in text])</span>
<span class="c1">#     return text</span>


<span class="c1"># def remove_repeated_characters(tokens):</span>
<span class="c1">#     repeat_pattern = re.compile(r&#39;(\w*)(\w)\2(\w*)&#39;)</span>
<span class="c1">#     match_substitution = r&#39;\1\2\3&#39;</span>
<span class="c1">#     def replace(old_word):</span>
<span class="c1">#         if wordnet.synsets(old_word):</span>
<span class="c1">#             return old_word</span>
<span class="c1">#         new_word = repeat_pattern.sub(match_substitution, old_word)</span>
<span class="c1">#         return replace(new_word) if new_word != old_word else new_word</span>
            
<span class="c1">#     correct_tokens = [replace(word) for word in tokens]</span>
<span class="c1">#     return correct_tokens</span>




<span class="k">def</span> <span class="nf">remove_accented_chars</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s1">&#39;NFKD&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="s1">&#39;ignore&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">remove_digits</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;[0-9]+&#39;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">remove_alphabets</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;[a-zA-Z_-]+&#39;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="k">def</span> <span class="nf">remove_symbols</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Unicode 6.0 has 7 character categories, and each category has subcategories:</span>

<span class="sd">    Letter (L): lowercase (Ll), modifier (Lm), titlecase (Lt), uppercase (Lu), other (Lo)</span>
<span class="sd">    Mark (M): spacing combining (Mc), enclosing (Me), non-spacing (Mn)</span>
<span class="sd">    Number (N): decimal digit (Nd), letter (Nl), other (No)</span>
<span class="sd">    Punctuation (P): connector (Pc), dash (Pd), initial quote (Pi), final quote (Pf), open (Ps), close (Pe), other (Po)</span>
<span class="sd">    Symbol (S): currency (Sc), modifier (Sk), math (Sm), other (So)</span>
<span class="sd">    Separator (Z): line (Zl), paragraph (Zp), space (Zs)</span>
<span class="sd">    Other (C): control (Cc), format (Cf), not assigned (Cn), private use (Co), surrogate (Cs)</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    There are 3 ranges reserved for private use (Co subcategory): </span>
<span class="sd">    U+E000—U+F8FF (6,400 code points), U+F0000—U+FFFFD (65,534) and U+100000—U+10FFFD (65,534). </span>
<span class="sd">    Surrogates (Cs subcategory) use the range U+D800—U+DFFF (2,048 code points).</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">## Brute-force version: list all possible unicode ranges, but this list is not complete.</span>
    <span class="c1">#   text = re.sub(&#39;[\u0021-\u002f\u003a-\u0040\u005b-\u0060\u007b-\u007e\u00a1-\u00bf\u2000-\u206f\u2013-\u204a\u20a0-\u20bf\u2100-\u214f\u2150-\u218b\u2190-\u21ff\u2200-\u22ff\u2300-\u23ff\u2460-\u24ff\u2500-\u257f\u2580-\u259f\u25a0-\u25ff\u2600-\u26ff\u2e00-\u2e7f\u3000-\u303f\ufe50-\ufe6f\ufe30-\ufe4f\ufe10-\ufe1f\uff00-\uffef─◆╱]+&#39;,&#39;&#39;,text)</span>

    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ch</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">text</span>
                   <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">ch</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">text</span>



<span class="k">def</span> <span class="nf">remove_stopwords</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">stopwords</span><span class="o">=</span><span class="n">stopword_list</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="n">filtered_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
    <span class="n">filtered_text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filtered_tokens</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">filtered_text</span>


<span class="k">def</span> <span class="nf">normalize_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> 
                     <span class="n">html_stripping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">accented_char_removal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">symbols_removal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">stopword_removal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                     <span class="n">digits_removal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">alphabets_removal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">stopwords</span><span class="o">=</span><span class="n">stopword_list</span><span class="p">):</span>
    
    <span class="n">normalized_corpus</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># normalize each document in the corpus</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
        
        <span class="c1"># word segmentation</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">word_seg</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

        <span class="c1"># strip HTML</span>
        <span class="k">if</span> <span class="n">html_stripping</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">strip_html_tags</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

        <span class="c1"># remove extra newlines</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\t\r</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;   &quot;</span><span class="p">))</span>

        <span class="c1"># remove accented characters</span>
        <span class="k">if</span> <span class="n">accented_char_removal</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">remove_accented_chars</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>


        <span class="c1"># remove special characters and\or digits    </span>
        <span class="k">if</span> <span class="n">symbols_removal</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">remove_symbols</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>  

        <span class="c1"># remove extra whitespace</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39; +&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>

        <span class="c1"># remove stopwords</span>
        <span class="k">if</span> <span class="n">stopword_removal</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">remove_stopwords</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">stopwords</span><span class="o">=</span><span class="n">stopwords</span><span class="p">)</span>
        
        <span class="c1"># remove digits</span>
        <span class="k">if</span> <span class="n">digits_removal</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">remove_digits</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">alphabets_removal</span><span class="p">:</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">remove_alphabets</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

        <span class="c1"># remove extra whitespace</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[ ]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            
        <span class="n">normalized_corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">normalized_corpus</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">dcard_arts_normalized</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">dcard_arts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tokenization: 100%|██████████| 87/87 [00:00&lt;00:00, 22810.81it/s]
Inference: 100%|██████████| 1/1 [00:36&lt;00:00, 36.74s/it]
Tokenization: 100%|██████████| 34/34 [00:00&lt;00:00, 11121.14it/s]
Inference: 100%|██████████| 1/1 [00:27&lt;00:00, 27.56s/it]
Tokenization: 100%|██████████| 75/75 [00:00&lt;00:00, 11394.68it/s]
Inference: 100%|██████████| 1/1 [00:32&lt;00:00, 32.45s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 14538.32it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.29it/s]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 14443.20it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.06s/it]
Tokenization: 100%|██████████| 71/71 [00:00&lt;00:00, 27691.61it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.96s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 7248.22it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.03s/it]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 21059.27it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.29it/s]
Tokenization: 100%|██████████| 26/26 [00:00&lt;00:00, 16528.02it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.17s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 10576.84it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.67s/it]
Tokenization: 100%|██████████| 94/94 [00:00&lt;00:00, 23642.63it/s]
Inference: 100%|██████████| 1/1 [00:27&lt;00:00, 27.42s/it]
Tokenization: 100%|██████████| 105/105 [00:00&lt;00:00, 18242.15it/s]
Inference: 100%|██████████| 1/1 [00:40&lt;00:00, 40.53s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 25684.65it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.96s/it]
Tokenization: 100%|██████████| 24/24 [00:00&lt;00:00, 15296.05it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.13s/it]
Tokenization: 100%|██████████| 55/55 [00:00&lt;00:00, 23474.79it/s]
Inference: 100%|██████████| 1/1 [00:22&lt;00:00, 22.95s/it]
Tokenization: 100%|██████████| 41/41 [00:00&lt;00:00, 18059.91it/s]
Inference: 100%|██████████| 1/1 [00:11&lt;00:00, 11.81s/it]
Tokenization: 100%|██████████| 36/36 [00:00&lt;00:00, 23745.08it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.98s/it]
Tokenization: 100%|██████████| 117/117 [00:00&lt;00:00, 36288.81it/s]
Inference: 100%|██████████| 1/1 [00:14&lt;00:00, 14.50s/it]
Tokenization: 100%|██████████| 48/48 [00:00&lt;00:00, 24540.05it/s]
Inference: 100%|██████████| 1/1 [00:13&lt;00:00, 13.84s/it]
Tokenization: 100%|██████████| 74/74 [00:00&lt;00:00, 22249.35it/s]
Inference: 100%|██████████| 1/1 [00:20&lt;00:00, 20.20s/it]
Tokenization: 100%|██████████| 45/45 [00:00&lt;00:00, 22320.68it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.28s/it]
Tokenization: 100%|██████████| 55/55 [00:00&lt;00:00, 20339.16it/s]
Inference: 100%|██████████| 1/1 [00:22&lt;00:00, 22.32s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 22477.51it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.05it/s]
Tokenization: 100%|██████████| 40/40 [00:00&lt;00:00, 17613.88it/s]
Inference: 100%|██████████| 1/1 [00:16&lt;00:00, 16.61s/it]
Tokenization: 100%|██████████| 44/44 [00:00&lt;00:00, 26489.07it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.72s/it]
Tokenization: 100%|██████████| 31/31 [00:00&lt;00:00, 13119.10it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.75s/it]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 31550.50it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.47s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 25525.50it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.52s/it]
Tokenization: 100%|██████████| 8/8 [00:00&lt;00:00, 8492.64it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.96s/it]
Tokenization: 100%|██████████| 68/68 [00:00&lt;00:00, 22245.74it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.08s/it]
Tokenization: 100%|██████████| 53/53 [00:00&lt;00:00, 23124.74it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.10s/it]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 4408.10it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 9004.28it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.92s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 3286.30it/s]
Inference: 100%|██████████| 1/1 [00:20&lt;00:00, 20.86s/it]
Tokenization: 100%|██████████| 13/13 [00:00&lt;00:00, 20217.26it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.65s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 16181.73it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.28s/it]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 15859.06it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.46s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 6766.22it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.57s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 16176.38it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.13s/it]
Tokenization: 100%|██████████| 81/81 [00:00&lt;00:00, 8153.66it/s]
Inference: 100%|██████████| 2/2 [01:21&lt;00:00, 40.89s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 19092.29it/s]
Inference: 100%|██████████| 1/1 [00:12&lt;00:00, 12.97s/it]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 8371.86it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.75it/s]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 18250.53it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.32s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 12949.82it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.42s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 19750.29it/s]
Inference: 100%|██████████| 1/1 [00:10&lt;00:00, 10.75s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 19025.71it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.19s/it]
Tokenization: 100%|██████████| 31/31 [00:00&lt;00:00, 16757.76it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.17s/it]
Tokenization: 100%|██████████| 33/33 [00:00&lt;00:00, 16809.82it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.17s/it]
Tokenization: 100%|██████████| 28/28 [00:00&lt;00:00, 21877.89it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.86s/it]
Tokenization: 100%|██████████| 84/84 [00:00&lt;00:00, 13983.79it/s]
Inference: 100%|██████████| 1/1 [00:11&lt;00:00, 11.26s/it]
Tokenization: 100%|██████████| 36/36 [00:00&lt;00:00, 26767.41it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.08s/it]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 12221.17it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.34it/s]
Tokenization: 100%|██████████| 41/41 [00:00&lt;00:00, 10643.46it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.17s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 22539.01it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.51s/it]
Tokenization: 100%|██████████| 30/30 [00:00&lt;00:00, 11649.77it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.50s/it]
Tokenization: 100%|██████████| 16/16 [00:00&lt;00:00, 3685.68it/s]
Inference: 100%|██████████| 1/1 [00:36&lt;00:00, 36.36s/it]
Tokenization: 100%|██████████| 13/13 [00:00&lt;00:00, 17983.49it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.02s/it]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 23590.01it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.77it/s]
Tokenization: 100%|██████████| 48/48 [00:00&lt;00:00, 15936.56it/s]
Inference: 100%|██████████| 1/1 [00:12&lt;00:00, 12.18s/it]
Tokenization: 100%|██████████| 36/36 [00:00&lt;00:00, 18423.00it/s]
Inference: 100%|██████████| 1/1 [00:17&lt;00:00, 17.83s/it]
Tokenization: 100%|██████████| 65/65 [00:00&lt;00:00, 26736.27it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.47s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 30456.56it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.51s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 12985.46it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.21s/it]
Tokenization: 100%|██████████| 6/6 [00:00&lt;00:00, 10828.67it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.11s/it]
Tokenization: 100%|██████████| 29/29 [00:00&lt;00:00, 22051.27it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.68s/it]
Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 4739.33it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.57it/s]
Tokenization: 100%|██████████| 20/20 [00:00&lt;00:00, 21782.93it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.69s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tokenization: 100%|██████████| 88/88 [00:00&lt;00:00, 44582.53it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.56s/it]
Tokenization: 100%|██████████| 22/22 [00:00&lt;00:00, 17786.18it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.81s/it]
Tokenization: 100%|██████████| 63/63 [00:00&lt;00:00, 22515.44it/s]
Inference: 100%|██████████| 1/1 [00:13&lt;00:00, 13.13s/it]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 12527.79it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.57it/s]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 25015.73it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.07it/s]
Tokenization: 100%|██████████| 61/61 [00:00&lt;00:00, 17779.88it/s]
Inference: 100%|██████████| 1/1 [00:22&lt;00:00, 22.02s/it]
Tokenization: 100%|██████████| 51/51 [00:00&lt;00:00, 24769.51it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.17s/it]
Tokenization: 100%|██████████| 9/9 [00:00&lt;00:00, 35444.82it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.10s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 13812.20it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.24it/s]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 16532.53it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.28s/it]
Tokenization: 100%|██████████| 7/7 [00:00&lt;00:00, 13107.20it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.18s/it]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 11052.18it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  2.75it/s]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 8197.34it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.59s/it]
Tokenization: 100%|██████████| 76/76 [00:00&lt;00:00, 24311.10it/s]
Inference: 100%|██████████| 1/1 [00:13&lt;00:00, 13.81s/it]
Tokenization: 100%|██████████| 35/35 [00:00&lt;00:00, 18961.59it/s]
Inference: 100%|██████████| 1/1 [00:08&lt;00:00,  8.98s/it]
Tokenization: 100%|██████████| 64/64 [00:00&lt;00:00, 26275.98it/s]
Inference: 100%|██████████| 1/1 [00:16&lt;00:00, 16.26s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 6555.46it/s]
Inference: 100%|██████████| 1/1 [00:14&lt;00:00, 14.95s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 17396.88it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.86s/it]
Tokenization: 100%|██████████| 21/21 [00:00&lt;00:00, 11897.93it/s]
Inference: 100%|██████████| 1/1 [00:07&lt;00:00,  7.60s/it]
Tokenization: 100%|██████████| 19/19 [00:00&lt;00:00, 23308.50it/s]
Inference: 100%|██████████| 1/1 [00:02&lt;00:00,  2.33s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 17791.32it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.56it/s]
Tokenization: 100%|██████████| 24/24 [00:00&lt;00:00, 19232.57it/s]
Inference: 100%|██████████| 1/1 [00:04&lt;00:00,  4.10s/it]
Tokenization: 100%|██████████| 10/10 [00:00&lt;00:00, 21399.51it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.54s/it]
Tokenization: 100%|██████████| 3/3 [00:00&lt;00:00, 9939.11it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.31s/it]
Tokenization: 100%|██████████| 5/5 [00:00&lt;00:00, 16939.84it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.37it/s]
Tokenization: 100%|██████████| 2/2 [00:00&lt;00:00, 9177.91it/s]
Inference: 100%|██████████| 1/1 [00:00&lt;00:00,  1.85it/s]
Tokenization: 100%|██████████| 29/29 [00:00&lt;00:00, 28593.05it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.30s/it]
Tokenization: 100%|██████████| 4/4 [00:00&lt;00:00, 4196.40it/s]
Inference: 100%|██████████| 1/1 [00:03&lt;00:00,  3.23s/it]
Tokenization: 100%|██████████| 34/34 [00:00&lt;00:00, 16757.50it/s]
Inference: 100%|██████████| 1/1 [00:09&lt;00:00,  9.76s/it]
Tokenization: 100%|██████████| 43/43 [00:00&lt;00:00, 15529.11it/s]
Inference: 100%|██████████| 1/1 [00:12&lt;00:00, 12.88s/it]
Tokenization: 100%|██████████| 11/11 [00:00&lt;00:00, 23551.48it/s]
Inference: 100%|██████████| 1/1 [00:01&lt;00:00,  1.45s/it]
Tokenization: 100%|██████████| 57/57 [00:00&lt;00:00, 12808.75it/s]
Inference: 100%|██████████| 1/1 [00:23&lt;00:00, 23.58s/it]
Tokenization: 100%|██████████| 12/12 [00:00&lt;00:00, 7536.93it/s]
Inference: 100%|██████████| 1/1 [00:06&lt;00:00,  6.83s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 15min 5s, sys: 16.1 s, total: 15min 21s
Wall time: 15min 6s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>


<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;dcard_normed.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">dcard_arts_normalized</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;dcard_normled.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">dcard_arts_normalized</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dcards_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39; +&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">dcard_arts_normalized</span><span class="p">],</span> <span class="p">[])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dcards_wf</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">dcards_words</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dcards_wf</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;真的&#39;, 115),
 (&#39;沒有&#39;, 92),
 (&#39;覺得&#39;, 90),
 (&#39;知道&#39;, 70),
 (&#39;看到&#39;, 67),
 (&#39;現在&#39;, 63),
 (&#39;喜歡&#39;, 56),
 (&#39;朋友&#39;, 54),
 (&#39;其實&#39;, 52),
 (&#39;一直&#39;, 52),
 (&#39;不會&#39;, 51),
 (&#39;發現&#39;, 43),
 (&#39;男友&#39;, 42),
 (&#39;一下&#39;, 41),
 (&#39;已經&#39;, 41),
 (&#39;很多&#39;, 40),
 (&#39;時間&#39;, 40),
 (&#39;工作&#39;, 40),
 (&#39;分享&#39;, 39),
 (&#39;感覺&#39;, 39)]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="question-2">
<h2>Question 2<a class="headerlink" href="#question-2" title="Permalink to this headline">¶</a></h2>
<p>In this exercise, please try the <code class="docutils literal notranslate"><span class="pre">spacy</span></code> for Chinese processing.</p>
<p>Please process the same Dcard corpus by:</p>
<ul class="simple">
<li><p>performing the word tokenization</p></li>
<li><p>identifying all nouns and verbs (i.e., words whose tags start with N or V)</p></li>
<li><p>identifying all words with at least two characters</p></li>
<li><p>removing all words that contain alphabets or digits</p></li>
<li><p>removing all words that are included in the <code class="docutils literal notranslate"><span class="pre">stopword_list</span></code></p></li>
</ul>
<p>Based on the above text-preprocessing criteria, your goal is to create a word frequency list and visualize the result in a Word Cloud.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">spacy</span></code> uses the <code class="docutils literal notranslate"><span class="pre">jieba</span></code> for Chinese word segmentation. There may be more tagging errors. In the expected results presented below, I did not use any self-defined dictionary. For this exercise, please ignore any tagging errors out of the module for the moment.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;zh_core_web_trf&#39;</span><span class="p">)</span><span class="c1">## disable=[&quot;parser&quot;]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">dcard_arts</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39; | &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="o">+</span><span class="s2">&quot;_&quot;</span><span class="o">+</span><span class="n">token</span><span class="o">.</span><span class="n">tag_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>https://i.imgur_URL | ._URL | com_NR | /_PU | REI_PU | EzSd.jpg_NN | 
__SP | 身高_NN | 195_CD | 公分_M | 的_DEC | 男大_NN | 生楊_NR | 承翰_NR | 在_P | 家教_NN | 社團_NN | P_PU | O_PU | 文徵_VV | 學生_NN | 的_DEC | 文章_NN | 被_LB | 網友_NN | 推爆_VV | 了_AS | ，_PU | 網友_NN | 們_NN | 看到_VV | 他_PN | 的_DEG | 學經歷_NN | 及_CC | 成績_NN | 不禁_AD | 大讚_VV | 根本_AD | 就是_VC | 學霸王_NN | ，_PU | 而_AD | 他_PN | 不只_AD | 擁_VV | 有_VV | 高_JJ | 顏質_NN | ，_PU | 還_CC | 是_CC | 籃球_NN | 系隊_NN | 成員_NN | ，_PU | 超乎_VV | 常人_NN | 的_DEC | 學經歷_NN | 及_CC | 證書_NN | 考試_NN | 成績_NN | ，_PU | 瞬間_AD | 讓_VV | 網友_NN | 都_AD | 跪著_VV | 朝聖_VV | ，_PU | 直呼_VV | 「_PU | 天哪_NN | 好_AD | 厲害_VA | 的_DEC | 帥哥_NN | 」_PU | 、_PU | 「_PU | 這個_PN | 當_VV | 家教_NN | 太_AD | 可惜_VA | 了_AS | 」_PU | 。_PU | 
__SP | 21_CD | 歲_M | 台大_NR | 學生_NN | 楊_NR | 承翰_NR | 日前_NT | 在_P | 臉書_NN | 社團_NN | 「_PU | 家教_NN | 補教_NN | 學校_NN | 兼_CC | 全_JJ | 職_JJ | 、_PU | 打工_NN | 、_PU | 師訓_NN | 交流_NN | 」_PU | 發文_VV | ，_PU | 想_VV | 以_P | 時薪_NN | 1千5百_CD | 元_M | 找_VV | 家教_NN | 學生_NN | ，_PU | 授課_NN | 內容_NN | 為_VC | 英文_NN | 、_PU | 數學_NN | 、_PU | 理化_NN | 、_PU | 程式_NN | 語言_NN | 、_PU | 留學_NN | 申請_NN | ，_PU | 及_CC | SAT／ACT／TOFEL／AP_PU | 等_ETC | ，_PU | 希望_VV | 能_VV | 在_P | 台北_NR | 範圍_NN | 教學_VV | ，_PU | 也_AD | 可_VV | 接受_VV | 線上_JJ | 教學_NN | ，_PU | 貼文_NN | 下方_LC | 也_AD | 附註_VV | 他_PN | 的_DEG | 學經歷_NN | 。_PU | 
__SP | 學歷_NN | ：_PU | 
__SP | 就_VV | 讀_VV | 美國_NR | 杜克大學_NR | （_PU | Duke_PU | University_PU | ）_PU | 大三_NN | ，_PU | 雙_CD | 主修_VV | 資工_NN | ，_PU | 數學_NN | 
__SP | 畢業_VV | 於_VV | 新竹_NR | 科學_NN | 園區_NN | 實驗_NN | 中_NN | 學_NN | （_PU | National_PU | Experimental_PU | High_PU | School_PU | ）_PU | 
__SP | 美國_NR | 哈佛大學_NR | （_PU | Harvard_PU | University_PU | ）_PU | 暑期_NN | 醫學_NN | 研究生_NN | 
__SP | 國立_JJ | 台灣_NR | 大學_NN | （_PU | National_PU | Taiwan_PU | University_PU | )_PU | 新_NR | 冠專_NR | 案訪_NN | 問生_NN | 
__SP | 相關_JJ | 經歷_NN | ：_PU | 
__SP | 從小_AD | 在_P | 美國_NR | 及_CC | 台灣_NR | 長大_VV | ，_PU | 精通_VV | 中英文_NN | 。_PU | 
__SP | 擁_VV | 有_VV | 三年_CD | 以上_LC | 的_DEG | 教學_NN | 經驗_NN | ，_PU | 1_CD | 對_CC | 1_CD | 家_NN | 教經驗_NN | 豐富_VA | （_PU | 7_CD | +_PU | 學生_NN | ，_PU | 科目_NN | 分別_AD | 為_VC | 代數_NN | 、_PU | 微積分_NN | 、_PU | 化學_NN | 、_PU | Python_PU | 程式_NN | 設計_NN | 及_CC | 英文_NN | 寫作_NN | ）_PU | 。_PU | 
__SP | 曾_AD | 任教_VV | 於_P | 台北市_NR | 美西_NR | 留學_NN | 教育_NN | 顧問_NN | 公司_NN | ，_PU | 擔任_VV | 數學_NN | 專科_NN | 及_CC | SAT衝_NN | 刺班_NN | 教師_NN | 。_PU | 
__SP | 多次_AD | 擔任_VV | 私人_JJ | 留學_NN | 顧問_NN | ，_PU | 幫助_VV | 學生_NN | 錄取_VV | 杜克大學_NR | （_PU | Duke_PU | University_PU | ）_PU | ，_PU | 加州_NR | 理工_NN | 學院_NN | （_PU | California_P | Institute_PU | of_P | Technology_PU | ）_PU | 及_CC | 密西根_NR | 大學_NN | （_PU | University_PU | of_P | Michigan_PU | ）_PU | 等_ETC | 。_PU | 
__SP | 協助_VV | 杜克_NR | 大學_NN | 校方_NN | 開發_VV | 資工_NN | 系_NN | 大一_NN | 必修_NN | 的_DEC | 課程_NN | 網頁_NN | 及_CC | 作業_NN | 内容_NN | 。_PU | 
__SP | 考試_NN | 分數_NN | ：_PU | 
__SP | SAT_PU | :_PU | 1540_CD | /_PU | 1600_CD | （_PU | Essay_PU | 24_NT | /_NT | 24_NT | ）_PU | 
__SP | ACT_PU | :_PU | 34_NT | /_NT | 36_CD | 
__SP | TOEFL_PU | :_PU | 119_CD | /_PU | 120_CD | 
__SP | SAT_PU | Chinese_PU | ,_PU | Biology_PU | ,_PU | Chemistry_PU | ,_PU | Math_PU | Level_PU | 2_CD | :_PU | 800_CD | /_CD | 800_CD | 
__SP | AP_PU | English_PU | Language_PU | ,_PU | English_PU | Literature_PU | ,_PU | Chinese_PU | ,_PU | World_PU | History_PU | ,_PU | US_PU | Government_PU | ,_PU | Biology_PU | ,_PU | Chemistry_PU | ,_PU | Physics_PU | 1_CD | ,_PU | Physics_PU | C_PU | :_PU | Mechanics_PU | ,_PU | Physics_PU | C_PU | :_PU | E_PU | &amp;_PU | M_PU | ,_PU | Calculus_PU | AB_PU | ,_PU | Calculus_PU | BC_PU | :_PU | 5_CD | /_NT | 5_CD | （_PU | Advanced_PU | Placement_PU | (_PU | AP)_PU | =_PU | 美國_NR | 大學_NN | 先_NN | 修課_NN | ）_PU | 
__SP | USA_PU | Biology_PU | Olympiad_PU | （_PU | USABO_PU | ）_PU | Semifinalist_PU | （_PU | 美國_NR | 生物_NN | 奧林_NR | 匹亞_NR | 準決_NN | 賽入_NN | 選者_NN | ）_PU | 
__SP | 文章_NN | 吸引_VV | 4千多_CD | 位_M | 網友_NN | 按讚_VV | ，_PU | 超狂_AD | 的_DEC | 學經_NN | 歷_NN | 背景_NN | 讓_VV | 網友_NN | 全_AD | 看傻眼_VV | 了_SP | ，_PU | 紛紛_AD | 留言_VV | 「_PU | 這經_NN | 歷_NN | 是_VC | 鬼_NN | 吧_SP | ，_PU | 好_AD | 猛_VA | 」_PU | 、_PU | 「_PU | 這個_PN | 當_VV | 家教_NN | 太_AD | 可惜_VA | 了_SP | 」_PU | 、_PU | 「_PU | 哇賽_IJ | 我_PN | 還_AD | 不_AD | 推爆_VV | 」_PU | 、_PU | 「_PU | 來_VV | 看_VV | 神仙_NN | 」_PU | 、_PU | 「_PU | 這_PN | 是_VC | 學霸_NN | 王_NN | 吧_SP | 」_PU | 、_PU | 「_PU | 怎麼_AD | 不_AD | 去_VV | 打_VV | NCAA_PU | ？_PU | 」_PU | 
__SP | 對此_AD | ，_PU | 楊_NR | 承翰_NR | 向_P | 《_PU | ETtoday_PU | 新_NN | 聞雲_NN | 》_PU | 表示_VV | ，_PU | 「_PU | 我_PN | 真的_AD | 沒有_AD | 想到_VV | 徵學生_NN | 的_DEC | 貼文會_NN | 被_SB | 受到_VV | 那_AD | 麼_AD | 多_CD | 關注_NN | 。_PU | 很_AD | 謝謝_VV | 大家_PN | 給_VV | 我_PN | 的_DEC | 支持_NN | 、_PU | 鼓勵_NN | 及_CC | 建議_NN | ，_PU | 我_PN | 也_AD | 成功_VA | 的_DEV | 找到_VV | 好幾_CD | 個_M | 合適_VA | 的_DEC | 家教_NN | 案件_NN | 了_SP | 。_PU | 」_PU | 
__SP | https://i.imgur_NN | ._URL | com_NR | /_PU | xWRCeuo.jpg_NN | 
__SP | https://i.imgur_NN | ._PU | com_NR | /_PU | 5_PU | An_PU | 71_PU | PS_PU | ._NN | j_NN | pg_NN | 
__SP | https_NN | :_NR | //_URL | www.et_URL | to_NR | day.net/news_URL | /_PU | 20210226_NT | /_PU | 1926628_CD | ._URL | htm_NN | 
__SP | 他_PN | 會這_AD | 麼高_VA | 是_VC | 遺傳_NN | +_PU | 後天_NT | 愛運_VV | 動_NN | 
__SP | 他_PN | 爸_NN | 183_CD | 
__SP | 媽媽_NN | 172_CD | 
__SP | 基因_NN | 強大_VA | 👀_PU | 
__SP | 另外_AD | 這個_DT | 學經_NN | 歷收_NN | 1500_CD | 也_AD | 很_AD | 佛心_VA | 
__SP | 台大_NR | 的_DEG | 家教_NN | 一_CD | 小_M | 時_M | 大概_AD | 800_CD | up_JJ | 
__SP | 醫學_NN | 可以_VV | 到_VV | 1200~1500_CD | 
__SP | 這樣_AD | 應_VV | 該算_VV | 很_AD | 勝利_VV | 了_SP | ?_PU
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dcard_arts</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;部分回應在B117 \n謝謝各位的留言，我都有看完\n好的不好的，我都接受謝謝大家🙇\u200d♀️\n（第三次更新在這邊）\nB258 這邊也有講到怎麼逃生\n很多人好奇我是怎麼踹門的，\n在這邊跟大家說一下，\n因為這台車本來就很老舊，\n加上我文章說的我有停在路邊檢查，\n之前有在練空手道，所以比較知道怎麼施力😥\n謝謝大家的關心，其他比較有問題的我會在留言一一回覆！\n後續處理的部分\n租車公司的話，他有很多間公司我當時租車的地方在新莊中原路。 \n我是在平台上訂的，租車公司沒有跟平台講，\n是我家人主動跟平台聯繫，所有的馬3都被下架。\n另外，前幾天有開事故會議，\n平台的律師態度是覺得不需要賠很多錢，\n因為他在談話中談到想用5000元跟我和解，\n但是我燒壞的東西跟經歷了那場浩劫的我\n實在是沒辦法接受\n難不成一條人命只值5000嗎⋯⋯\n對這個平台的律師感到非常不解\n如果和解談不成的話，可能會上訴\n目前車子在等待第三方鑑定，\n鑑定完後會再談一次。\n以下正文\n2/19號這天，我跟我的朋友們要去台中吃燒烤，因為大家都住在北部，所以想說租一台車一起下去比高鐵便宜，加上大家都會開車，可以輪流開。\n租車的人是我本人，因為非常臨時租車，所以我上網查到一個平台是提供租車服務，非常方便也很便宜。\n這是我租車當時的資料。\nhttps://i.imgur.com/vjtbzMD.jpg\nhttps://i.imgur.com/sXtHoFy.jpg\nhttps://i.imgur.com/WgZ9pnD.jpg\n沒想到我當天取車的時候，老闆跟我說他派錯人手了，請我搭計程車到新莊的總站去牽車\nhttps://i.imgur.com/95y2NVW.jpg\n這是我當時去全家按的計程車證明聯。\n而到了現場，老闆態度還不錯，\n但因為我在台中的燒肉店有預約下午一點，\n我跟他說我已經有點被耽誤了，\n我還要去桃園接我朋友才能一起下去，\n所以老闆二話不說叫我簽名蓋指紋章後，\n立馬把車開到門口讓我出發，\n是已經發動引擎的狀態。（這邊我知道我不應該沒檢查就開出去，真的很後悔）\n開出去的時候都還好，\n但是開了10分鐘後我要上快速道路前，\n我發現我的車子被限速在60，\n儀表板上面顯示我的車門沒有關好，\n所以我停在路邊檢查我的車子，\n我把門關好之後，又繼續開出去，\n發現車子可以開到100以上以後，\n我才開上五楊高架，\n在這中間我發現我的引擎聲很不對勁，\n可是我已經上高架橋上了沒辦法停下來，\n直到我踩到100以上的時候，\n我的車子開始不受控制，聲音超大開始冒白煙\n我只能往高乘載道上開，\n因為後面比較沒車我怕車子爆炸波及到別人\n這是當時的狀況\nhttps://i.imgur.com/2SMP49P.jpg\n因為車子已經無法發動，\n門也被鎖死我被關在裡面，我沒辦法跑出去\n當下的心情真的很複雜，我只能想辦法把門踹開\n我用了全力踹門才衝出去，\n但是我的包包跟所有東西還全部在副駕上\n因為煙越來越大，開始冒小火，\n我沒辦法回去拿\n只有手機在身上\n這是當時現場的影片跟照片\nhttps://i.imgur.com/WXZrWYF.jpg\nhttps://www.dcard.tw/v2/vivid/videos/49754f1e-c061-44ea-b470-ebd6bd4a0401?r=1.7777777777777777\nhttps://www.dcard.tw/v2/vivid/videos/e995985d-df5b-410f-931e-1630fdfd45da?r=1.7777777777777777\nhttps://i.imgur.com/apkOsj8.jpg\n（當時友人剛好經過提供）\n火勢真的越來越大，那個廢煙也非常大，\n我裡面的東西最後有被消防員取出，\n但部分東西全部燒毀，已經沒有殘骸了。\n這是我的車子最後被燒毀的模樣\nhttps://i.imgur.com/pMIiQwW.jpg\nhttps://i.imgur.com/KZslOFY.jpg\nhttps://i.imgur.com/mSpX1eu.jpg\n（照片取自ettoday新聞雲）\n而消防人員鑑定出來，不是人為問題\n是汽車的機械問題，\n看照片看得出來是前面開始起火的。\n警惕大家，以後上路前，要好好檢查車子。\n為什麼過了這麼久才發出來，\n其實內心還是有陰影。\n幸好當時有逃出來，不然我可能已經沒命了。&#39;,
 &#39;https://i.imgur.com/REIEzSd.jpg\n身高195公分的男大生楊承翰在家教社團PO文徵學生的文章被網友推爆了，網友們看到他的學經歷及成績不禁大讚根本就是學霸王，而他不只擁有高顏質，還是籃球系隊成員，超乎常人的學經歷及證書考試成績，瞬間讓網友都跪著朝聖，直呼「天哪好厲害的帥哥」、「這個當家教太可惜了」。\n21歲台大學生楊承翰日前在臉書社團「家教補教學校兼全職、打工、師訓交流」發文，想以時薪1千5百元找家教學生，授課內容為英文、數學、理化、程式語言、留學申請，及SAT／ACT／TOFEL／AP等，希望能在台北範圍教學，也可接受線上教學，貼文下方也附註他的學經歷。\n學歷：\n就讀美國杜克大學（Duke University）大三，雙主修資工，數學\n畢業於新竹科學園區實驗中學（National Experimental High School）\n美國哈佛大學（Harvard University）暑期醫學研究生\n國立台灣大學（National Taiwan University) 新冠專案訪問生\n相關經歷：\n從小在美國及台灣長大，精通中英文。\n擁有三年以上的教學經驗，1對1家教經驗豐富（7+學生，科目分別為代數、微積分、化學、Python程式設計及英文寫作）。\n曾任教於台北市美西留學教育顧問公司，擔任數學專科及SAT衝刺班教師。\n多次擔任私人留學顧問，幫助學生錄取杜克大學（Duke University），加州理工學院（California Institute of Technology）及密西根大學（University of Michigan）等。\n協助杜克大學校方開發資工系大一必修的課程網頁及作業内容。\n考試分數：\nSAT: 1540/1600（Essay 24/24）\nACT: 34/36\nTOEFL: 119/120\nSAT Chinese, Biology, Chemistry, Math Level 2: 800/800\nAP English Language, English Literature, Chinese, World History, US Government, Biology, Chemistry, Physics 1, Physics C: Mechanics, Physics C: E&amp;M, Calculus AB, Calculus BC: 5/5 （Advanced Placement (AP) = 美國大學先修課）\nUSA Biology Olympiad（USABO）Semifinalist（美國生物奧林匹亞準決賽入選者）\n文章吸引4千多位網友按讚，超狂的學經歷背景讓網友全看傻眼了，紛紛留言「這經歷是鬼吧，好猛」、「這個當家教太可惜了」、「哇賽我還不推爆」、「來看神仙」、「這是學霸王吧」、「怎麼不去打NCAA？」\n對此，楊承翰向《ETtoday新聞雲》表示，「我真的沒有想到徵學生的貼文會被受到那麼多關注。很謝謝大家給我的支持、鼓勵及建議，我也成功的找到好幾個合適的家教案件了。」\nhttps://i.imgur.com/xWRCeuo.jpg\nhttps://i.imgur.com/5An71PS.jpg\nhttps://www.ettoday.net/news/20210226/1926628.htm\n他會這麼高是遺傳+後天愛運動\n他爸183\n媽媽172\n基因強大👀\n另外這個學經歷收1500也很佛心\n台大的家教一小時大概800up\n醫學可以到1200~1500\n這樣應該算很勝利了?&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../../RepositoryData/data/stopwords/tomlinNTUB-chinese-stopwords.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">stopword_list</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">doc_list</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">dcard_arts</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="c1">## extract all nouns</span>
<span class="n">nouns_verbs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">doc_list</span><span class="p">:</span>
    <span class="n">nouns_verbs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">d</span> 
                        <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">tag_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;V&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">2</span> 
                        <span class="ow">and</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[a-z0-9</span><span class="se">\\</span><span class="s1">/]+&#39;</span><span class="p">,</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
                       <span class="ow">and</span> <span class="n">token</span><span class="o">.</span><span class="n">text</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopword_list</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 34.1 s, sys: 801 ms, total: 34.9 s
Wall time: 34.1 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nouns_verbs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;回應&#39;,
  &#39;謝謝&#39;,
  &#39;留言&#39;,
  &#39;完&#39;,
  &#39;好的&#39;,
  &#39;好的&#39;,
  &#39;接受&#39;,
  &#39;謝謝&#39;,
  &#39;更新&#39;,
  &#39;講到&#39;,
  &#39;逃生&#39;,
  &#39;好奇&#39;,
  &#39;踹門&#39;,
  &#39;說&#39;,
  &#39;台車&#39;,
  &#39;老舊&#39;,
  &#39;文章&#39;,
  &#39;說&#39;,
  &#39;停在&#39;,
  &#39;路邊&#39;,
  &#39;檢查&#39;,
  &#39;練空&#39;,
  &#39;手道&#39;,
  &#39;知道&#39;,
  &#39;施力&#39;,
  &#39;謝謝&#39;,
  &#39;關心&#39;,
  &#39;問題&#39;,
  &#39;會&#39;,
  &#39;留言&#39;,
  &#39;回覆&#39;,
  &#39;處理&#39;,
  &#39;部分&#39;,
  &#39;租車&#39;,
  &#39;公司&#39;,
  &#39;公司&#39;,
  &#39;當時&#39;,
  &#39;租車&#39;,
  &#39;地方&#39;,
  &#39;新莊&#39;,
  &#39;中原路&#39;,
  &#39;平台&#39;,
  &#39;訂&#39;,
  &#39;租車&#39;,
  &#39;公司&#39;,
  &#39;平台&#39;,
  &#39;講&#39;,
  &#39;家人&#39;,
  &#39;平台&#39;,
  &#39;聯繫&#39;,
  &#39;馬&#39;,
  &#39;下架&#39;,
  &#39;前&#39;,
  &#39;開&#39;,
  &#39;事故&#39;,
  &#39;會議&#39;,
  &#39;平台&#39;,
  &#39;律師&#39;,
  &#39;態度&#39;,
  &#39;覺&#39;,
  &#39;需要&#39;,
  &#39;賠&#39;,
  &#39;錢&#39;,
  &#39;談話&#39;,
  &#39;中談&#39;,
  &#39;想&#39;,
  &#39;和解&#39;,
  &#39;燒壞&#39;,
  &#39;東西&#39;,
  &#39;經歷&#39;,
  &#39;浩劫&#39;,
  &#39;沒辦法&#39;,
  &#39;接受&#39;,
  &#39;難&#39;,
  &#39;人命&#39;,
  &#39;值&#39;,
  &#39;平台&#39;,
  &#39;律師&#39;,
  &#39;感到&#39;,
  &#39;不解&#39;,
  &#39;解談&#39;,
  &#39;可能&#39;,
  &#39;會上&#39;,
  &#39;訴&#39;,
  &#39;目前&#39;,
  &#39;車子&#39;,
  &#39;等待&#39;,
  &#39;鑑定&#39;,
  &#39;鑑定&#39;,
  &#39;完&#39;,
  &#39;後會&#39;,
  &#39;談&#39;,
  &#39;正文&#39;,
  &#39;號&#39;,
  &#39;這天&#39;,
  &#39;朋友&#39;,
  &#39;台中&#39;,
  &#39;吃&#39;,
  &#39;燒烤&#39;,
  &#39;住&#39;,
  &#39;北部&#39;,
  &#39;想&#39;,
  &#39;說租&#39;,
  &#39;車&#39;,
  &#39;下去&#39;,
  &#39;高鐵&#39;,
  &#39;便宜&#39;,
  &#39;會&#39;,
  &#39;開車&#39;,
  &#39;流開&#39;,
  &#39;租車&#39;,
  &#39;租車&#39;,
  &#39;上網&#39;,
  &#39;查到&#39;,
  &#39;平台&#39;,
  &#39;提供&#39;,
  &#39;租車&#39;,
  &#39;服務&#39;,
  &#39;方便&#39;,
  &#39;便宜&#39;,
  &#39;租車&#39;,
  &#39;當時&#39;,
  &#39;資料&#39;,
  &#39;MD.jpg&#39;,
  &#39;.&#39;,
  &#39;想到&#39;,
  &#39;當天&#39;,
  &#39;取車&#39;,
  &#39;老闆&#39;,
  &#39;說&#39;,
  &#39;派錯人&#39;,
  &#39;手&#39;,
  &#39;請&#39;,
  &#39;搭&#39;,
  &#39;計程&#39;,
  &#39;車到&#39;,
  &#39;新莊&#39;,
  &#39;總站&#39;,
  &#39;牽車&#39;,
  &#39;當時&#39;,
  &#39;全家&#39;,
  &#39;計程&#39;,
  &#39;車證&#39;,
  &#39;明聯&#39;,
  &#39;現場&#39;,
  &#39;老闆&#39;,
  &#39;態度&#39;,
  &#39;錯&#39;,
  &#39;台中&#39;,
  &#39;燒肉&#39;,
  &#39;店&#39;,
  &#39;預約&#39;,
  &#39;下午&#39;,
  &#39;點&#39;,
  &#39;說&#39;,
  &#39;耽誤&#39;,
  &#39;桃園&#39;,
  &#39;接&#39;,
  &#39;朋友&#39;,
  &#39;下去&#39;,
  &#39;老闆&#39;,
  &#39;二&#39;,
  &#39;說&#39;,
  &#39;簽名&#39;,
  &#39;蓋指&#39;,
  &#39;紋章&#39;,
  &#39;車開&#39;,
  &#39;門口&#39;,
  &#39;出發&#39;,
  &#39;發動&#39;,
  &#39;引擎&#39;,
  &#39;狀態&#39;,
  &#39;知道&#39;,
  &#39;應&#39;,
  &#39;該沒&#39;,
  &#39;檢查&#39;,
  &#39;開&#39;,
  &#39;出去&#39;,
  &#39;後悔&#39;,
  &#39;開&#39;,
  &#39;出去&#39;,
  &#39;開&#39;,
  &#39;道路&#39;,
  &#39;發現&#39;,
  &#39;車子&#39;,
  &#39;限速&#39;,
  &#39;儀&#39;,
  &#39;表板&#39;,
  &#39;上面&#39;,
  &#39;顯示&#39;,
  &#39;車門&#39;,
  &#39;關好&#39;,
  &#39;停&#39;,
  &#39;路邊&#39;,
  &#39;檢查&#39;,
  &#39;車子&#39;,
  &#39;門關&#39;,
  &#39;繼&#39;,
  &#39;續開&#39;,
  &#39;出去&#39;,
  &#39;發現&#39;,
  &#39;車子&#39;,
  &#39;開到&#39;,
  &#39;開上&#39;,
  &#39;五&#39;,
  &#39;楊&#39;,
  &#39;高架&#39;,
  &#39;這中間&#39;,
  &#39;發現&#39;,
  &#39;引擎&#39;,
  &#39;聲&#39;,
  &#39;對勁&#39;,
  &#39;經上&#39;,
  &#39;高架&#39;,
  &#39;橋上&#39;,
  &#39;沒辦法&#39;,
  &#39;停下&#39;,
  &#39;踩到&#39;,
  &#39;車子&#39;,
  &#39;受&#39;,
  &#39;控制&#39;,
  &#39;聲音&#39;,
  &#39;超大&#39;,
  &#39;冒白&#39;,
  &#39;煙&#39;,
  &#39;高乘&#39;,
  &#39;載道&#39;,
  &#39;開&#39;,
  &#39;後面&#39;,
  &#39;較沒&#39;,
  &#39;車&#39;,
  &#39;怕&#39;,
  &#39;車子&#39;,
  &#39;爆炸&#39;,
  &#39;波及&#39;,
  &#39;當時&#39;,
  &#39;狀況&#39;,
  &#39;車子&#39;,
  &#39;發動&#39;,
  &#39;門&#39;,
  &#39;鎖死&#39;,
  &#39;關&#39;,
  &#39;裡面&#39;,
  &#39;沒&#39;,
  &#39;辦法&#39;,
  &#39;跑&#39;,
  &#39;出去&#39;,
  &#39;當下&#39;,
  &#39;心情&#39;,
  &#39;複雜&#39;,
  &#39;想&#39;,
  &#39;辦法&#39;,
  &#39;門踹&#39;,
  &#39;開&#39;,
  &#39;踹門&#39;,
  &#39;衝&#39;,
  &#39;出去&#39;,
  &#39;包包&#39;,
  &#39;東西還&#39;,
  &#39;副駕上&#39;,
  &#39;小火&#39;,
  &#39;沒辦法&#39;,
  &#39;回去&#39;,
  &#39;手機&#39;,
  &#39;身上&#39;,
  &#39;當時&#39;,
  &#39;現場&#39;,
  &#39;影片&#39;,
  &#39;照片&#39;,
  &#39;F.jpg&#39;,
  &#39;當時&#39;,
  &#39;友人&#39;,
  &#39;提供&#39;,
  &#39;火勢&#39;,
  &#39;廢煙&#39;,
  &#39;裡面&#39;,
  &#39;東西&#39;,
  &#39;消防員&#39;,
  &#39;取出&#39;,
  &#39;東西&#39;,
  &#39;燒毀&#39;,
  &#39;經沒&#39;,
  &#39;殘骸&#39;,
  &#39;車子&#39;,
  &#39;燒毀&#39;,
  &#39;模樣&#39;,
  &#39;.&#39;,
  &#39;.&#39;,
  &#39;照片&#39;,
  &#39;取自et&#39;,
  &#39;新&#39;,
  &#39;聞雲&#39;,
  &#39;消防人&#39;,
  &#39;員&#39;,
  &#39;鑑定&#39;,
  &#39;問題&#39;,
  &#39;汽車&#39;,
  &#39;機械&#39;,
  &#39;問題&#39;,
  &#39;照片&#39;,
  &#39;前面&#39;,
  &#39;起火&#39;,
  &#39;警惕&#39;,
  &#39;檢查&#39;,
  &#39;車子&#39;,
  &#39;麼過&#39;,
  &#39;發&#39;,
  &#39;心還&#39;,
  &#39;陰影&#39;,
  &#39;當時&#39;,
  &#39;逃出&#39;,
  &#39;可能&#39;,
  &#39;沒命&#39;],
 [&#39;EzSd.jpg&#39;,
  &#39;身高&#39;,
  &#39;男大&#39;,
  &#39;生楊&#39;,
  &#39;承翰&#39;,
  &#39;家教&#39;,
  &#39;社團&#39;,
  &#39;文徵&#39;,
  &#39;學生&#39;,
  &#39;文章&#39;,
  &#39;網友&#39;,
  &#39;推爆&#39;,
  &#39;網友&#39;,
  &#39;看到&#39;,
  &#39;學經歷&#39;,
  &#39;成績&#39;,
  &#39;大讚&#39;,
  &#39;學霸王&#39;,
  &#39;擁&#39;,
  &#39;顏質&#39;,
  &#39;籃球&#39;,
  &#39;系隊&#39;,
  &#39;成員&#39;,
  &#39;超乎&#39;,
  &#39;常人&#39;,
  &#39;學經歷&#39;,
  &#39;證書&#39;,
  &#39;考試&#39;,
  &#39;成績&#39;,
  &#39;網友&#39;,
  &#39;跪著&#39;,
  &#39;朝聖&#39;,
  &#39;直呼&#39;,
  &#39;天哪&#39;,
  &#39;厲害&#39;,
  &#39;帥哥&#39;,
  &#39;家教&#39;,
  &#39;可惜&#39;,
  &#39;台大&#39;,
  &#39;學生&#39;,
  &#39;楊&#39;,
  &#39;承翰&#39;,
  &#39;日前&#39;,
  &#39;臉書&#39;,
  &#39;社團&#39;,
  &#39;家教&#39;,
  &#39;補教&#39;,
  &#39;學校&#39;,
  &#39;打工&#39;,
  &#39;師訓&#39;,
  &#39;交流&#39;,
  &#39;發文&#39;,
  &#39;想&#39;,
  &#39;時薪&#39;,
  &#39;找&#39;,
  &#39;家教&#39;,
  &#39;學生&#39;,
  &#39;授課&#39;,
  &#39;內容&#39;,
  &#39;英文&#39;,
  &#39;數學&#39;,
  &#39;理化&#39;,
  &#39;程式&#39;,
  &#39;語言&#39;,
  &#39;留學&#39;,
  &#39;申請&#39;,
  &#39;希望&#39;,
  &#39;台北&#39;,
  &#39;範圍&#39;,
  &#39;教學&#39;,
  &#39;接受&#39;,
  &#39;教學&#39;,
  &#39;貼文&#39;,
  &#39;附註&#39;,
  &#39;學經歷&#39;,
  &#39;學歷&#39;,
  &#39;讀&#39;,
  &#39;美國&#39;,
  &#39;杜克大學&#39;,
  &#39;大三&#39;,
  &#39;主修&#39;,
  &#39;資工&#39;,
  &#39;數學&#39;,
  &#39;畢業&#39;,
  &#39;新竹&#39;,
  &#39;科學&#39;,
  &#39;園區&#39;,
  &#39;實驗&#39;,
  &#39;中&#39;,
  &#39;學&#39;,
  &#39;美國&#39;,
  &#39;哈佛大學&#39;,
  &#39;暑期&#39;,
  &#39;醫學&#39;,
  &#39;研究生&#39;,
  &#39;台灣&#39;,
  &#39;大學&#39;,
  &#39;新&#39;,
  &#39;冠專&#39;,
  &#39;案訪&#39;,
  &#39;問生&#39;,
  &#39;經歷&#39;,
  &#39;美國&#39;,
  &#39;台灣&#39;,
  &#39;長大&#39;,
  &#39;精通&#39;,
  &#39;中英文&#39;,
  &#39;擁&#39;,
  &#39;教學&#39;,
  &#39;經驗&#39;,
  &#39;家&#39;,
  &#39;教經驗&#39;,
  &#39;豐富&#39;,
  &#39;學生&#39;,
  &#39;科目&#39;,
  &#39;代數&#39;,
  &#39;微積分&#39;,
  &#39;化學&#39;,
  &#39;程式&#39;,
  &#39;設計&#39;,
  &#39;英文&#39;,
  &#39;寫作&#39;,
  &#39;任教&#39;,
  &#39;台北市&#39;,
  &#39;美西&#39;,
  &#39;留學&#39;,
  &#39;教育&#39;,
  &#39;顧問&#39;,
  &#39;公司&#39;,
  &#39;擔任&#39;,
  &#39;數學&#39;,
  &#39;專科&#39;,
  &#39;SAT衝&#39;,
  &#39;刺班&#39;,
  &#39;教師&#39;,
  &#39;擔任&#39;,
  &#39;留學&#39;,
  &#39;顧問&#39;,
  &#39;幫助&#39;,
  &#39;學生&#39;,
  &#39;錄取&#39;,
  &#39;杜克大學&#39;,
  &#39;加州&#39;,
  &#39;理工&#39;,
  &#39;學院&#39;,
  &#39;密西根&#39;,
  &#39;大學&#39;,
  &#39;協助&#39;,
  &#39;杜克&#39;,
  &#39;大學&#39;,
  &#39;校方&#39;,
  &#39;開發&#39;,
  &#39;資工&#39;,
  &#39;系&#39;,
  &#39;大一&#39;,
  &#39;必修&#39;,
  &#39;課程&#39;,
  &#39;網頁&#39;,
  &#39;作業&#39;,
  &#39;内容&#39;,
  &#39;考試&#39;,
  &#39;分數&#39;,
  &#39;美國&#39;,
  &#39;大學&#39;,
  &#39;先&#39;,
  &#39;修課&#39;,
  &#39;美國&#39;,
  &#39;生物&#39;,
  &#39;奧林&#39;,
  &#39;匹亞&#39;,
  &#39;準決&#39;,
  &#39;賽入&#39;,
  &#39;選者&#39;,
  &#39;文章&#39;,
  &#39;吸引&#39;,
  &#39;網友&#39;,
  &#39;按讚&#39;,
  &#39;學經&#39;,
  &#39;歷&#39;,
  &#39;背景&#39;,
  &#39;網友&#39;,
  &#39;看傻眼&#39;,
  &#39;留言&#39;,
  &#39;這經&#39;,
  &#39;歷&#39;,
  &#39;鬼&#39;,
  &#39;猛&#39;,
  &#39;家教&#39;,
  &#39;可惜&#39;,
  &#39;推爆&#39;,
  &#39;神仙&#39;,
  &#39;學霸&#39;,
  &#39;王&#39;,
  &#39;楊&#39;,
  &#39;承翰&#39;,
  &#39;新&#39;,
  &#39;聞雲&#39;,
  &#39;表示&#39;,
  &#39;想到&#39;,
  &#39;徵學生&#39;,
  &#39;貼文會&#39;,
  &#39;關注&#39;,
  &#39;謝謝&#39;,
  &#39;支持&#39;,
  &#39;鼓勵&#39;,
  &#39;建議&#39;,
  &#39;成功&#39;,
  &#39;找到&#39;,
  &#39;合適&#39;,
  &#39;家教&#39;,
  &#39;案件&#39;,
  &#39;.&#39;,
  &#39;:&#39;,
  &#39;麼高&#39;,
  &#39;遺傳&#39;,
  &#39;後天&#39;,
  &#39;愛運&#39;,
  &#39;動&#39;,
  &#39;爸&#39;,
  &#39;媽媽&#39;,
  &#39;基因&#39;,
  &#39;強大&#39;,
  &#39;學經&#39;,
  &#39;歷收&#39;,
  &#39;佛心&#39;,
  &#39;台大&#39;,
  &#39;家教&#39;,
  &#39;醫學&#39;,
  &#39;應&#39;,
  &#39;該算&#39;,
  &#39;勝利&#39;],
 [&#39;看過&#39;,
  &#39;感情&#39;,
  &#39;渣事&#39;,
  &#39;創作文&#39;,
  &#39;想&#39;,
  &#39;荒謬&#39;,
  &#39;八點檔&#39;,
  &#39;事情&#39;,
  &#39;會&#39;,
  &#39;發生&#39;,
  &#39;身上&#39;,
  &#39;為與&#39;,
  &#39;交往&#39;,
  &#39;男友&#39;,
  &#39;關係&#39;,
  &#39;分手&#39;,
  &#39;發文&#39;,
  &#39;私訊&#39;,
  &#39;爆料&#39;,
  &#39;塞爆&#39;,
  &#39;發現&#39;,
  &#39;交往&#39;,
  &#39;認識&#39;,
  &#39;劈腿&#39;,
  &#39;幻謊症&#39;,
  &#39;部分&#39;,
  &#39;可能&#39;,
  &#39;妄想症&#39;,
  &#39;接下來&#39;,
  &#39;故事&#39;,
  &#39;發生&#39;,
  &#39;事情&#39;,
  &#39;故事&#39;,
  &#39;複雜&#39;,
  &#39;牽扯&#39;,
  &#39;確定&#39;,
  &#39;會分&#39;,
  &#39;成&#39;,
  &#39;今天&#39;,
  &#39;識到&#39;,
  &#39;在一起&#39;,
  &#39;故事&#39;,
  &#39;講起&#39;,
  &#39;故事&#39;,
  &#39;簡稱&#39;,
  &#39;時間&#39;,
  &#39;管理&#39;,
  &#39;大師&#39;,
  &#39;男友&#39;,
  &#39;涉及&#39;,
  &#39;主角&#39;,
  &#39;加&#39;,
  &#39;女&#39;,
  &#39;Ｃ女&#39;,
  &#39;Ｄ女&#39;,
  &#39;Ｅ女&#39;,
  &#39;Ｎ女&#39;,
  &#39;提&#39;,
  &#39;背景&#39;,
  &#39;目前&#39;,
  &#39;日本&#39;,
  &#39;留學&#39;,
  &#39;學校&#39;,
  &#39;寒暑假&#39;,
  &#39;會回&#39;,
  &#39;台灣&#39;,
  &#39;於遠&#39;,
  &#39;戀愛&#39;,
  &#39;交往&#39;,
  &#39;期間&#39;,
  &#39;疫情&#39;,
  &#39;回台&#39;,
  &#39;時間&#39;,
  &#39;離戀&#39;,
  &#39;愛變&#39;,
  &#39;成同&#39;,
  &#39;城市&#39;,
  &#39;戀愛&#39;,
  &#39;聊天&#39;,
  &#39;交往&#39;,
  &#39;曖昧&#39;,
  &#39;時間&#39;,
  &#39;形象&#39;,
  &#39;外表&#39;,
  &#39;高冷&#39;,
  &#39;斯斯文文&#39;,
  &#39;紳士&#39;,
  &#39;K說&#39;,
  &#39;沖繩&#39;,
  &#39;拍&#39;,
  &#39;觀光&#39;,
  &#39;廣告&#39;,
  &#39;跨年&#39;,
  &#39;沖繩&#39;,
  &#39;機票&#39;,
  &#39;飯店&#39;,
  &#39;廠&#39;,
  &#39;商包&#39;,
  &#39;邀請&#39;,
  &#39;沖繩&#39;,
  &#39;跨年&#39;,
  &#39;從東&#39;,
  &#39;京飛&#39;,
  &#39;沖繩&#39;,
  &#39;找&#39;,
  &#39;說&#39;,
  &#39;攝&#39;,
  &#39;影師&#39;,
  &#39;大哥&#39;,
  &#39;住&#39;,
  &#39;房&#39;,
  &#39;訂&#39;,
  &#39;外面&#39;,
  &#39;住宿&#39;,
  &#39;跨年&#39;,
  &#39;晚&#39;,
  &#39;K牽&#39;,
  &#39;手&#39;,
  &#39;當晚&#39;,
  &#39;問&#39;,
  &#39;關係&#39;,
  &#39;旁邊&#39;,
  &#39;心理&#39;,
  &#39;建設&#39;,
  &#39;久&#39;,
  &#39;鼓起&#39;,
  &#39;勇氣&#39;,
  &#39;說&#39;,
  &#39;在一起&#39;,
  &#39;元旦&#39;,
  &#39;附手&#39;,
  &#39;機&#39;,
  &#39;照片&#39;,
  &#39;時間&#39;,
  &#39;點&#39;,
  &#39;證明&#39;,
  &#39;講ㄛ&#39;,
  &#39;.&#39;,
  &#39;為過年&#39;,
  &#39;疫情&#39;,
  &#39;回台&#39;,
  &#39;台灣&#39;,
  &#39;月&#39;,
  &#39;時間&#39;,
  &#39;態度&#39;,
  &#39;轉變&#39;,
  &#39;K開始&#39;,
  &#39;重心&#39;,
  &#39;擺&#39;,
  &#39;工作&#39;,
  &#39;工作&#39;,
  &#39;理由&#39;,
  &#39;消失&#39;,
  &#39;說&#39;,
  &#39;工作室&#39;,
  &#39;半夜&#39;,
  &#39;會&#39;,
  &#39;狀況&#39;,
  &#39;處理&#39;,
  &#39;會&#39;,
  &#39;工作室&#39;,
  &#39;過夜&#39;,
  &#39;模特兒&#39;,
  &#39;拍攝&#39;,
  &#39;工作&#39;,
  &#39;想&#39;,
  &#39;說&#39;,
  &#39;干涉&#39;,
  &#39;事業&#39;,
  &#39;誇張&#39;,
  &#39;約&#39;,
  &#39;出去&#39;,
  &#39;玩&#39;,
  &#39;會&#39;,
  &#39;工作&#39;,
  &#39;關係&#39;,
  &#39;取消&#39;,
  &#39;改期&#39;,
  &#39;放鳥&#39;,
  &#39;事實&#39;,
  &#39;證明&#39;,
  &#39;找&#39;,
  &#39;妹子&#39;,
  &#39;工作&#39;,
  &#39;名氣&#39;,
  &#39;模特兒&#39;,
  &#39;自稱&#39;,
  &#39;接&#39;,
  &#39;平面&#39;,
  &#39;廣告&#39;,
  &#39;戲劇&#39;,
  &#39;拍攝&#39;,
  &#39;經營&#39;,
  &#39;個人&#39;,
  &#39;工作室&#39;,
  &#39;做&#39;,
  &#39;接&#39;,
  &#39;案子&#39;,
  &#39;蝦X&#39;,
  &#39;吳伯毅&#39;,
  &#39;食物&#39;,
  &#39;熊貓&#39;,
  &#39;強調&#39;,
  &#39;自稱&#39;,
  &#39;附上&#39;,
  &#39;去年&#39;,
  &#39;八月&#39;,
  &#39;拍攝&#39;,
  &#39;台南&#39;,
  &#39;出遊&#39;,
  &#39;照片&#39;,
  &#39;時&#39;,
  &#39;看到&#39;,
  &#39;發&#39;,
  &#39;拍&#39;,
  &#39;照片&#39;,
  &#39;爽&#39;,
  &#39;按愛&#39;,
  &#39;心ㄏ&#39;,
  &#39;台灣&#39;,
  &#39;期間&#39;,
  &#39;行蹤不明&#39;,
  &#39;事情&#39;,
  &#39;吵架&#39;,
  &#39;沒&#39;,
  &#39;回&#39;,
  &#39;日本&#39;,
  &#39;後情&#39;,
  &#39;況&#39;,
  &#39;加劇&#39;,
  &#39;愛回&#39;,
  &#39;回&#39;,
  &#39;愛理&#39;,
  &#39;不理&#39;,
  &#39;願意&#39;,
  &#39;社群&#39;,
  &#39;公開&#39;,
  &#39;關係&#39;,
  &#39;事情&#39;,
  &#39;大吵&#39;,
  &#39;放棄&#39;,
  &#39;感情&#39;,
  &#39;想到&#39;,
  &#39;溝通&#39;,
  &#39;哭&#39;,
  &#39;並說&#39;,
  &#39;台灣&#39;,
  &#39;見&#39;,
  &#39;痛苦&#39;,
  &#39;地方&#39;,
  &#39;身邊&#39;,
  &#39;電話&#39;,
  &#39;掛掉&#39;,
  &#39;難受&#39;,
  &#39;聽到&#39;,
  &#39;驚&#39;,
  &#39;表露&#39;,
  &#39;情緒&#39;,
  &#39;知道&#39;,
  &#39;傻&#39;,
  &#39;說&#39;,
  &#39;單身&#39;,
  &#39;約妹&#39;,
  &#39;出去&#39;,
  &#39;女友&#39;,
  &#39;N女&#39;,
  &#39;台南&#39;,
  &#39;景點&#39;,
  &#39;分手&#39;,
  &#39;說&#39;,
  &#39;想&#39;,
  &#39;地方&#39;,
  &#39;分手&#39;,
  &#39;倒數&#39;,
  &#39;導火&#39;,
  &#39;線&#39;,
  &#39;K生日&#39;,
  &#39;點&#39;,
  &#39;傳&#39;,
  &#39;生日&#39;,
  &#39;訊息&#39;,
  &#39;敷衍&#39;,
  &#39;消失&#39;,
  &#39;講&#39;,
  &#39;理由&#39;,
  &#39;說&#39;,
  &#39;想&#39;,
  &#39;視訊&#39;,
  &#39;說&#39;,
  &#39;生日&#39;,
  &#39;時間&#39;,
  &#39;軸&#39;,
  &#39;晚上&#39;,
  &#39;告訴&#39;,
  &#39;朋友&#39;,
  &#39;喝酒&#39;,
  &#39;消失&#39;,
  &#39;早上&#39;,
  &#39;點出&#39;,
  &#39;現&#39;,
  &#39;下午&#39;,
  &#39;通話&#39;,
  &#39;掛掉&#39;,
  &#39;晚上&#39;,
  &#39;出現&#39;,
  &#39;消失&#39;,
  &#39;號&#39;,
  &#39;早上&#39;,
  &#39;.&#39;,
  &#39;.&#39;,
  &#39;圖裡&#39;,
  &#39;蛋糕&#39;,
  &#39;知道&#39;,
  &#39;妹子&#39;,
  &#39;送&#39;,
  &#39;K騙&#39;,
  &#39;林森&#39;,
  &#39;北路&#39;,
  &#39;開&#39;,
  &#39;房間&#39;,
  &#39;女生&#39;,
  &#39;簡稱&#39;,
  &#39;D女&#39;,
  &#39;後面&#39;,
  &#39;會詳&#39;,
  &#39;細介紹&#39;,
  &#39;消失&#39;,
  &#39;難過&#39;,
  &#39;生日&#39;,
  &#39;爆氣&#39;,
  &#39;說詞&#39;,
  &#39;希望&#39;,
  &#39;生日&#39;,
  &#39;視訊&#39;,
  &#39;想&#39;,
  &#39;接收&#39;,
  &#39;現場&#39;,
  &#39;祝福&#39;,
  &#39;爸&#39;,
  &#39;電話&#39;,
  &#39;沒接&#39;,
  &#39;女友&#39;,
  &#39;日本&#39;,
  &#39;視訊&#39;,
  &#39;.&#39;,
  &#39;GgwhzLO.png&#39;,
  &#39;分手&#39;,
  &#39;倒數&#39;,
  &#39;導火&#39;,
  &#39;線&#39;,
  &#39;史上&#39;,
  &#39;爆炸&#39;,
  &#39;大吵&#39;,
  &#39;跨年&#39;,
  &#39;想&#39;,
  &#39;打電&#39;,
  &#39;話給&#39;,
  &#39;加上&#39;,
  &#39;元旦&#39;,
  &#39;年&#39;,
  &#39;說&#39;,
  &#39;參&#39;,
  &#39;加某&#39;,
  &#39;台&#39;,
  &#39;灣機&#39;,
  &#39;品牌&#39;,
  &#39;活&#39;,
  &#39;動說&#39;,
  &#39;會&#39;,
  &#39;放歌&#39;,
  &#39;說聲&#39;,
  &#39;新年&#39;,
  &#39;快樂&#39;,
  &#39;樣&#39;,
  &#39;行徑&#39;,
  &#39;發生&#39;,
  &#39;晚上&#39;,
  &#39;八九&#39;,
  &#39;點&#39;,
  &#39;消失&#39;,
  &#39;隔天&#39;,
  &#39;早上&#39;,
  &#39;七&#39;,
  &#39;點&#39;,
  &#39;出現&#39;,
  &#39;發現&#39;,
  &#39;可能&#39;,
  &#39;表演&#39;,
  &#39;跨年&#39;,
  &#39;女人&#39;,
  &#39;聲稱&#39;,
  &#39;單身&#39;,
  &#39;陣子&#39;,
  &#39;表演&#39;,
  &#39;情侶&#39;,
  &#39;接受&#39;,
  &#39;消失&#39;,
  &#39;跨年&#39;,
  &#39;年&#39;,
  &#39;紀念&#39;,
  &#39;大吵時&#39;,
  &#39;電話&#39;,
  &#39;中說&#39;,
  &#39;受傷&#39;,
  &#39;說&#39;,
  &#39;決心&#39;,
  &#39;想要&#39;,
  &#39;走&#39;,
  &#39;下去&#39;,
  &#39;跨年&#39;,
  &#39;這天&#39;,
  &#39;潑&#39;,
  &#39;冷水&#39;,
  &#39;自尊心&#39;,
  &#39;踐踏&#39;,
  &#39;錯&#39;,
  &#39;怪&#39;,
  &#39;身上&#39;,
  &#39;錯&#39;,
  &#39;.&#39;,
  &#39;.&#39;,
  &#39;出軌&#39;,
  &#39;出軌&#39;,
  &#39;現&#39;,
  &#39;看到&#39;,
  &#39;覺&#39;,
  &#39;愚蠢&#39;,
  &#39;分手&#39;,
  &#39;愛情&#39;,
  &#39;蒙蔽&#39;,
  &#39;雙眼&#39;,
  &#39;為K&#39;,
  &#39;忙&#39;,
  &#39;無理&#39;,
  &#39;取鬧&#39;,
  &#39;鄭重&#39;,
  &#39;道歉&#39;,
  &#39;筆寫&#39;,
  &#39;信&#39;,
  &#39;寄&#39;,
  &#39;認&#39;,
  &#39;會&#39;,
  &#39;過年&#39;,
  &#39;K回台&#39;,
  &#39;會&#39;,
  &#39;步入&#39;,
  &#39;正軌&#39;,
  &#39;讀&#39;,
  &#39;期間&#39;,
  &#39;種人&#39;,
  &#39;出去&#39;,
  &#39;玩樂&#39;,
  &#39;動態&#39;,
  &#39;女生&#39;,
  &#39;出去&#39;,
  &#39;照片&#39;,
  &#39;受不了&#39;,
  &#39;退&#39;,
  &#39;追蹤&#39;,
  &#39;K告訴&#39;,
  &#39;沒辦法&#39;,
  &#39;繼續&#39;,
  &#39;努力&#39;,
  &#39;離讓&#39;,
  &#39;無力&#39;,
  &#39;分手&#39;,
  &#39;MobLprc.jpg&#39;,
  &#39;一月&#39;,
  &#39;期間&#39;,
  &#39;感受&#39;,
  &#39;努力&#39;,
  &#39;想要&#39;,
  &#39;溝通&#39;,
  &#39;冷淡&#39;,
  &#39;說&#39;,
  &#39;接電話&#39;,
  &#39;聽聽&#39;,
  &#39;新&#39;,
  &#39;想法&#39;,
  &#39;間&#39;,
  &#39;死&#39;,
  &#39;決定&#39;,
  &#39;放下&#39;,
  &#39;感情&#39;,
  &#39;結束&#39;,
  &#39;分手&#39;,
  &#39;收到&#39;,
  &#39;說K&#39;,
  &#39;交&#39;,
  &#39;女朋友&#39;,
  &#39;看到&#39;,
  &#39;覺&#39;,
  &#39;匿名&#39;,
  &#39;奇怪&#39;,
  &#39;懷疑&#39;,
  &#39;來搗亂&#39;,
  &#39;匿名&#39;,
  &#39;A給&#39;,
  &#39;N女&#39;,
  &#39;帳號&#39;,
  &#39;看到&#39;,
  &#39;崩潰&#39;,
  &#39;DEPbmoA.jpg&#39;,
  &#39;N女&#39;,
  &#39;台南&#39;,
  &#39;玩&#39;,
  &#39;動態&#39;,
  &#39;情侶&#39;,
  &#39;般&#39;,
  &#39;親密&#39;,
  &#39;互動&#39;,
  &#39;餵食&#39;,
  &#39;食物&#39;,
  &#39;畫&#39;,
  &#39;愛心&#39;,
  &#39;海灘&#39;,
  &#39;奔跑&#39;,
  &#39;月&#39;,
  &#39;說&#39;,
  &#39;回去&#39;,
  &#39;台南&#39;,
  &#39;.&#39;,
  &#39;N女&#39;,
  &#39;動態&#39;,
  &#39;對ㄌ&#39;,
  &#39;去年&#39;,
  &#39;八月&#39;,
  &#39;下面&#39;,
  &#39;月&#39;,
  &#39;對話&#39;,
  &#39;看到&#39;,
  &#39;動態&#39;,
  &#39;朋友&#39;,
  &#39;打抱不平&#39;,
  &#39;生氣&#39;,
  &#39;跑去&#39;,
  &#39;私訊&#39;,
  &#39;N女&#39;,
  &#39;做&#39;,
  &#39;錯事&#39;,
  &#39;樣子&#39;,
  &#39;動態&#39;,
  &#39;裡發&#39;,
  &#39;文&#39;,
  &#39;離然&#39;,
  &#39;寂寞&#39;,
  &#39;難耐&#39;,
  &#39;喜歡&#39;,
  &#39;N女&#39;,
  &#39;事情&#39;,
  &#39;開端&#39;,
  &#39;下為&#39;,
  &#39;朋友&#39;,
  &#39;對話&#39;,
  &#39;發生&#39;,
  &#39;事&#39;,
  &#39;算是&#39;,
  &#39;事&#39;,
  &#39;想&#39;,
  &#39;沒想&#39;,
  &#39;過會&#39;,
  &#39;遇到&#39;,
  &#39;事情&#39;,
  &#39;覺得&#39;,
  &#39;交往&#39;,
  &#39;相處&#39;,
  &#39;信任&#39;,
  &#39;過手&#39;,
  &#39;機&#39;,
  &#39;說&#39;,
  &#39;信&#39;,
  &#39;知道&#39;,
  &#39;交往&#39;,
  &#39;躺&#39;,
  &#39;旁邊&#39;,
  &#39;病態&#39;,
  &#39;程度&#39;,
  &#39;事&#39;,
  &#39;圖片&#39;,
  &#39;請&#39;,
  &#39;等待&#39;,
  &#39;整理&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">nouns_verbs</span><span class="p">,[])</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="n">wf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span><span class="o">=</span> <span class="mi">150</span>

<span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
               <span class="n">font_path</span><span class="o">=</span><span class="s1">&#39;/System/Library/Fonts/STHeiti Medium.ttc&#39;</span><span class="p">,</span>
               <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">max_font_size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1">## stopwords not work when wc.genreate_from_frequencies</span>
<span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">frequencies</span><span class="o">=</span><span class="n">wf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;wordcloud.wordcloud.WordCloud at 0x7fcad178c898&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4-chinese-nlp_19_0.png" src="../_images/4-chinese-nlp_19_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./exercise-ans"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>