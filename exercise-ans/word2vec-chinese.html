
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Assignment X: Word Embeddings &#8212; ENC2045 Computational Linguistics</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu-word-2.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ENC2045 Computational Linguistics</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  INTRODUCTION
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-primer.html">
   Natural Language Processing: A Primer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-pipeline.html">
   NLP Pipeline
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Preprocessing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../nlp/text-preprocessing.html">
   Text Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-normalization-eng.html">
     Text Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-tokenization.html">
     Text Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/text-enrichment.html">
     Text Enrichment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/chinese-word-seg.html">
     Chinese Word Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/google-colab.html">
     Google Colab
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Text Vectorization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/text-vec-traditional.html">
   Text Vectorization Using Traditional Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-overview.html">
   1. Machine Learning: Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-simple-case.html">
   2. Machine Learning: A Simple Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-algorithm.html">
   3. Classification Models
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine-Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-sklearn-classification.html">
   1. Sentiment Analysis Using Bag-of-Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/topic-modeling-naive.html">
   2. Topic Modeling: A Naive Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/ml-nlp-case.html">
   3. Machine Learning: NLP Tasks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep Learning NLP
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-neural-network-from-scratch.html">
   Neural Network From Scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding.html">
   Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/text-vec-embedding-keras.html">
   Word Embedding Using Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-statistical-language-model.html">
   Statistical Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-sequence-models-intuition.html">
   Sequence Models Intuition
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Attention, Transformers, and Transfer Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-seq-to-seq-types.html">
   Attention: Intuition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../temp/dl-transformers-intuition.html">
   Transformers: Intuition
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1-python-basics.html">
   1. Assignment I: Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2-journal-review.html">
   2. Assignment II: Journal Articles Review
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../exercise/3-preprocessing.html">
   3. Assignment III: Preprocessing
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-3-1.html">
     Student Sample 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exercise-student/Assignment-3-2.html">
     Student Sample 2
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4-chinese-nlp.html">
   4. Assignment IV: Chinese Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5-text-vectorization.html">
   5. Assignment V: Text Vectorization
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:center">
<i class="fas fa-chalkboard-teacher fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinntnu.github.io/NTNU_ENC2045/" target='_blank'>ENC2045 Course Website</a><br>
<i class="fas fa-home fa-2x" style="color:Maroon;margin-right:5px"></i><a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/exercise-ans/word2vec-chinese.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/NTNU_ENC2045_LECTURES/main?urlpath=tree/exercise-ans/word2vec-chinese.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/NTNU_ENC2045_LECTURES/blob/main/exercise-ans/word2vec-chinese.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-1">
   Question 1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alice-corpus">
   Alice Corpus
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-2">
   Question 2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loading-corpus-raw-texts">
     Loading Corpus Raw Texts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word-segmentation">
     Word Segmentation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-frame-representation">
     Data Frame Representation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word-cloud">
     Word Cloud
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-word-embeddings">
     Creating Word Embeddings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-semantic-similarities">
     Exploring Semantic Similarities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualization">
     Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-3">
   Question 3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#question-4">
   Question 4
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="assignment-x-word-embeddings">
<h1>Assignment X: Word Embeddings<a class="headerlink" href="#assignment-x-word-embeddings" title="Permalink to this headline">¶</a></h1>
<div class="section" id="question-1">
<h2>Question 1<a class="headerlink" href="#question-1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Alice in the wonderland</p></li>
<li><p>verbs?</p></li>
<li><p>word embeddings/</p></li>
</ul>
</div>
<div class="section" id="alice-corpus">
<h2>Alice Corpus<a class="headerlink" href="#alice-corpus" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">word2vec</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span><span class="o">=</span> <span class="mi">300</span>
<span class="c1">#%matplotlib inline</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(gutenberg.fileids())</span>
<span class="n">alice</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">sents</span><span class="p">(</span><span class="s1">&#39;carroll-alice.txt&#39;</span><span class="p">)</span>

<span class="c1"># remove tokens that contain non-alphanumeric chars</span>
<span class="n">alice_norm</span> <span class="o">=</span> <span class="p">[[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sent</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\W&#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">)]</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">alice</span><span class="p">]</span>
<span class="c1"># concatenate tokens into long strings</span>
<span class="n">alice_norm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">alice_norm</span><span class="p">]</span>


<span class="c1">## check short lines with less than 2 tokens</span>
<span class="c1"># print([t for (t,s) in zip(alice,alice_norm) if s==None])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Sentences:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">alice_norm</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Line (Raw):&quot;</span><span class="p">,</span> <span class="n">alice</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Line (Norm):&quot;</span><span class="p">,</span> <span class="n">alice_norm</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Sentences: 1703
Sample Line (Raw): [&#39;Would&#39;, &#39;the&#39;, &#39;fall&#39;, &#39;NEVER&#39;, &#39;come&#39;, &#39;to&#39;, &#39;an&#39;, &#39;end&#39;, &#39;!&#39;]
Sample Line (Norm): would the fall never come to an end
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="c1"># tokenize sentences in corpus</span>
<span class="n">wpt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">WordPunctTokenizer</span><span class="p">()</span>
<span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">wpt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">alice_norm</span> <span class="k">if</span> <span class="n">document</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># Set values for various parameters</span>
<span class="n">feature_size</span> <span class="o">=</span> <span class="mi">100</span>    <span class="c1"># Word vector dimensionality  </span>
<span class="n">window_context</span> <span class="o">=</span> <span class="mi">5</span>          <span class="c1"># Context window size                                                                                    </span>
<span class="n">min_word_count</span> <span class="o">=</span> <span class="mi">5</span>   <span class="c1"># Minimum word count                        </span>
<span class="n">sample</span> <span class="o">=</span> <span class="mf">1e-3</span>   <span class="c1"># Downsample setting for frequent words</span>

<span class="n">w2v_model_alice</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">feature_size</span><span class="p">,</span> 
                          <span class="n">window</span><span class="o">=</span><span class="n">window_context</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="n">min_word_count</span><span class="p">,</span>
                          <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">sg</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># `sg=1` for skip-gram; `sg=0` for CBOW</span>

<span class="c1"># view similar words based on gensim&#39;s model</span>
<span class="n">similar_words</span> <span class="o">=</span> <span class="p">{</span><span class="n">search_term</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w2v_model_alice</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="n">search_term</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)]</span>
                  <span class="k">for</span> <span class="n">search_term</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;alice&#39;</span><span class="p">,</span> <span class="s1">&#39;rabbit&#39;</span><span class="p">,</span> <span class="s1">&#39;queen&#39;</span><span class="p">,</span> <span class="s1">&#39;king&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;caterpillar&#39;</span><span class="p">,</span><span class="s1">&#39;hatter&#39;</span><span class="p">,</span><span class="s1">&#39;could&#39;</span><span class="p">,</span><span class="s1">&#39;would&#39;</span><span class="p">]}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similar_words</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;alice&#39;: [&#39;she&#39;, &#39;feeling&#39;, &#39;politely&#39;, &#39;frightened&#39;, &#39;hastily&#39;], &#39;rabbit&#39;: [&#39;white&#39;, &#39;kid&#39;, &#39;hole&#39;, &#39;loud&#39;, &#39;fan&#39;], &#39;queen&#39;: [&#39;executioner&#39;, &#39;hearts&#39;, &#39;reply&#39;, &#39;shrill&#39;, &#39;ground&#39;], &#39;king&#39;: [&#39;executioner&#39;, &#39;important&#39;, &#39;unimportant&#39;, &#39;jury&#39;, &#39;aloud&#39;], &#39;cat&#39;: [&#39;cheshire&#39;, &#39;cats&#39;, &#39;somebody&#39;, &#39;grin&#39;, &#39;our&#39;], &#39;caterpillar&#39;: [&#39;hookah&#39;, &#39;father&#39;, &#39;cook&#39;, &#39;lory&#39;, &#39;william&#39;], &#39;hatter&#39;: [&#39;hare&#39;, &#39;tea&#39;, &#39;dormouse&#39;, &#39;march&#39;, &#39;isn&#39;], &#39;could&#39;: [&#39;pack&#39;, &#39;swim&#39;, &#39;even&#39;, &#39;join&#39;, &#39;dare&#39;], &#39;would&#39;: [&#39;simple&#39;, &#39;makes&#39;, &#39;lobsters&#39;, &#39;told&#39;, &#39;dance&#39;]}
CPU times: user 4.06 s, sys: 48.8 ms, total: 4.11 s
Wall time: 1.96 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="n">words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">similar_words</span><span class="o">.</span><span class="n">items</span><span class="p">()],</span> <span class="p">[])</span>
<span class="n">wvs</span> <span class="o">=</span> <span class="n">w2v_model_alice</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">words</span><span class="p">]</span>

<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">wvs</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">words</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">T</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">T</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/word2vec-chinese_6_0.png" src="../_images/word2vec-chinese_6_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="kn">from</span> <span class="nn">gensim.models.fasttext</span> <span class="kn">import</span> <span class="n">FastText</span>

<span class="n">wpt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">WordPunctTokenizer</span><span class="p">()</span>
<span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">wpt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">alice_norm</span> <span class="k">if</span> <span class="n">document</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># Set values for various parameters</span>
<span class="n">feature_size</span> <span class="o">=</span> <span class="mi">100</span>    <span class="c1"># Word vector dimensionality  </span>
<span class="n">window_context</span> <span class="o">=</span> <span class="mi">5</span>          <span class="c1"># Context window size                                                                                    </span>
<span class="n">min_word_count</span> <span class="o">=</span> <span class="mi">5</span>   <span class="c1"># Minimum word count                        </span>
<span class="n">sample</span> <span class="o">=</span> <span class="mf">1e-3</span>   <span class="c1"># Downsample setting for frequent words</span>


<span class="n">ft_model_alice</span> <span class="o">=</span> <span class="n">FastText</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">feature_size</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">window_context</span><span class="p">,</span> 
                    <span class="n">min_count</span><span class="o">=</span><span class="n">min_word_count</span><span class="p">,</span><span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 14.7 s, sys: 2.48 s, total: 17.2 s
Wall time: 13.4 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view similar words based on gensim&#39;s model</span>
<span class="n">similar_words2</span> <span class="o">=</span> <span class="p">{</span><span class="n">search_term</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w2v_model_alice</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="n">search_term</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">3</span><span class="p">)]</span>
                  <span class="k">for</span> <span class="n">search_term</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;alice&#39;</span><span class="p">,</span> <span class="s1">&#39;rabbit&#39;</span><span class="p">,</span> <span class="s1">&#39;queen&#39;</span><span class="p">,</span> <span class="s1">&#39;king&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;caterpillar&#39;</span><span class="p">,</span><span class="s1">&#39;hatter&#39;</span><span class="p">,</span><span class="s1">&#39;could&#39;</span><span class="p">,</span><span class="s1">&#39;would&#39;</span><span class="p">]}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similar_words2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;alice&#39;: [&#39;she&#39;, &#39;feeling&#39;, &#39;politely&#39;], &#39;rabbit&#39;: [&#39;white&#39;, &#39;kid&#39;, &#39;hole&#39;], &#39;queen&#39;: [&#39;executioner&#39;, &#39;hearts&#39;, &#39;reply&#39;], &#39;king&#39;: [&#39;executioner&#39;, &#39;important&#39;, &#39;unimportant&#39;], &#39;cat&#39;: [&#39;cheshire&#39;, &#39;cats&#39;, &#39;somebody&#39;], &#39;caterpillar&#39;: [&#39;hookah&#39;, &#39;father&#39;, &#39;cook&#39;], &#39;hatter&#39;: [&#39;hare&#39;, &#39;tea&#39;, &#39;dormouse&#39;], &#39;could&#39;: [&#39;pack&#39;, &#39;swim&#39;, &#39;even&#39;], &#39;would&#39;: [&#39;simple&#39;, &#39;makes&#39;, &#39;lobsters&#39;]}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">similar_words2</span><span class="o">.</span><span class="n">items</span><span class="p">()],</span> <span class="p">[])</span>
<span class="n">wvs</span> <span class="o">=</span> <span class="n">ft_model_alice</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">words</span><span class="p">]</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">wvs</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">words</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">P</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">P</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">P</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">P</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mf">0.06</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="mf">0.03</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/word2vec-chinese_9_0.png" src="../_images/word2vec-chinese_9_0.png" />
</div>
</div>
<ul class="simple">
<li><p>English Word Embeddings</p></li>
</ul>
</div>
<div class="section" id="question-2">
<h2>Question 2<a class="headerlink" href="#question-2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Chinese Word Embeddings on Presidential Inaugural Speech</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DEMO_DATA_ROOT</span> <span class="o">=</span> <span class="s2">&quot;../../../RepositoryData/data&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="loading-corpus-raw-texts">
<h3>Loading Corpus Raw Texts<a class="headerlink" href="#loading-corpus-raw-texts" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus.reader</span> <span class="kn">import</span> <span class="n">PlaintextCorpusReader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">jieba</span><span class="o">,</span> <span class="nn">re</span>

<span class="n">jieba</span><span class="o">.</span><span class="n">set_dictionary</span><span class="p">(</span><span class="n">DEMO_DATA_ROOT</span> <span class="o">+</span> <span class="s2">&quot;/jiaba/dict.txt.big.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus_dir</span> <span class="o">=</span> <span class="n">DEMO_DATA_ROOT</span><span class="o">+</span><span class="s2">&quot;/TaiwanPresidentialInaugarationSpeech_en&quot;</span>

<span class="n">twp</span> <span class="o">=</span> <span class="n">PlaintextCorpusReader</span><span class="p">(</span><span class="n">corpus_dir</span><span class="p">,</span> <span class="s2">&quot;.*\.txt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">twp</span><span class="o">.</span><span class="n">raw</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="word-segmentation">
<h3>Word Segmentation<a class="headerlink" href="#word-segmentation" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Try two methods: <code class="docutils literal notranslate"><span class="pre">ckiptagger</span></code> vs. <code class="docutils literal notranslate"><span class="pre">jieba</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ckiptagger</span> <span class="kn">import</span> <span class="n">WS</span><span class="p">,</span> <span class="n">POS</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ws</span> <span class="o">=</span> <span class="n">WS</span><span class="p">(</span><span class="s2">&quot;/Users/Alvin/Dropbox/Corpus/CKIP_WordSeg/data&quot;</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">POS</span><span class="p">(</span><span class="s2">&quot;/Users/Alvin/Dropbox/Corpus/CKIP_WordSeg/data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Print first 200 chars of file 13</span>
<span class="nb">print</span><span class="p">(</span><span class="n">twp</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileids</span><span class="o">=</span><span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">()[</span><span class="mi">13</span><span class="p">])[:</span><span class="mi">200</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># word-seg the raw text and return a long string</span>
<span class="k">def</span> <span class="nf">tokenize_raw1</span><span class="p">(</span><span class="n">raw</span><span class="p">):</span>
    <span class="n">word_tok</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">para</span><span class="p">)</span> <span class="k">for</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">ws</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">regexp_tokenize</span><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;[^\s]+&#39;</span><span class="p">))]</span> <span class="c1"># para-like units</span>
    <span class="n">raw_tok</span>  <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word_tok</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">raw_tok</span>


<span class="c1"># word-seg the raw text and return list of words</span>
<span class="k">def</span> <span class="nf">tokenize_raw2</span><span class="p">(</span><span class="n">raw</span><span class="p">):</span>
    <span class="n">para_list</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">regexp_tokenize</span><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;[^\s]+&#39;</span><span class="p">)</span> <span class="c1"># para-like units</span>
    <span class="n">word_list</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ws</span><span class="p">(</span><span class="n">para_list</span><span class="p">),[])</span> 
    <span class="k">return</span> <span class="n">word_list</span>


<span class="k">def</span> <span class="nf">tokenize_raw3</span><span class="p">(</span><span class="n">raw</span><span class="p">):</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[\n\s\r]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">raw</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">raw</span><span class="p">)])</span>

<span class="n">tokenize_corpus1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">tokenize_raw1</span><span class="p">)</span>
<span class="n">tokenize_corpus2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">tokenize_raw2</span><span class="p">)</span>
<span class="n">tokenize_corpus3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">tokenize_raw3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following experiments try to see whether a few parameters may impact the performance of Chinese tokenization:</p>
<ol class="simple">
<li><p>Segmenter: <code class="docutils literal notranslate"><span class="pre">ckiptagger</span></code> vs. <code class="docutils literal notranslate"><span class="pre">jibea</span></code></p></li>
<li><p>Data Structure: <code class="docutils literal notranslate"><span class="pre">List</span></code> vs. <code class="docutils literal notranslate"><span class="pre">numpy.array</span></code></p></li>
</ol>
<p>It seems that <code class="docutils literal notranslate"><span class="pre">jieba</span></code> with <code class="docutils literal notranslate"><span class="pre">List</span></code> structure is the fastest?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">twp</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileids</span><span class="o">=</span><span class="n">fid</span><span class="p">)</span> <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">()])</span>
<span class="n">twp_corpus_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">twp</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileids</span><span class="o">=</span><span class="n">fid</span><span class="p">)</span> <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">twp_corpus_seg1a</span> <span class="o">=</span> <span class="n">tokenize_corpus1</span><span class="p">(</span><span class="n">twp_corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">twp_corpus_seg1b</span> <span class="o">=</span> <span class="n">tokenize_corpus1</span><span class="p">(</span><span class="n">twp_corpus_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">twp_corpus_seg3a</span> <span class="o">=</span> <span class="n">tokenize_corpus3</span><span class="p">(</span><span class="n">twp_corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">twp_corpus_seg3b</span> <span class="o">=</span> <span class="n">tokenize_corpus3</span><span class="p">(</span><span class="n">twp_corpus_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_corpus</span><span class="p">[</span><span class="mi">13</span><span class="p">,][:</span><span class="mi">200</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_corpus_seg1a</span><span class="p">[</span><span class="mi">13</span><span class="p">][:</span><span class="mi">200</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_corpus_seg3a</span><span class="p">[</span><span class="mi">13</span><span class="p">][:</span><span class="mi">200</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-frame-representation">
<h3>Data Frame Representation<a class="headerlink" href="#data-frame-representation" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## data frame representation</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">re</span>


<span class="n">twp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;fileid&quot;</span><span class="p">:</span> <span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">(),</span>
    <span class="s2">&quot;corpus_raw&quot;</span><span class="p">:</span> <span class="n">twp_corpus</span><span class="p">,</span>
    <span class="s2">&quot;corpus_seg_ckip&quot;</span><span class="p">:</span> <span class="n">twp_corpus_seg1a</span><span class="p">,</span>
    <span class="s2">&quot;corpus_seg_jb&quot;</span><span class="p">:</span> <span class="n">twp_corpus_seg3a</span>
<span class="p">})</span>
<span class="n">twp_df</span><span class="p">[[</span><span class="s1">&#39;year&#39;</span><span class="p">,</span><span class="s1">&#39;id&#39;</span><span class="p">,</span><span class="s1">&#39;president&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">twp_df</span><span class="p">[</span><span class="s1">&#39;fileid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">twp_df</span><span class="p">[</span><span class="s1">&#39;president&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">twp_df</span><span class="p">[</span><span class="s1">&#39;president&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">twp_df</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="word-cloud">
<h3>Word Cloud<a class="headerlink" href="#word-cloud" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## choose one version of segmented texts</span>
<span class="n">twp_corpus_seg</span> <span class="o">=</span> <span class="n">twp_corpus_seg1a</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wst</span> <span class="o">=</span><span class="n">nltk</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">tokenized_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">wst</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">twp_corpus_seg</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Concordance</span>

<span class="n">twp_text</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,[]))</span>
<span class="n">twp_text</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="s1">&#39;台灣&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span><span class="p">,</span> <span class="n">ImageColorGenerator</span><span class="p">,</span> <span class="n">STOPWORDS</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,[])</span>
<span class="n">words</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="nb">sorted</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  



<span class="c1">## Check font paths</span>
<span class="c1">## !fc-list :lang=zh</span>


<span class="c1">## Load stopwords</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">DEMO_DATA_ROOT</span><span class="o">+</span><span class="s1">&#39;/stopwords/tomlinNTUB-chinese-stopwords.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">stopwords</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create stopwords ad hoc</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s1">&#39;一個&#39;</span><span class="p">])</span>
<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/PingFang.ttc&quot;</span><span class="p">,</span>
                      <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;ghostwhite&#39;</span><span class="p">,</span>
                      <span class="c1">#stopwords=stopwords,</span>
                      <span class="n">width</span><span class="o">=</span><span class="mi">1600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span> 
                     <span class="p">)</span>  <span class="c1">##add  system chinese font path</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">#plt.savefig(&#39;../data/twp-wordcloud2.png&#39;, facecolor=&#39;k&#39;, bbox_inches=&#39;tight&#39;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">back_color</span> <span class="o">=</span> <span class="n">imageio</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">DEMO_DATA_ROOT</span><span class="o">+</span> <span class="s1">&#39;/image/tw-char.jpg&#39;</span><span class="p">)</span>
<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">font_path</span><span class="o">=</span><span class="s2">&quot;/System/Library/Fonts/PingFang.ttc&quot;</span><span class="p">,</span>
                      <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
                      <span class="n">mask</span><span class="o">=</span><span class="n">back_color</span><span class="p">,</span>
                      <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                      <span class="n">max_words</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span>
                      <span class="c1">#max_font_size=40,</span>
                      <span class="n">min_font_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                      <span class="n">width</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                      <span class="n">height</span><span class="o">=</span><span class="mi">1600</span><span class="p">)</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]))</span>
<span class="n">image_colors</span> <span class="o">=</span> <span class="n">ImageColorGenerator</span><span class="p">(</span><span class="n">back_color</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">fig_path</span> <span class="o">=</span> <span class="s1">&#39;twp-wordcloud.png&#39;</span>
<span class="n">wordcloud</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="n">fig_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="creating-word-embeddings">
<h3>Creating Word Embeddings<a class="headerlink" href="#creating-word-embeddings" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Set features for parameters</span>
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">context_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">min_word_count</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sample</span> <span class="o">=</span> <span class="mf">1e-3</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">word2vec</span>

<span class="n">w2v_model</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">tokenized_corpus</span><span class="p">,</span> 
                              <span class="n">size</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span>
                              <span class="n">window</span><span class="o">=</span><span class="n">context_size</span><span class="p">,</span>
                              <span class="n">min_count</span><span class="o">=</span><span class="n">min_word_count</span><span class="p">,</span>
                              <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span>
                              <span class="nb">iter</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exploring-semantic-similarities">
<h3>Exploring Semantic Similarities<a class="headerlink" href="#exploring-semantic-similarities" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## View Similar Words</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;人民&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;台灣&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">similar_words</span> <span class="o">=</span> <span class="p">{</span><span class="n">key_word</span><span class="p">:[</span><span class="n">similar_word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">similar_word</span> <span class="ow">in</span> <span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">key_word</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">6</span><span class="p">)]</span>
                          <span class="k">for</span> <span class="n">key_word</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;台灣&#39;</span><span class="p">,</span><span class="s1">&#39;人民&#39;</span><span class="p">,</span><span class="s1">&#39;國家&#39;</span><span class="p">,</span><span class="s1">&#39;民主&#39;</span><span class="p">,</span><span class="s1">&#39;中共&#39;</span><span class="p">,</span><span class="s1">&#39;大陸&#39;</span><span class="p">,</span><span class="s1">&#39;共匪&#39;</span><span class="p">,</span><span class="s1">&#39;自由&#39;</span><span class="p">,</span><span class="s1">&#39;美國&#39;</span><span class="p">]}</span>
<span class="n">similar_words</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="visualization">
<h3>Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Visualization</span>

<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="n">all_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">key_word</span><span class="p">]</span><span class="o">+</span><span class="n">similar_words</span> <span class="k">for</span> <span class="n">key_word</span><span class="p">,</span> <span class="n">similar_words</span> <span class="ow">in</span> <span class="n">similar_words</span><span class="o">.</span><span class="n">items</span><span class="p">()],</span> <span class="p">[])</span>
<span class="n">all_words_vec</span> <span class="o">=</span> <span class="n">w2v_model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">all_words</span><span class="p">]</span>

<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">all_words_vec</span><span class="p">)</span>
<span class="n">labels</span><span class="o">=</span><span class="n">all_words</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Chinese Font Issues in Plotting</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="kn">from</span> <span class="nn">matplotlib.font_manager</span> <span class="kn">import</span> <span class="n">FontProperties</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># rcParams[&#39;axes.unicode_minus&#39;]=False</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">myfont</span> <span class="o">=</span> <span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;/System/Library/Fonts/PingFang.ttc&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">T</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">label</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">T</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">T</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span><span class="n">fontproperties</span><span class="o">=</span><span class="n">myfont</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="question-3">
<h2>Question 3<a class="headerlink" href="#question-3" title="Permalink to this headline">¶</a></h2>
<p>Use pre-trained embeddings for cluster documents.</p>
<p>For word tokenization:</p>
<ul class="simple">
<li><p>Use spacy <code class="docutils literal notranslate"><span class="pre">en_core_web_lg</span></code></p></li>
<li><p>Cluster documents based on their average word embeddings (300 dimensions)</p></li>
<li><p>No filtering of words</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">inaugural</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en_core_web_lg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_vectors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Word Vectors:&#39;</span><span class="p">,</span> <span class="n">total_vectors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Word Vectors: 684830
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Use spacy to get the document vectors to cluster</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># get doc-level averaged vectors</span>

<span class="n">usp_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">inaugural</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileids</span><span class="o">=</span><span class="n">fid</span><span class="p">)</span> <span class="k">for</span> <span class="n">fid</span> <span class="ow">in</span> <span class="n">inaugural</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>

<span class="n">usp_corpus_pipe</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">usp_corpus</span><span class="p">)</span>
<span class="n">usp_corpus_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">vector</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">usp_corpus_pipe</span> <span class="k">if</span> <span class="n">doc</span><span class="o">.</span><span class="n">has_vector</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 20.5 s, sys: 1.91 s, total: 22.5 s
Wall time: 22.9 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">usp_corpus_vec</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(58, 300)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">textid</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">inaugural</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>
<span class="n">similarity_doc_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">usp_corpus_vec</span><span class="p">)</span>
<span class="n">similarity_doc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">,</span>
                                <span class="n">index</span><span class="o">=</span><span class="n">textid</span><span class="p">,</span>
                                <span class="n">columns</span><span class="o">=</span><span class="n">textid</span><span class="p">)</span>
<span class="n">similarity_doc_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1789-Washington</th>
      <th>1793-Washington</th>
      <th>1797-Adams</th>
      <th>1801-Jefferson</th>
      <th>1805-Jefferson</th>
      <th>1809-Madison</th>
      <th>1813-Madison</th>
      <th>1817-Monroe</th>
      <th>1821-Monroe</th>
      <th>1825-Adams</th>
      <th>...</th>
      <th>1981-Reagan</th>
      <th>1985-Reagan</th>
      <th>1989-Bush</th>
      <th>1993-Clinton</th>
      <th>1997-Clinton</th>
      <th>2001-Bush</th>
      <th>2005-Bush</th>
      <th>2009-Obama</th>
      <th>2013-Obama</th>
      <th>2017-Trump</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1789-Washington</th>
      <td>1.000000</td>
      <td>0.984878</td>
      <td>0.995147</td>
      <td>0.995411</td>
      <td>0.995921</td>
      <td>0.996675</td>
      <td>0.994359</td>
      <td>0.996029</td>
      <td>0.995247</td>
      <td>0.992055</td>
      <td>...</td>
      <td>0.986210</td>
      <td>0.984592</td>
      <td>0.979744</td>
      <td>0.979804</td>
      <td>0.983050</td>
      <td>0.983414</td>
      <td>0.988405</td>
      <td>0.985737</td>
      <td>0.985897</td>
      <td>0.976485</td>
    </tr>
    <tr>
      <th>1793-Washington</th>
      <td>0.984878</td>
      <td>1.000000</td>
      <td>0.979064</td>
      <td>0.980040</td>
      <td>0.979855</td>
      <td>0.980850</td>
      <td>0.979593</td>
      <td>0.978495</td>
      <td>0.979905</td>
      <td>0.978952</td>
      <td>...</td>
      <td>0.969932</td>
      <td>0.968063</td>
      <td>0.963082</td>
      <td>0.961651</td>
      <td>0.964160</td>
      <td>0.966520</td>
      <td>0.974160</td>
      <td>0.966003</td>
      <td>0.967889</td>
      <td>0.959819</td>
    </tr>
    <tr>
      <th>1797-Adams</th>
      <td>0.995147</td>
      <td>0.979064</td>
      <td>1.000000</td>
      <td>0.996836</td>
      <td>0.996357</td>
      <td>0.995833</td>
      <td>0.994133</td>
      <td>0.995444</td>
      <td>0.995159</td>
      <td>0.992922</td>
      <td>...</td>
      <td>0.987519</td>
      <td>0.987122</td>
      <td>0.980362</td>
      <td>0.982656</td>
      <td>0.985610</td>
      <td>0.986268</td>
      <td>0.991875</td>
      <td>0.986466</td>
      <td>0.985879</td>
      <td>0.980082</td>
    </tr>
    <tr>
      <th>1801-Jefferson</th>
      <td>0.995411</td>
      <td>0.980040</td>
      <td>0.996836</td>
      <td>1.000000</td>
      <td>0.997605</td>
      <td>0.995725</td>
      <td>0.993608</td>
      <td>0.995258</td>
      <td>0.992867</td>
      <td>0.990582</td>
      <td>...</td>
      <td>0.992771</td>
      <td>0.991856</td>
      <td>0.987243</td>
      <td>0.989480</td>
      <td>0.990766</td>
      <td>0.991621</td>
      <td>0.995475</td>
      <td>0.992918</td>
      <td>0.992549</td>
      <td>0.986645</td>
    </tr>
    <tr>
      <th>1805-Jefferson</th>
      <td>0.995921</td>
      <td>0.979855</td>
      <td>0.996357</td>
      <td>0.997605</td>
      <td>1.000000</td>
      <td>0.996422</td>
      <td>0.994365</td>
      <td>0.996315</td>
      <td>0.995215</td>
      <td>0.990830</td>
      <td>...</td>
      <td>0.990597</td>
      <td>0.988671</td>
      <td>0.982631</td>
      <td>0.985335</td>
      <td>0.986885</td>
      <td>0.988334</td>
      <td>0.992062</td>
      <td>0.990233</td>
      <td>0.990316</td>
      <td>0.982970</td>
    </tr>
    <tr>
      <th>1809-Madison</th>
      <td>0.996675</td>
      <td>0.980850</td>
      <td>0.995833</td>
      <td>0.995725</td>
      <td>0.996422</td>
      <td>1.000000</td>
      <td>0.996375</td>
      <td>0.997183</td>
      <td>0.995316</td>
      <td>0.995387</td>
      <td>...</td>
      <td>0.985634</td>
      <td>0.984529</td>
      <td>0.976437</td>
      <td>0.980069</td>
      <td>0.984644</td>
      <td>0.983880</td>
      <td>0.990701</td>
      <td>0.985869</td>
      <td>0.986502</td>
      <td>0.977609</td>
    </tr>
    <tr>
      <th>1813-Madison</th>
      <td>0.994359</td>
      <td>0.979593</td>
      <td>0.994133</td>
      <td>0.993608</td>
      <td>0.994365</td>
      <td>0.996375</td>
      <td>1.000001</td>
      <td>0.995724</td>
      <td>0.995724</td>
      <td>0.994184</td>
      <td>...</td>
      <td>0.985924</td>
      <td>0.985979</td>
      <td>0.977283</td>
      <td>0.980455</td>
      <td>0.985236</td>
      <td>0.983550</td>
      <td>0.990505</td>
      <td>0.986500</td>
      <td>0.986124</td>
      <td>0.978471</td>
    </tr>
    <tr>
      <th>1817-Monroe</th>
      <td>0.996029</td>
      <td>0.978495</td>
      <td>0.995444</td>
      <td>0.995258</td>
      <td>0.996315</td>
      <td>0.997183</td>
      <td>0.995724</td>
      <td>1.000000</td>
      <td>0.998122</td>
      <td>0.993730</td>
      <td>...</td>
      <td>0.990336</td>
      <td>0.989043</td>
      <td>0.982400</td>
      <td>0.984682</td>
      <td>0.988608</td>
      <td>0.987530</td>
      <td>0.992253</td>
      <td>0.989618</td>
      <td>0.989983</td>
      <td>0.983361</td>
    </tr>
    <tr>
      <th>1821-Monroe</th>
      <td>0.995247</td>
      <td>0.979905</td>
      <td>0.995159</td>
      <td>0.992867</td>
      <td>0.995215</td>
      <td>0.995316</td>
      <td>0.995724</td>
      <td>0.998122</td>
      <td>0.999999</td>
      <td>0.993530</td>
      <td>...</td>
      <td>0.987214</td>
      <td>0.986302</td>
      <td>0.978821</td>
      <td>0.980137</td>
      <td>0.984373</td>
      <td>0.982719</td>
      <td>0.988643</td>
      <td>0.985501</td>
      <td>0.984886</td>
      <td>0.978818</td>
    </tr>
    <tr>
      <th>1825-Adams</th>
      <td>0.992055</td>
      <td>0.978952</td>
      <td>0.992922</td>
      <td>0.990582</td>
      <td>0.990830</td>
      <td>0.995387</td>
      <td>0.994184</td>
      <td>0.993730</td>
      <td>0.993530</td>
      <td>1.000001</td>
      <td>...</td>
      <td>0.977643</td>
      <td>0.978597</td>
      <td>0.966633</td>
      <td>0.971966</td>
      <td>0.979890</td>
      <td>0.975559</td>
      <td>0.986688</td>
      <td>0.978106</td>
      <td>0.978866</td>
      <td>0.970515</td>
    </tr>
    <tr>
      <th>1829-Jackson</th>
      <td>0.995951</td>
      <td>0.981070</td>
      <td>0.994520</td>
      <td>0.994290</td>
      <td>0.995688</td>
      <td>0.997892</td>
      <td>0.994350</td>
      <td>0.996643</td>
      <td>0.994453</td>
      <td>0.994707</td>
      <td>...</td>
      <td>0.983727</td>
      <td>0.981999</td>
      <td>0.973411</td>
      <td>0.977393</td>
      <td>0.981828</td>
      <td>0.981821</td>
      <td>0.988586</td>
      <td>0.983319</td>
      <td>0.984976</td>
      <td>0.974845</td>
    </tr>
    <tr>
      <th>1833-Jackson</th>
      <td>0.995177</td>
      <td>0.981126</td>
      <td>0.994459</td>
      <td>0.995453</td>
      <td>0.995950</td>
      <td>0.997814</td>
      <td>0.995246</td>
      <td>0.996454</td>
      <td>0.994452</td>
      <td>0.996332</td>
      <td>...</td>
      <td>0.986135</td>
      <td>0.985625</td>
      <td>0.976402</td>
      <td>0.981160</td>
      <td>0.985915</td>
      <td>0.983780</td>
      <td>0.991483</td>
      <td>0.986348</td>
      <td>0.987685</td>
      <td>0.979457</td>
    </tr>
    <tr>
      <th>1837-VanBuren</th>
      <td>0.997132</td>
      <td>0.979465</td>
      <td>0.995547</td>
      <td>0.996498</td>
      <td>0.997712</td>
      <td>0.997487</td>
      <td>0.996082</td>
      <td>0.997200</td>
      <td>0.995804</td>
      <td>0.992917</td>
      <td>...</td>
      <td>0.989616</td>
      <td>0.988521</td>
      <td>0.981917</td>
      <td>0.984427</td>
      <td>0.987152</td>
      <td>0.987704</td>
      <td>0.991836</td>
      <td>0.990500</td>
      <td>0.990337</td>
      <td>0.981309</td>
    </tr>
    <tr>
      <th>1841-Harrison</th>
      <td>0.996547</td>
      <td>0.984176</td>
      <td>0.995456</td>
      <td>0.993744</td>
      <td>0.994771</td>
      <td>0.996229</td>
      <td>0.995675</td>
      <td>0.996543</td>
      <td>0.996776</td>
      <td>0.995657</td>
      <td>...</td>
      <td>0.983650</td>
      <td>0.982628</td>
      <td>0.975313</td>
      <td>0.976015</td>
      <td>0.981576</td>
      <td>0.980141</td>
      <td>0.988099</td>
      <td>0.982552</td>
      <td>0.983003</td>
      <td>0.973709</td>
    </tr>
    <tr>
      <th>1845-Polk</th>
      <td>0.994352</td>
      <td>0.980833</td>
      <td>0.994124</td>
      <td>0.992897</td>
      <td>0.995125</td>
      <td>0.996879</td>
      <td>0.994985</td>
      <td>0.997363</td>
      <td>0.996248</td>
      <td>0.996059</td>
      <td>...</td>
      <td>0.984364</td>
      <td>0.983254</td>
      <td>0.973426</td>
      <td>0.977386</td>
      <td>0.982950</td>
      <td>0.981469</td>
      <td>0.989114</td>
      <td>0.983499</td>
      <td>0.985173</td>
      <td>0.976562</td>
    </tr>
    <tr>
      <th>1849-Taylor</th>
      <td>0.993819</td>
      <td>0.984255</td>
      <td>0.993084</td>
      <td>0.993102</td>
      <td>0.994177</td>
      <td>0.996145</td>
      <td>0.991413</td>
      <td>0.993880</td>
      <td>0.992048</td>
      <td>0.993927</td>
      <td>...</td>
      <td>0.980572</td>
      <td>0.978725</td>
      <td>0.969689</td>
      <td>0.974634</td>
      <td>0.978297</td>
      <td>0.979331</td>
      <td>0.986728</td>
      <td>0.979633</td>
      <td>0.982047</td>
      <td>0.971975</td>
    </tr>
    <tr>
      <th>1853-Pierce</th>
      <td>0.997477</td>
      <td>0.980679</td>
      <td>0.996367</td>
      <td>0.997194</td>
      <td>0.997385</td>
      <td>0.997250</td>
      <td>0.995815</td>
      <td>0.997575</td>
      <td>0.996034</td>
      <td>0.992429</td>
      <td>...</td>
      <td>0.990351</td>
      <td>0.988876</td>
      <td>0.983408</td>
      <td>0.985109</td>
      <td>0.987597</td>
      <td>0.988674</td>
      <td>0.992857</td>
      <td>0.990694</td>
      <td>0.990596</td>
      <td>0.982052</td>
    </tr>
    <tr>
      <th>1857-Buchanan</th>
      <td>0.995859</td>
      <td>0.982590</td>
      <td>0.995709</td>
      <td>0.995075</td>
      <td>0.995738</td>
      <td>0.996562</td>
      <td>0.995917</td>
      <td>0.998308</td>
      <td>0.997658</td>
      <td>0.994089</td>
      <td>...</td>
      <td>0.989070</td>
      <td>0.988087</td>
      <td>0.980712</td>
      <td>0.982739</td>
      <td>0.987007</td>
      <td>0.986314</td>
      <td>0.992005</td>
      <td>0.987987</td>
      <td>0.988497</td>
      <td>0.981471</td>
    </tr>
    <tr>
      <th>1861-Lincoln</th>
      <td>0.993374</td>
      <td>0.984271</td>
      <td>0.991365</td>
      <td>0.992244</td>
      <td>0.994267</td>
      <td>0.991100</td>
      <td>0.990278</td>
      <td>0.992932</td>
      <td>0.993294</td>
      <td>0.984708</td>
      <td>...</td>
      <td>0.987580</td>
      <td>0.984547</td>
      <td>0.981070</td>
      <td>0.979340</td>
      <td>0.980550</td>
      <td>0.983889</td>
      <td>0.986979</td>
      <td>0.984963</td>
      <td>0.986019</td>
      <td>0.977243</td>
    </tr>
    <tr>
      <th>1865-Lincoln</th>
      <td>0.991850</td>
      <td>0.978980</td>
      <td>0.989841</td>
      <td>0.993097</td>
      <td>0.992186</td>
      <td>0.988775</td>
      <td>0.991558</td>
      <td>0.990383</td>
      <td>0.990859</td>
      <td>0.983373</td>
      <td>...</td>
      <td>0.990906</td>
      <td>0.990722</td>
      <td>0.987152</td>
      <td>0.985562</td>
      <td>0.986962</td>
      <td>0.986906</td>
      <td>0.988931</td>
      <td>0.990939</td>
      <td>0.988519</td>
      <td>0.983334</td>
    </tr>
    <tr>
      <th>1869-Grant</th>
      <td>0.993630</td>
      <td>0.982554</td>
      <td>0.990639</td>
      <td>0.992533</td>
      <td>0.994123</td>
      <td>0.992883</td>
      <td>0.990527</td>
      <td>0.995151</td>
      <td>0.993490</td>
      <td>0.986786</td>
      <td>...</td>
      <td>0.990599</td>
      <td>0.988255</td>
      <td>0.982825</td>
      <td>0.983772</td>
      <td>0.986367</td>
      <td>0.986984</td>
      <td>0.989443</td>
      <td>0.988477</td>
      <td>0.989815</td>
      <td>0.982621</td>
    </tr>
    <tr>
      <th>1873-Grant</th>
      <td>0.994870</td>
      <td>0.982566</td>
      <td>0.994265</td>
      <td>0.994683</td>
      <td>0.994519</td>
      <td>0.993786</td>
      <td>0.993044</td>
      <td>0.996282</td>
      <td>0.996298</td>
      <td>0.989333</td>
      <td>...</td>
      <td>0.992510</td>
      <td>0.992199</td>
      <td>0.987673</td>
      <td>0.986921</td>
      <td>0.990121</td>
      <td>0.988595</td>
      <td>0.991817</td>
      <td>0.990175</td>
      <td>0.989506</td>
      <td>0.985568</td>
    </tr>
    <tr>
      <th>1877-Hayes</th>
      <td>0.995040</td>
      <td>0.982854</td>
      <td>0.995742</td>
      <td>0.993774</td>
      <td>0.994285</td>
      <td>0.996054</td>
      <td>0.994080</td>
      <td>0.996027</td>
      <td>0.995692</td>
      <td>0.996267</td>
      <td>...</td>
      <td>0.984084</td>
      <td>0.983427</td>
      <td>0.974936</td>
      <td>0.977775</td>
      <td>0.982705</td>
      <td>0.982174</td>
      <td>0.989867</td>
      <td>0.982554</td>
      <td>0.983685</td>
      <td>0.975392</td>
    </tr>
    <tr>
      <th>1881-Garfield</th>
      <td>0.993440</td>
      <td>0.981812</td>
      <td>0.993894</td>
      <td>0.993194</td>
      <td>0.993665</td>
      <td>0.995713</td>
      <td>0.995446</td>
      <td>0.996579</td>
      <td>0.995986</td>
      <td>0.996781</td>
      <td>...</td>
      <td>0.985706</td>
      <td>0.985540</td>
      <td>0.975861</td>
      <td>0.979533</td>
      <td>0.985460</td>
      <td>0.982937</td>
      <td>0.991188</td>
      <td>0.984959</td>
      <td>0.985929</td>
      <td>0.978803</td>
    </tr>
    <tr>
      <th>1885-Cleveland</th>
      <td>0.992011</td>
      <td>0.978997</td>
      <td>0.993574</td>
      <td>0.992360</td>
      <td>0.992653</td>
      <td>0.995996</td>
      <td>0.993043</td>
      <td>0.994325</td>
      <td>0.991620</td>
      <td>0.996554</td>
      <td>...</td>
      <td>0.981095</td>
      <td>0.980658</td>
      <td>0.969785</td>
      <td>0.975766</td>
      <td>0.981837</td>
      <td>0.980475</td>
      <td>0.989219</td>
      <td>0.980835</td>
      <td>0.983073</td>
      <td>0.974305</td>
    </tr>
    <tr>
      <th>1889-Harrison</th>
      <td>0.995146</td>
      <td>0.981674</td>
      <td>0.994755</td>
      <td>0.994420</td>
      <td>0.996618</td>
      <td>0.996619</td>
      <td>0.994981</td>
      <td>0.998114</td>
      <td>0.996787</td>
      <td>0.993638</td>
      <td>...</td>
      <td>0.988813</td>
      <td>0.986968</td>
      <td>0.979556</td>
      <td>0.982007</td>
      <td>0.986132</td>
      <td>0.986057</td>
      <td>0.991057</td>
      <td>0.987642</td>
      <td>0.988941</td>
      <td>0.981019</td>
    </tr>
    <tr>
      <th>1893-Cleveland</th>
      <td>0.993250</td>
      <td>0.977272</td>
      <td>0.991348</td>
      <td>0.993219</td>
      <td>0.994435</td>
      <td>0.996141</td>
      <td>0.992948</td>
      <td>0.994192</td>
      <td>0.990387</td>
      <td>0.992246</td>
      <td>...</td>
      <td>0.984151</td>
      <td>0.982170</td>
      <td>0.973228</td>
      <td>0.978738</td>
      <td>0.982136</td>
      <td>0.983638</td>
      <td>0.989369</td>
      <td>0.985115</td>
      <td>0.987462</td>
      <td>0.976212</td>
    </tr>
    <tr>
      <th>1897-McKinley</th>
      <td>0.994731</td>
      <td>0.980758</td>
      <td>0.995447</td>
      <td>0.994105</td>
      <td>0.995678</td>
      <td>0.995787</td>
      <td>0.993905</td>
      <td>0.997884</td>
      <td>0.997270</td>
      <td>0.993484</td>
      <td>...</td>
      <td>0.988548</td>
      <td>0.987124</td>
      <td>0.979139</td>
      <td>0.982133</td>
      <td>0.985482</td>
      <td>0.985578</td>
      <td>0.990682</td>
      <td>0.986769</td>
      <td>0.987339</td>
      <td>0.980595</td>
    </tr>
    <tr>
      <th>1901-McKinley</th>
      <td>0.993446</td>
      <td>0.982137</td>
      <td>0.994229</td>
      <td>0.994610</td>
      <td>0.995475</td>
      <td>0.995578</td>
      <td>0.995256</td>
      <td>0.997006</td>
      <td>0.996385</td>
      <td>0.994055</td>
      <td>...</td>
      <td>0.990321</td>
      <td>0.989782</td>
      <td>0.981016</td>
      <td>0.985248</td>
      <td>0.988533</td>
      <td>0.987503</td>
      <td>0.993202</td>
      <td>0.988948</td>
      <td>0.989856</td>
      <td>0.984238</td>
    </tr>
    <tr>
      <th>1905-Roosevelt</th>
      <td>0.991457</td>
      <td>0.971164</td>
      <td>0.991291</td>
      <td>0.995269</td>
      <td>0.993987</td>
      <td>0.991513</td>
      <td>0.990980</td>
      <td>0.994046</td>
      <td>0.990902</td>
      <td>0.985437</td>
      <td>...</td>
      <td>0.994908</td>
      <td>0.993565</td>
      <td>0.990337</td>
      <td>0.992515</td>
      <td>0.992954</td>
      <td>0.994099</td>
      <td>0.994717</td>
      <td>0.996303</td>
      <td>0.995625</td>
      <td>0.989384</td>
    </tr>
    <tr>
      <th>1909-Taft</th>
      <td>0.992431</td>
      <td>0.979226</td>
      <td>0.991373</td>
      <td>0.989280</td>
      <td>0.992032</td>
      <td>0.993608</td>
      <td>0.991492</td>
      <td>0.996117</td>
      <td>0.996290</td>
      <td>0.991720</td>
      <td>...</td>
      <td>0.983451</td>
      <td>0.981775</td>
      <td>0.973397</td>
      <td>0.974879</td>
      <td>0.980545</td>
      <td>0.978645</td>
      <td>0.985085</td>
      <td>0.980764</td>
      <td>0.981918</td>
      <td>0.974217</td>
    </tr>
    <tr>
      <th>1913-Wilson</th>
      <td>0.992206</td>
      <td>0.972594</td>
      <td>0.992515</td>
      <td>0.995943</td>
      <td>0.994530</td>
      <td>0.991556</td>
      <td>0.991222</td>
      <td>0.994529</td>
      <td>0.991896</td>
      <td>0.985253</td>
      <td>...</td>
      <td>0.995620</td>
      <td>0.994697</td>
      <td>0.992290</td>
      <td>0.992518</td>
      <td>0.993737</td>
      <td>0.993489</td>
      <td>0.994009</td>
      <td>0.996153</td>
      <td>0.994582</td>
      <td>0.990180</td>
    </tr>
    <tr>
      <th>1917-Wilson</th>
      <td>0.992573</td>
      <td>0.975883</td>
      <td>0.990609</td>
      <td>0.995545</td>
      <td>0.995115</td>
      <td>0.993256</td>
      <td>0.991972</td>
      <td>0.994777</td>
      <td>0.991777</td>
      <td>0.987201</td>
      <td>...</td>
      <td>0.994100</td>
      <td>0.992487</td>
      <td>0.988961</td>
      <td>0.991070</td>
      <td>0.992434</td>
      <td>0.992264</td>
      <td>0.994405</td>
      <td>0.995138</td>
      <td>0.995452</td>
      <td>0.988934</td>
    </tr>
    <tr>
      <th>1921-Harding</th>
      <td>0.991518</td>
      <td>0.973856</td>
      <td>0.993635</td>
      <td>0.996226</td>
      <td>0.994506</td>
      <td>0.993272</td>
      <td>0.991788</td>
      <td>0.994429</td>
      <td>0.991240</td>
      <td>0.987752</td>
      <td>...</td>
      <td>0.994521</td>
      <td>0.993510</td>
      <td>0.987794</td>
      <td>0.992516</td>
      <td>0.992958</td>
      <td>0.994717</td>
      <td>0.996548</td>
      <td>0.994779</td>
      <td>0.994982</td>
      <td>0.989444</td>
    </tr>
    <tr>
      <th>1925-Coolidge</th>
      <td>0.993633</td>
      <td>0.976016</td>
      <td>0.993194</td>
      <td>0.994760</td>
      <td>0.995690</td>
      <td>0.994461</td>
      <td>0.993212</td>
      <td>0.997622</td>
      <td>0.995366</td>
      <td>0.989427</td>
      <td>...</td>
      <td>0.993236</td>
      <td>0.991182</td>
      <td>0.986116</td>
      <td>0.987946</td>
      <td>0.989782</td>
      <td>0.991431</td>
      <td>0.993701</td>
      <td>0.992526</td>
      <td>0.993495</td>
      <td>0.985808</td>
    </tr>
    <tr>
      <th>1929-Hoover</th>
      <td>0.990946</td>
      <td>0.975569</td>
      <td>0.991888</td>
      <td>0.991455</td>
      <td>0.992478</td>
      <td>0.995203</td>
      <td>0.992329</td>
      <td>0.995957</td>
      <td>0.993169</td>
      <td>0.994771</td>
      <td>...</td>
      <td>0.985203</td>
      <td>0.984329</td>
      <td>0.974429</td>
      <td>0.979863</td>
      <td>0.985587</td>
      <td>0.984464</td>
      <td>0.991181</td>
      <td>0.984891</td>
      <td>0.987067</td>
      <td>0.978435</td>
    </tr>
    <tr>
      <th>1933-Roosevelt</th>
      <td>0.994623</td>
      <td>0.977735</td>
      <td>0.992866</td>
      <td>0.995453</td>
      <td>0.995147</td>
      <td>0.994973</td>
      <td>0.993812</td>
      <td>0.997260</td>
      <td>0.994477</td>
      <td>0.990058</td>
      <td>...</td>
      <td>0.994042</td>
      <td>0.992711</td>
      <td>0.987441</td>
      <td>0.989234</td>
      <td>0.992009</td>
      <td>0.992171</td>
      <td>0.994279</td>
      <td>0.993827</td>
      <td>0.994124</td>
      <td>0.986814</td>
    </tr>
    <tr>
      <th>1937-Roosevelt</th>
      <td>0.990172</td>
      <td>0.972661</td>
      <td>0.989536</td>
      <td>0.994134</td>
      <td>0.992516</td>
      <td>0.991482</td>
      <td>0.991152</td>
      <td>0.993871</td>
      <td>0.990222</td>
      <td>0.986891</td>
      <td>...</td>
      <td>0.995623</td>
      <td>0.995301</td>
      <td>0.990128</td>
      <td>0.992313</td>
      <td>0.995160</td>
      <td>0.993967</td>
      <td>0.995574</td>
      <td>0.996414</td>
      <td>0.996372</td>
      <td>0.990314</td>
    </tr>
    <tr>
      <th>1941-Roosevelt</th>
      <td>0.988531</td>
      <td>0.972102</td>
      <td>0.990354</td>
      <td>0.992957</td>
      <td>0.989439</td>
      <td>0.988767</td>
      <td>0.990600</td>
      <td>0.992111</td>
      <td>0.990005</td>
      <td>0.986698</td>
      <td>...</td>
      <td>0.993642</td>
      <td>0.994664</td>
      <td>0.990250</td>
      <td>0.991596</td>
      <td>0.994821</td>
      <td>0.992409</td>
      <td>0.995335</td>
      <td>0.994605</td>
      <td>0.992958</td>
      <td>0.989574</td>
    </tr>
    <tr>
      <th>1945-Roosevelt</th>
      <td>0.985560</td>
      <td>0.970936</td>
      <td>0.984518</td>
      <td>0.991326</td>
      <td>0.987265</td>
      <td>0.983530</td>
      <td>0.984057</td>
      <td>0.986986</td>
      <td>0.983619</td>
      <td>0.976326</td>
      <td>...</td>
      <td>0.995476</td>
      <td>0.994958</td>
      <td>0.994579</td>
      <td>0.993437</td>
      <td>0.993088</td>
      <td>0.994703</td>
      <td>0.992738</td>
      <td>0.996447</td>
      <td>0.995031</td>
      <td>0.990903</td>
    </tr>
    <tr>
      <th>1949-Truman</th>
      <td>0.986526</td>
      <td>0.966529</td>
      <td>0.988999</td>
      <td>0.991442</td>
      <td>0.991287</td>
      <td>0.991231</td>
      <td>0.988996</td>
      <td>0.993925</td>
      <td>0.989982</td>
      <td>0.987271</td>
      <td>...</td>
      <td>0.991403</td>
      <td>0.991079</td>
      <td>0.982909</td>
      <td>0.989248</td>
      <td>0.992046</td>
      <td>0.991017</td>
      <td>0.994693</td>
      <td>0.991352</td>
      <td>0.993231</td>
      <td>0.987852</td>
    </tr>
    <tr>
      <th>1953-Eisenhower</th>
      <td>0.989820</td>
      <td>0.973125</td>
      <td>0.991441</td>
      <td>0.995925</td>
      <td>0.992788</td>
      <td>0.992651</td>
      <td>0.991203</td>
      <td>0.993149</td>
      <td>0.988750</td>
      <td>0.988242</td>
      <td>...</td>
      <td>0.993412</td>
      <td>0.992955</td>
      <td>0.987340</td>
      <td>0.992125</td>
      <td>0.994473</td>
      <td>0.994017</td>
      <td>0.997410</td>
      <td>0.994952</td>
      <td>0.995546</td>
      <td>0.990027</td>
    </tr>
    <tr>
      <th>1957-Eisenhower</th>
      <td>0.986477</td>
      <td>0.969427</td>
      <td>0.990091</td>
      <td>0.994551</td>
      <td>0.991010</td>
      <td>0.988981</td>
      <td>0.988332</td>
      <td>0.990914</td>
      <td>0.987247</td>
      <td>0.983687</td>
      <td>...</td>
      <td>0.995253</td>
      <td>0.995137</td>
      <td>0.990537</td>
      <td>0.994996</td>
      <td>0.995775</td>
      <td>0.995322</td>
      <td>0.997209</td>
      <td>0.996652</td>
      <td>0.995561</td>
      <td>0.993226</td>
    </tr>
    <tr>
      <th>1961-Kennedy</th>
      <td>0.987520</td>
      <td>0.972412</td>
      <td>0.989059</td>
      <td>0.994776</td>
      <td>0.991143</td>
      <td>0.988151</td>
      <td>0.988878</td>
      <td>0.990319</td>
      <td>0.986957</td>
      <td>0.981397</td>
      <td>...</td>
      <td>0.996872</td>
      <td>0.996884</td>
      <td>0.993398</td>
      <td>0.995691</td>
      <td>0.996412</td>
      <td>0.995577</td>
      <td>0.996370</td>
      <td>0.997358</td>
      <td>0.996638</td>
      <td>0.993826</td>
    </tr>
    <tr>
      <th>1965-Johnson</th>
      <td>0.983712</td>
      <td>0.968233</td>
      <td>0.983886</td>
      <td>0.990713</td>
      <td>0.986524</td>
      <td>0.981792</td>
      <td>0.983502</td>
      <td>0.985785</td>
      <td>0.982485</td>
      <td>0.974258</td>
      <td>...</td>
      <td>0.996825</td>
      <td>0.996948</td>
      <td>0.997027</td>
      <td>0.995795</td>
      <td>0.995601</td>
      <td>0.995767</td>
      <td>0.993645</td>
      <td>0.997215</td>
      <td>0.995343</td>
      <td>0.994133</td>
    </tr>
    <tr>
      <th>1969-Nixon</th>
      <td>0.983411</td>
      <td>0.966299</td>
      <td>0.983062</td>
      <td>0.990399</td>
      <td>0.985533</td>
      <td>0.982240</td>
      <td>0.982663</td>
      <td>0.985878</td>
      <td>0.982129</td>
      <td>0.974961</td>
      <td>...</td>
      <td>0.996669</td>
      <td>0.997003</td>
      <td>0.996383</td>
      <td>0.996723</td>
      <td>0.996937</td>
      <td>0.994960</td>
      <td>0.993562</td>
      <td>0.997327</td>
      <td>0.995405</td>
      <td>0.994648</td>
    </tr>
    <tr>
      <th>1973-Nixon</th>
      <td>0.985883</td>
      <td>0.968705</td>
      <td>0.985145</td>
      <td>0.990984</td>
      <td>0.988480</td>
      <td>0.986011</td>
      <td>0.984715</td>
      <td>0.989927</td>
      <td>0.985709</td>
      <td>0.978199</td>
      <td>...</td>
      <td>0.997192</td>
      <td>0.996679</td>
      <td>0.994331</td>
      <td>0.996236</td>
      <td>0.996751</td>
      <td>0.996319</td>
      <td>0.994708</td>
      <td>0.996687</td>
      <td>0.997110</td>
      <td>0.993863</td>
    </tr>
    <tr>
      <th>1977-Carter</th>
      <td>0.986636</td>
      <td>0.967777</td>
      <td>0.986108</td>
      <td>0.992544</td>
      <td>0.989733</td>
      <td>0.986370</td>
      <td>0.985504</td>
      <td>0.989480</td>
      <td>0.984525</td>
      <td>0.977306</td>
      <td>...</td>
      <td>0.996640</td>
      <td>0.995500</td>
      <td>0.994102</td>
      <td>0.995748</td>
      <td>0.994950</td>
      <td>0.997313</td>
      <td>0.995005</td>
      <td>0.997600</td>
      <td>0.997995</td>
      <td>0.992384</td>
    </tr>
    <tr>
      <th>1981-Reagan</th>
      <td>0.986210</td>
      <td>0.969932</td>
      <td>0.987519</td>
      <td>0.992771</td>
      <td>0.990597</td>
      <td>0.985634</td>
      <td>0.985924</td>
      <td>0.990336</td>
      <td>0.987214</td>
      <td>0.977643</td>
      <td>...</td>
      <td>1.000000</td>
      <td>0.998517</td>
      <td>0.996777</td>
      <td>0.997345</td>
      <td>0.996348</td>
      <td>0.997490</td>
      <td>0.995543</td>
      <td>0.998226</td>
      <td>0.997504</td>
      <td>0.996276</td>
    </tr>
    <tr>
      <th>1985-Reagan</th>
      <td>0.984592</td>
      <td>0.968063</td>
      <td>0.987122</td>
      <td>0.991856</td>
      <td>0.988671</td>
      <td>0.984529</td>
      <td>0.985979</td>
      <td>0.989043</td>
      <td>0.986302</td>
      <td>0.978597</td>
      <td>...</td>
      <td>0.998517</td>
      <td>1.000000</td>
      <td>0.996242</td>
      <td>0.997388</td>
      <td>0.997684</td>
      <td>0.996678</td>
      <td>0.995618</td>
      <td>0.997725</td>
      <td>0.996575</td>
      <td>0.996393</td>
    </tr>
    <tr>
      <th>1989-Bush</th>
      <td>0.979744</td>
      <td>0.963082</td>
      <td>0.980362</td>
      <td>0.987243</td>
      <td>0.982631</td>
      <td>0.976437</td>
      <td>0.977283</td>
      <td>0.982400</td>
      <td>0.978821</td>
      <td>0.966633</td>
      <td>...</td>
      <td>0.996777</td>
      <td>0.996242</td>
      <td>1.000000</td>
      <td>0.995683</td>
      <td>0.993678</td>
      <td>0.995151</td>
      <td>0.990250</td>
      <td>0.995531</td>
      <td>0.993573</td>
      <td>0.994374</td>
    </tr>
    <tr>
      <th>1993-Clinton</th>
      <td>0.979804</td>
      <td>0.961651</td>
      <td>0.982656</td>
      <td>0.989480</td>
      <td>0.985335</td>
      <td>0.980069</td>
      <td>0.980455</td>
      <td>0.984682</td>
      <td>0.980137</td>
      <td>0.971966</td>
      <td>...</td>
      <td>0.997345</td>
      <td>0.997388</td>
      <td>0.995683</td>
      <td>1.000000</td>
      <td>0.997029</td>
      <td>0.997300</td>
      <td>0.994541</td>
      <td>0.997460</td>
      <td>0.996898</td>
      <td>0.997785</td>
    </tr>
    <tr>
      <th>1997-Clinton</th>
      <td>0.983050</td>
      <td>0.964160</td>
      <td>0.985610</td>
      <td>0.990766</td>
      <td>0.986885</td>
      <td>0.984644</td>
      <td>0.985236</td>
      <td>0.988608</td>
      <td>0.984373</td>
      <td>0.979890</td>
      <td>...</td>
      <td>0.996348</td>
      <td>0.997684</td>
      <td>0.993678</td>
      <td>0.997029</td>
      <td>1.000000</td>
      <td>0.995707</td>
      <td>0.995684</td>
      <td>0.997072</td>
      <td>0.996276</td>
      <td>0.996217</td>
    </tr>
    <tr>
      <th>2001-Bush</th>
      <td>0.983414</td>
      <td>0.966520</td>
      <td>0.986268</td>
      <td>0.991621</td>
      <td>0.988334</td>
      <td>0.983880</td>
      <td>0.983550</td>
      <td>0.987530</td>
      <td>0.982719</td>
      <td>0.975559</td>
      <td>...</td>
      <td>0.997490</td>
      <td>0.996678</td>
      <td>0.995151</td>
      <td>0.997300</td>
      <td>0.995707</td>
      <td>1.000000</td>
      <td>0.996184</td>
      <td>0.997199</td>
      <td>0.997579</td>
      <td>0.995097</td>
    </tr>
    <tr>
      <th>2005-Bush</th>
      <td>0.988405</td>
      <td>0.974160</td>
      <td>0.991875</td>
      <td>0.995475</td>
      <td>0.992062</td>
      <td>0.990701</td>
      <td>0.990505</td>
      <td>0.992253</td>
      <td>0.988643</td>
      <td>0.986688</td>
      <td>...</td>
      <td>0.995543</td>
      <td>0.995618</td>
      <td>0.990250</td>
      <td>0.994541</td>
      <td>0.995684</td>
      <td>0.996184</td>
      <td>1.000000</td>
      <td>0.995275</td>
      <td>0.996155</td>
      <td>0.992885</td>
    </tr>
    <tr>
      <th>2009-Obama</th>
      <td>0.985737</td>
      <td>0.966003</td>
      <td>0.986466</td>
      <td>0.992918</td>
      <td>0.990233</td>
      <td>0.985869</td>
      <td>0.986500</td>
      <td>0.989618</td>
      <td>0.985501</td>
      <td>0.978106</td>
      <td>...</td>
      <td>0.998226</td>
      <td>0.997725</td>
      <td>0.995531</td>
      <td>0.997460</td>
      <td>0.997072</td>
      <td>0.997199</td>
      <td>0.995275</td>
      <td>1.000000</td>
      <td>0.998365</td>
      <td>0.995803</td>
    </tr>
    <tr>
      <th>2013-Obama</th>
      <td>0.985897</td>
      <td>0.967889</td>
      <td>0.985879</td>
      <td>0.992549</td>
      <td>0.990316</td>
      <td>0.986502</td>
      <td>0.986124</td>
      <td>0.989983</td>
      <td>0.984886</td>
      <td>0.978866</td>
      <td>...</td>
      <td>0.997504</td>
      <td>0.996575</td>
      <td>0.993573</td>
      <td>0.996898</td>
      <td>0.996276</td>
      <td>0.997579</td>
      <td>0.996155</td>
      <td>0.998365</td>
      <td>1.000000</td>
      <td>0.995012</td>
    </tr>
    <tr>
      <th>2017-Trump</th>
      <td>0.976485</td>
      <td>0.959819</td>
      <td>0.980082</td>
      <td>0.986645</td>
      <td>0.982970</td>
      <td>0.977609</td>
      <td>0.978471</td>
      <td>0.983361</td>
      <td>0.978818</td>
      <td>0.970515</td>
      <td>...</td>
      <td>0.996276</td>
      <td>0.996393</td>
      <td>0.994374</td>
      <td>0.997785</td>
      <td>0.996217</td>
      <td>0.995097</td>
      <td>0.992885</td>
      <td>0.995803</td>
      <td>0.995012</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>58 rows × 58 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;US Presidential Inaugural Speech&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Document&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">textid</span><span class="p">,</span> <span class="n">leaf_rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mf">0.07</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7fd5bdaad940&gt;
</pre></div>
</div>
<img alt="../_images/word2vec-chinese_57_1.png" src="../_images/word2vec-chinese_57_1.png" />
</div>
</div>
</div>
<div class="section" id="question-4">
<h2>Question 4<a class="headerlink" href="#question-4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Use ckip-transformer</p>
<ul>
<li><p>word segmentation and pos-tagging</p></li>
<li><p>filter words whose POS initial ‘N’</p></li>
<li><p>get GloVe</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus.reader</span> <span class="kn">import</span> <span class="n">PlaintextCorpusReader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">DEMO_DATA_ROOT</span> <span class="o">=</span> <span class="s2">&quot;../../../RepositoryData/data&quot;</span>
<span class="n">corpus_dir</span> <span class="o">=</span> <span class="n">DEMO_DATA_ROOT</span><span class="o">+</span><span class="s2">&quot;/TaiwanPresidentialInaugarationSpeech_en&quot;</span>
<span class="n">twp</span> <span class="o">=</span> <span class="n">PlaintextCorpusReader</span><span class="p">(</span><span class="n">corpus_dir</span><span class="p">,</span> <span class="s2">&quot;.*\.txt&quot;</span><span class="p">)</span>
<span class="n">twp_corpus</span><span class="o">=</span> <span class="p">[</span><span class="n">twp</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileids</span><span class="o">=</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>


<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;zh_core_web_lg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%time</span>
<span class="c1"># ##################################################################</span>
<span class="c1"># ## CKIP-transformer word-pos the entire corpus                  ##</span>
<span class="c1"># ##################################################################</span>

<span class="c1"># import ckip_transformers</span>
<span class="c1"># from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger</span>


<span class="c1"># # Initialize drivers</span>
<span class="c1"># ws_driver = CkipWordSegmenter(level=3, device=-1)</span>
<span class="c1"># pos_driver = CkipPosTagger(level=3, device=-1)</span>

<span class="c1"># d = &#39;這是一個中文句子&#39;</span>

<span class="c1"># def word_pos(string, ws_driver, pos_driver):</span>
<span class="c1">#     cur_w = ws_driver([string],use_delim=True)</span>
<span class="c1">#     cur_pos = pos_driver(cur_w)</span>
    
<span class="c1">#     return [(w,p) for (w,p) in zip(cur_w[0], cur_pos[0])]</span>
<span class="c1"># word_pos(d, ws_driver, pos_driver)</span>
<span class="c1"># # word_pos(twp_corpus[0], ws_driver, pos_driver)</span>

<span class="c1"># # twp_corpus_seg4 = [word_pos(d, ws_driver, pos_driver) for d in twp_corpus]</span>

<span class="c1"># ##################################################################</span>
<span class="c1"># ## Pickle results                                               ##</span>
<span class="c1"># ##################################################################</span>

<span class="c1"># # import pickle</span>
<span class="c1"># # with open(&#39;twp_corpus_seg4.pickle&#39;, &#39;wb&#39;) as f:</span>
<span class="c1"># #     pickle.dump(twp_corpus_seg4, f, protocol=pickle.HIGHEST_PROTOCOL)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Load ckip-transformer segmented version</span>
<span class="c1">## each file is a list of (word, pos) tuples</span>
<span class="c1">## use the pos to filter words</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;twp_corpus_seg4.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">twp_corpus_seg4</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">twp_corpus_seg4</span><span class="p">))</span>


<span class="c1">###########################################################################</span>
<span class="c1">## Add new file to the pickle without rerunning the entire pos-tagging</span>
<span class="c1">###########################################################################</span>
<span class="c1"># %%time</span>
<span class="c1"># print(len(twp_corpus_seg4))</span>
<span class="c1"># twp_corpus_seg4.append(word_pos(twp_corpus[14], ws_driver, pos_driver))</span>
<span class="c1"># print(len(twp_corpus_seg4))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>15
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_corpus_seg4</span><span class="p">[</span><span class="mi">14</span><span class="p">][:</span><span class="mi">50</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;各位&#39;, &#39;Nh&#39;),
 (&#39;友邦&#39;, &#39;Nc&#39;),
 (&#39;的&#39;, &#39;DE&#39;),
 (&#39;元首&#39;, &#39;Na&#39;),
 (&#39;與&#39;, &#39;Caa&#39;),
 (&#39;貴賓&#39;, &#39;Na&#39;),
 (&#39;、&#39;, &#39;PAUSECATEGORY&#39;),
 (&#39;各&#39;, &#39;Nes&#39;),
 (&#39;國&#39;, &#39;Nc&#39;),
 (&#39;駐&#39;, &#39;VCL&#39;),
 (&#39;臺&#39;, &#39;Nc&#39;),
 (&#39;使節&#39;, &#39;Na&#39;),
 (&#39;及&#39;, &#39;Caa&#39;),
 (&#39;代表&#39;, &#39;Na&#39;),
 (&#39;、&#39;, &#39;PAUSECATEGORY&#39;),
 (&#39;現場&#39;, &#39;Nc&#39;),
 (&#39;的&#39;, &#39;DE&#39;),
 (&#39;好朋友&#39;, &#39;Na&#39;),
 (&#39;，&#39;, &#39;COMMACATEGORY&#39;),
 (&#39;全體&#39;, &#39;Na&#39;),
 (&#39;國人&#39;, &#39;Na&#39;),
 (&#39;同胞&#39;, &#39;Na&#39;),
 (&#39;，&#39;, &#39;COMMACATEGORY&#39;),
 (&#39;大家&#39;, &#39;Nh&#39;),
 (&#39;好&#39;, &#39;VH&#39;),
 (&#39;：&#39;, &#39;COLONCATEGORY&#39;),
 (&#39;\n&#39;, &#39;WHITESPACE&#39;),
 (&#39;\n&#39;, &#39;WHITESPACE&#39;),
 (&#39;感謝&#39;, &#39;VK&#39;),
 (&#39;與&#39;, &#39;Caa&#39;),
 (&#39;承擔&#39;, &#39;VC&#39;),
 (&#39;\n&#39;, &#39;WHITESPACE&#39;),
 (&#39;就&#39;, &#39;D&#39;),
 (&#39;在&#39;, &#39;P&#39;),
 (&#39;剛剛&#39;, &#39;D&#39;),
 (&#39;，&#39;, &#39;COMMACATEGORY&#39;),
 (&#39;我&#39;, &#39;Nh&#39;),
 (&#39;和&#39;, &#39;Caa&#39;),
 (&#39;陳建仁&#39;, &#39;Nb&#39;),
 (&#39;已經&#39;, &#39;D&#39;),
 (&#39;在&#39;, &#39;VCL&#39;),
 (&#39;總統府&#39;, &#39;Nc&#39;),
 (&#39;裡面&#39;, &#39;Ncd&#39;),
 (&#39;，&#39;, &#39;COMMACATEGORY&#39;),
 (&#39;正式&#39;, &#39;VH&#39;),
 (&#39;宣誓&#39;, &#39;VE&#39;),
 (&#39;就任&#39;, &#39;VG&#39;),
 (&#39;中華民國&#39;, &#39;Nc&#39;),
 (&#39;第十四&#39;, &#39;Neu&#39;),
 (&#39;任&#39;, &#39;Nf&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># filter word tokens based don POS</span>
<span class="c1">#twp_tokens = [[w for (w,p) in doc if p[0] in [&#39;N&#39;,&#39;V&#39;]] for doc in twp_corpus_seg4]</span>
<span class="n">twp_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">w</span> <span class="k">for</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">p</span><span class="p">)</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">&lt;=</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">twp_corpus_seg4</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">twp_tokens_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">nlp</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">vector</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">d</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">twp_tokens</span><span class="p">]</span>
<span class="p">)</span><span class="c1"># axis=0 get column sums</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 2min 59s, sys: 1.18 s, total: 3min
Wall time: 3min 19s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twp_tokens_vec</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(15, 300)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">textid</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">twp</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>
<span class="n">similarity_doc_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">twp_tokens_vec</span><span class="p">)</span>
<span class="n">similarity_doc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">,</span>
                                <span class="n">index</span><span class="o">=</span><span class="n">textid</span><span class="p">,</span>
                                <span class="n">columns</span><span class="o">=</span><span class="n">textid</span><span class="p">)</span>
<span class="n">similarity_doc_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1948_1_JIANGZHONGZHENG</th>
      <th>1954_2_JIANGZHONGZHENG</th>
      <th>1960_3_JIANGZHONGZHENG</th>
      <th>1966_4_JIANGZHONGZHENG</th>
      <th>1972_5_JIANGZHONGZHENG</th>
      <th>1978_6_JIANGJINGGUO</th>
      <th>1984_7_JIANGJINGGUO</th>
      <th>1990_8_LIDENGHUI</th>
      <th>1996_9_LIDENGHUI</th>
      <th>2000_10_CHENSHUIBIAN</th>
      <th>2004_11_CHENSHUIBIAN</th>
      <th>2008_12_MAYANGJIU</th>
      <th>2012_13_MAYANGJIU</th>
      <th>2016_14_CAYANGWEN</th>
      <th>2020_15_CAYANGWEN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1948_1_JIANGZHONGZHENG</th>
      <td>1.000000</td>
      <td>0.985627</td>
      <td>0.981232</td>
      <td>0.965179</td>
      <td>0.949978</td>
      <td>0.988248</td>
      <td>0.975657</td>
      <td>0.982243</td>
      <td>0.985900</td>
      <td>0.987231</td>
      <td>0.986692</td>
      <td>0.980455</td>
      <td>0.972849</td>
      <td>0.974946</td>
      <td>0.976299</td>
    </tr>
    <tr>
      <th>1954_2_JIANGZHONGZHENG</th>
      <td>0.985627</td>
      <td>1.000000</td>
      <td>0.991394</td>
      <td>0.979616</td>
      <td>0.953108</td>
      <td>0.987037</td>
      <td>0.951434</td>
      <td>0.962869</td>
      <td>0.973823</td>
      <td>0.981131</td>
      <td>0.978606</td>
      <td>0.961651</td>
      <td>0.949542</td>
      <td>0.950532</td>
      <td>0.951906</td>
    </tr>
    <tr>
      <th>1960_3_JIANGZHONGZHENG</th>
      <td>0.981232</td>
      <td>0.991394</td>
      <td>1.000000</td>
      <td>0.983092</td>
      <td>0.959223</td>
      <td>0.988496</td>
      <td>0.960238</td>
      <td>0.965506</td>
      <td>0.976752</td>
      <td>0.977978</td>
      <td>0.974651</td>
      <td>0.964379</td>
      <td>0.954721</td>
      <td>0.951598</td>
      <td>0.953175</td>
    </tr>
    <tr>
      <th>1966_4_JIANGZHONGZHENG</th>
      <td>0.965179</td>
      <td>0.979616</td>
      <td>0.983092</td>
      <td>1.000000</td>
      <td>0.980073</td>
      <td>0.970618</td>
      <td>0.952876</td>
      <td>0.942376</td>
      <td>0.955721</td>
      <td>0.957353</td>
      <td>0.951970</td>
      <td>0.941041</td>
      <td>0.930210</td>
      <td>0.925379</td>
      <td>0.926220</td>
    </tr>
    <tr>
      <th>1972_5_JIANGZHONGZHENG</th>
      <td>0.949978</td>
      <td>0.953108</td>
      <td>0.959223</td>
      <td>0.980073</td>
      <td>1.000000</td>
      <td>0.952888</td>
      <td>0.952956</td>
      <td>0.940802</td>
      <td>0.939708</td>
      <td>0.934869</td>
      <td>0.929428</td>
      <td>0.919957</td>
      <td>0.914989</td>
      <td>0.897766</td>
      <td>0.899317</td>
    </tr>
    <tr>
      <th>1978_6_JIANGJINGGUO</th>
      <td>0.988248</td>
      <td>0.987037</td>
      <td>0.988496</td>
      <td>0.970618</td>
      <td>0.952888</td>
      <td>1.000000</td>
      <td>0.970226</td>
      <td>0.975380</td>
      <td>0.985753</td>
      <td>0.987611</td>
      <td>0.982094</td>
      <td>0.975832</td>
      <td>0.966259</td>
      <td>0.963024</td>
      <td>0.964227</td>
    </tr>
    <tr>
      <th>1984_7_JIANGJINGGUO</th>
      <td>0.975657</td>
      <td>0.951434</td>
      <td>0.960238</td>
      <td>0.952876</td>
      <td>0.952956</td>
      <td>0.970226</td>
      <td>1.000000</td>
      <td>0.976908</td>
      <td>0.978380</td>
      <td>0.968354</td>
      <td>0.965434</td>
      <td>0.976530</td>
      <td>0.971699</td>
      <td>0.966244</td>
      <td>0.966440</td>
    </tr>
    <tr>
      <th>1990_8_LIDENGHUI</th>
      <td>0.982243</td>
      <td>0.962869</td>
      <td>0.965506</td>
      <td>0.942376</td>
      <td>0.940802</td>
      <td>0.975380</td>
      <td>0.976908</td>
      <td>1.000000</td>
      <td>0.989875</td>
      <td>0.981773</td>
      <td>0.983571</td>
      <td>0.982701</td>
      <td>0.986612</td>
      <td>0.968347</td>
      <td>0.970363</td>
    </tr>
    <tr>
      <th>1996_9_LIDENGHUI</th>
      <td>0.985900</td>
      <td>0.973823</td>
      <td>0.976752</td>
      <td>0.955721</td>
      <td>0.939708</td>
      <td>0.985753</td>
      <td>0.978380</td>
      <td>0.989875</td>
      <td>1.000000</td>
      <td>0.993962</td>
      <td>0.991728</td>
      <td>0.993690</td>
      <td>0.988530</td>
      <td>0.982831</td>
      <td>0.983564</td>
    </tr>
    <tr>
      <th>2000_10_CHENSHUIBIAN</th>
      <td>0.987231</td>
      <td>0.981131</td>
      <td>0.977978</td>
      <td>0.957353</td>
      <td>0.934869</td>
      <td>0.987611</td>
      <td>0.968354</td>
      <td>0.981773</td>
      <td>0.993962</td>
      <td>1.000000</td>
      <td>0.995687</td>
      <td>0.990095</td>
      <td>0.980922</td>
      <td>0.980913</td>
      <td>0.981304</td>
    </tr>
    <tr>
      <th>2004_11_CHENSHUIBIAN</th>
      <td>0.986692</td>
      <td>0.978606</td>
      <td>0.974651</td>
      <td>0.951970</td>
      <td>0.929428</td>
      <td>0.982094</td>
      <td>0.965434</td>
      <td>0.983571</td>
      <td>0.991728</td>
      <td>0.995687</td>
      <td>1.000000</td>
      <td>0.988828</td>
      <td>0.982707</td>
      <td>0.980889</td>
      <td>0.981782</td>
    </tr>
    <tr>
      <th>2008_12_MAYANGJIU</th>
      <td>0.980455</td>
      <td>0.961651</td>
      <td>0.964379</td>
      <td>0.941041</td>
      <td>0.919957</td>
      <td>0.975832</td>
      <td>0.976530</td>
      <td>0.982701</td>
      <td>0.993690</td>
      <td>0.990095</td>
      <td>0.988828</td>
      <td>1.000000</td>
      <td>0.991403</td>
      <td>0.991361</td>
      <td>0.991321</td>
    </tr>
    <tr>
      <th>2012_13_MAYANGJIU</th>
      <td>0.972849</td>
      <td>0.949542</td>
      <td>0.954721</td>
      <td>0.930210</td>
      <td>0.914989</td>
      <td>0.966259</td>
      <td>0.971699</td>
      <td>0.986612</td>
      <td>0.988530</td>
      <td>0.980922</td>
      <td>0.982707</td>
      <td>0.991403</td>
      <td>1.000000</td>
      <td>0.984512</td>
      <td>0.985406</td>
    </tr>
    <tr>
      <th>2016_14_CAYANGWEN</th>
      <td>0.974946</td>
      <td>0.950532</td>
      <td>0.951598</td>
      <td>0.925379</td>
      <td>0.897766</td>
      <td>0.963024</td>
      <td>0.966244</td>
      <td>0.968347</td>
      <td>0.982831</td>
      <td>0.980913</td>
      <td>0.980889</td>
      <td>0.991361</td>
      <td>0.984512</td>
      <td>0.999999</td>
      <td>0.999630</td>
    </tr>
    <tr>
      <th>2020_15_CAYANGWEN</th>
      <td>0.976299</td>
      <td>0.951906</td>
      <td>0.953175</td>
      <td>0.926220</td>
      <td>0.899317</td>
      <td>0.964227</td>
      <td>0.966440</td>
      <td>0.970363</td>
      <td>0.983564</td>
      <td>0.981304</td>
      <td>0.981782</td>
      <td>0.991321</td>
      <td>0.985406</td>
      <td>0.999630</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">similarity_doc_matrix</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Taiwan Presidential Inaugural Speech&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Document&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">textid</span><span class="p">,</span> <span class="n">leaf_rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7fd59c864b38&gt;
</pre></div>
</div>
<img alt="../_images/word2vec-chinese_68_1.png" src="../_images/word2vec-chinese_68_1.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python-notes",
            path: "./exercise-ans"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>